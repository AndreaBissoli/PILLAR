{
    "patterns": [
        {
            "filename": "Abridged-Terms-and-Conditions.html",
            "title": "Abridged Terms and Conditions",
            "excerpt": "Enables the user to better understand the Terms and Conditions presented by a system through summarization. The most important elements therein are condensed into a more concise overview.",
            "sections": {
                "Context": "Controllers which provide services (or products) to users have various policies, including those which affect user privacy, which need to relayed to the user. If users do not have knowledge of the risks, rights, and responsibilities relevant to them, this is the fault of the controller. Keeping users (the data subjects) informed, especially prior to acquiring consent, is a legal requirement. As such, controllers need to ensure that this is the case. It is however difficult to keep user attention on such matters, as they are often more willing to spend time on other things, including actually using a system. Efforts to hold attention by force also face active resistance.",
                "Problem": "Users often overlook Terms and Conditions when presented with them in their entirety before the use of a service.\n\n##",
                "Forces and Concerns": "- Controllers need to write Terms and Conditions in a manner which will hold up to scrutiny from the law, but this is not accessible to users\n- Controllers want to ensure that users are fully aware of the risks of using the system before using it, for both legal and image purposes\n- Users want to get to using the service without being blockaded by walls of text, but the also do not want to be blindsided about policy\n- Users want to understand the risks in as little time as necessary, at a granularity most suitable to their value of it",
                "Solution": "Summarize the legally sufficient Terms and Conditions into concise and relevant variations which suit the user's level of interest and attention. At first use of a service, users should be able to investigate further, but not have to read much to understand the risks involved.\n\n\n\n\n\n\n\n\n\n#",
                "Implementation": "Prepare the concise Terms and Conditions according to a user perspective, focusing on matters which are most important to them. Aspects which do not affect them should not be included in summarized variations. Where areas of potential interest are easily bundled, group them under a general summary with option to expand further. Using titles in this regard is less helpful if they do not summarize the policies involved, as expanding should not be necessary unless the user notes an area worth their concern. Aim towards a page or less of information, as the inclusion of a scrollbar may dissuade the user.\n\nThe full, legally sound version should also be available, and should not contradict the summarized information. This applies at first use as well, as a user should be allowed to review detail prior to being subjected to it.",
                "Consequences": "The appropriate and concise summarization of the Terms and Conditions will allow users to get a sufficient idea of the rights, risks, and responsibilities relevant to them. As it should be brief, only the most carefree users will overlook them. It will not therefore be guaranteed that users are fully informed, and this should be taken into account.\n\n_Due to the fact that the Terms and Conditions of an application are condensed to a size that is easily comprehensible, a user\u2019s trust in the application can be increased. Additionally, this ensures a greater transparency to the user since possible implications for the user, which may result through the usage of the application, can be recognized more easily beforehand._",
                "Examples": "#",
                "Known Uses": "- _Support-U: An example of an abridged TAC is given in fig. 3. The figure shows the results of the abridged TAC pattern used for the Support-U application._\n- _Connect-U: The user has to sign a license agreement of the size of one page in A4 format. On this page the agreement about the data usage is described in clear detail._\n- _Meet-U: The key points of TAC that affect the user\u2019s privacy the most, are displayed on one screen. Hence, the gathering and processing of data are addressed and summarized briefly. The long version of the TAC is linked. The user has to agree on that before continuing with the application._",
                "See Also": "#",
                "Related Patterns": "This pattern _complements_ Privacy Aware Wording(Privacy-Aware-Wording), Layered Policy Design(Layered-policy-design), and Privacy-Aware Network Client(Privacy-aware-network-client).\n\nThe relationships this pattern has to these accessible policies patterns stem from its inherent compatibility with policy standardization, summarization, separation into layers and re-wording. Abridging a policy may support these aspects, or even entail them, though this pattern focuses on a specific kind of policy document. Were this pattern to have a broader context, it could even be considered an accessible policies pattern itself.\n\nThis pattern is also _complemented by_ the following:\n\n- _Explanation of Processes: The application shall inform users on demand about processes._\n- _Extras on Demand: \u201dShow the most important content up front, but hide the rest. Let the user reach it via a single, simple gesture.\u201d_ (Tidwell, 2005)\n\n#",
                "Sources": "H. Baraki et al., Towards Interdisciplinary Design Patterns for Ubiquitous Computing Applications. Kassel, Germany, 2014.\n\nJ. Tidwell, Designing interfaces. O\u2019Reilly Media, Inc., 2005."
            }
        },
        {
            "filename": "Active-broadcast-of-presence.html",
            "title": "Active broadcast of presence",
            "excerpt": "Users may actively choose to automatically provide updates when they want to share presence information, to increase both the relevance of, and control over, their sharing.",
            "sections": {
                "Context": "Controllers provide an interface for acquiring information about the user. When one such user wants to share or broadcast their information, such as location or other presence data, that user may want to constrain the information. In this way, they may wish to prioritize data that is contextually relevant, or avoid a full stream of data which may be either noisy or intrusive. The controller wants the user to be able to provide this data at will, to maximize the applicability of their services. However, they do not want the user to regret providing too much data, nor to bother the user with constant requests.",
                "Problem": "A service aims to acquire or broadcast a user's real-time data, particularly presence or location information, to a platform (e.g. social network). They wish to do so without revealing sensitive data (e.g. private locations, histories, or health information) nor overwhelming recipients with noisy data or users with constant requests.\n\n##",
                "Forces/Concerns": "- The controller wants to use the user's current data to provide more relevant information to the users of their service, but without violating the user's privacy.\n- The user wants to participate in the service and provide useful information, but not all information, as they consider some aspects more sensitive than others.\n- Users who intend to use the service do not want to have the service flooded with irrelevant data.",
                "Solution": "Allow the user to actively choose when to share information, whether to _broadcast_ it, and when not to. Assume that sharing settings do not apply holistically to all situations and seek clarification when in doubt.\n\n#",
                "Structure": "The service may present distinct contexts in which to honor explicit settings, but in absence of this context assume that further consent is required. The user may choose not be be asked again, but must make this decision explicit.\n\n#",
                "Implementation": "In addition to privacy settings with appropriate defaults, allow the user the option to be asked again, every time the context changes.\n\nBy default, users should actively choose to broadcast rather than the service deciding based on general settings which may not apply to the present context. Various contexts may be provided distinct settings.\n\nIn these situations users need only be reminded prior to setting the values themselves. After this, they may choose to be notified about broadcasting, but not about sharing with the service itself. In this way, the user may decide later.",
                "Examples": "#",
                "Known Uses": "- Foursquare check-in model prior to Pilgrim\n- Google services\n\n\n\n\n\n\n#",
                "Related Patterns": "Active broadcast of presence(Active-broadcast-of-presence) _complements_ Reasonable Level of Control(Reasonable-Level-of-Control), Masquerade(Masquerade), and Private link(Private-link). With Reasonable Level of Control(Reasonable-Level-of-Control), it can consider a larger audience with granular sharing choices. With Masquerade(Masquerade), it may make the audience more specific. Finally, with Private link(Private-link), the specific audience may be determined by whom is provided with the link. As such, it may not be as private.\n\nLike many patterns which affect user data, this pattern _must use_ Lawful Consent(Lawful-Consent).\n\n#",
                "Sources": "Based on:\n\nChung, E. S., Hong, J. I., Lin, J., Prabaker, M. K., Landay, J. a., & Liu, A. L. (2004). Development and Evaluation of Emerging Design Patterns for Ubiquitous Computing. DIS \u201904 Proceedings of the 5th Conference on Designing Interactive Systems: Processes, Practices, Methods, and Techniques, 233\u2013242. http://doi.org/10.1145/1013115.1013148\n\nBier, C., & Krempel, E. (2012). Common Privacy Patterns in Video Surveillance and Smart Energy. In ICCCT-2012 (pp. 610\u2013615). Karlsruhe, Germany: IEEE.\n\nDoty, N., Gupta, M., & Zych, J. (n.d.). PrivacyPatterns.org. Retrieved February 26, 2015, from http://privacypatterns.org/"
            }
        },
        {
            "filename": "Added-noise-measurement-obfuscation.html",
            "title": "Added-noise measurement obfuscation",
            "excerpt": "Add some noise to service operation measurements, but make it cancel itself in the long-term",
            "sections": {
                "Summary": "Add some noise to service operation measurements, but make it cancel itself in the long-term",
                "Context": "A service provider gets continuous measurements of a service attribute linked to a service individual.",
                "Problem": "The provision of a service may require repeated, detailed measurements of a service attribute linked to a data subject to e.g. properly bill them for the service usage, or adapt the service according to the demand load. However, these measurements may reveal further information (e.g. personal habits, etc.) when repeated over time.",
                "Solution": "A noise value is added to the true, measured value before it is transmitted to the service provider, so as to obfuscate it. The noise abides by a previously known distribution, so that the best estimation for the result of adding several measurements can be computed, while an adversary would not be able to infer the real value of any individual measurement. Note that the noise needs not be either additive or Gaussian. In fact, these may not be useful for privacy-oriented obfuscation. Scaling noise and additive Laplacian noise have proved more useful for privacy preservation.\n\n\nA service provider can get reliable measurements of service attributes to fulfil its operating requirements; however, no additional personal information can be inferred from the aggregation of several measurements coming from the same user.",
                "Consequences": "The pattern applies to any scenario where the use of a resource over time is being monitored (e.g. smart grid, cloud computing). The device providing the measurement must be trustworthy, in order to ensure that it abides by the established noise pattern.\n\nSome information is lost due to the noise added. This loss of information may prevent the information from being exploited for other purposes. This is partly an intended consequence (e.g. avoid discovering user habits), but it may also preclude other legitimate uses.\n\nIn order for information to be useful after noise addition, the number of data points over which measurements are aggregated (i.e. the size of the aggregated user base) needs to be high; otherwise, either the confidence interval would be too broad or differential privacy could not be effectively achieved.\n\n#",
                "Constraints": "The pattern applies to any scenario where the use of a resource over time is being monitored (e.g. smart grid, cloud computing). The device providing the measurement must be trustworthy, in order to ensure that it abides by the established noise pattern.\n\nSome information is lost due to the noise added. This loss of information may prevent the information from being exploited for other purposes. This is partly an intended consequence (e.g. avoid discovering user habits), but it may also preclude other legitimate uses.\n\nIn order for information to be useful after noise addition, the number of data points over which measurements are aggregated (i.e. the size of the aggregated user base) needs to be high; otherwise, either the confidence interval would be too broad or differential privacy could not be effectively achieved.",
                "Examples": "An electric utility operates a smart grid network with smart meters that provide measurements of the instantaneous power consumption of each user. The utility employs that information to both adapt the power distribution in a dynamic fashion, according to user demand at each moment, and bill the each client periodically, according to his aggregated consumption over the billing period. However, this information can also be exploited to infer sensitive user information (e.g. at what time he or she leaves and comes back to home, etc.)\n\n#",
                "Known Uses": "- Bohli, J.-M.; Sorge, C.; Ugus, O., \"A Privacy Model for Smart Metering,\" Communications Workshops (ICC), 2010 IEEE International Conference on , vol., no., pp.1,5, 23-27 May 2010\n- Xuebin Ren; Xinyu Yang; Jie Lin; Qingyu Yang; Wei Yu, \"On Scaling Perturbation Based Privacy-Preserving Schemes in Smart Metering Systems,\" Computer Communications and Networks (ICCCN), 2013 22nd International Conference on , vol., no., pp.1,7, July 30 2013-Aug. 2 2013\n- Mivule, K. (2013). Utilizing noise addition for data privacy, an overview. arXiv preprint arXiv:1309.3958."
            }
        },
        {
            "filename": "Aggregation-gateway.html",
            "title": "Aggregation Gateway",
            "excerpt": "Encrypt, aggregate and decrypt at different places.",
            "sections": {
                "Summary": "Encrypt, aggregate and decrypt at different places.",
                "Context": "A service provider gets continuous measurements of a service attribute linked to a set of individual service users.",
                "Problem": "The provision of a service may require detailed measurements of a service attribute linked to a data subject to adapt the service operation at each moment according to the demand load. However, these measurements may reveal further information (e.g. personal habits, etc.) when repeated over time.",
                "Solution": "A homomorphic encryption (e.g. Paillier) is applied at the metering system, using a secret shared with the service provider (generated by applying e.g. Shamir\u2019s Secret Sharing Scheme)\n    The encrypted measurements from a group of users are transmitted to an independent yet trusted third party. This third-party cannot know about the content of each measurement (as it is encrypted), but it can still operate on that data in an encrypted form (as the encryption system is homomorphic). There are different trusted third parties for each group of users. In order to improve the privacy resilience, each user may belong to several groups at the same time.\n    The trusted third-party aggregates the measurements from all the users in the same group, without accessing the data in the clear at any time.\n    The service provider receives the encrypted, aggregated measurement and decrypts it with the shared secret.\n\nA feeder metering system can be added as a measuring rod which introduces a comparison for each group of meters.\n\n\nLet the service provider have reliable access to the aggregated load at every moment, so as to fulfil its operating requirements, without letting it access the individual load required from each specific service user.",
                "Consequences": "There is a need to deploy trusted third parties that compute the aggregations over each group of users. Note that they need to be honest (i.e., they cannot collude with the other parties involved), but they need not respect confidentiality (as they only have access to encrypted contents). Smart meters are needed that have computation resources to apply secret generation and homomorphic encryption procedures (note that this is trivial when dealing with the use of computational resources, but it does not have to be always available in the case of e.g. smart grid systems). The potential range of measured values must be large enough to avoid brute force attacks. Robust homomorphic encryption schemes introduce a large computational load.",
                "Examples": "An electric utility operates a smart grid network with smart meters that provide measurements of the instantaneous power consumption of each user. The utility employs that information to adapt the power distribution in a dynamic fashion, according to the user demand at each moment.\n\n#",
                "Known Uses": "- Lu, R., Liang, X., Li, X., Lin, X., & Shen, X. (2012). Eppa: An efficient and privacy-preserving aggregation scheme for secure smart grid communications.Parallel and Distributed Systems, IEEE Transactions on, 23(9), 1621-1631.\n- Rottondi, C., Verticale, G., & Capone, A. (2013). Privacy-preserving smart metering with multiple data consumers. Computer Networks, 57(7), 1699-1713.\n- Kursawe, K., Danezis, G., & Kohlweiss, M. (2011, January). Privacy-friendly aggregation for the smart-grid. In Privacy Enhancing Technologies (pp. 175-191). Springer Berlin Heidelberg."
            }
        },
        {
            "filename": "Ambient-notice.html",
            "title": "Ambient Notice",
            "excerpt": "Provide unobtrusive, non-modal, continuous notice when personal data is being accessed to increase awareness of real-time tracking.",
            "sections": {
                "Also Known As": "Instant User Interface for Information (about PII) / Talking Collector / On the Spot Information",
                "Context": "Modern sensor systems process massive quantities of data, performing complex and silent operations which users typically overlook. The tracking of user information is used to improve the quality of these services (or products), and typically users wish to benefit from this. This is particularly evident in consumption, location, and physical activity tracking. While these users do not want to be exposed to extensive and otherwise intimidating details, this processing must be done under the user's informed and explicit consent. Once the consent for it has been obtained,  processing may occur regularly or in real-time. While users are to be informed of this, in-progress readings still happen in a manner which is streamlined and not inherently noticeable. Users are also capable of forgetting some time after consent was given.",
                "Problem": "Users are frequently unaware of the sensors currently tracking them. It is important that they understand that their personal data is being further collected in order for their informed consent to remain valid. This should be unobtrusive, however, so as to avoid notification fatigue or desensitization.\n\n_A user may not realize that an application given permission to access sensor data is doing so continuously or repeatedly, or may not remember that explicit permissions given in the past allow a service to access data again later. In some cases, past explicit permission may not have been provided by the current user of the device (but instead by a spouse, parent or even an ex-spouse or stalker who temporarily had control of the device or the account). If notice is provided only at the time of consent, a user may inadvertently distribute personal information over a long period of time after having lost control of their device only momentarily._\n\n##",
                "Forces and Concerns": "- Users are capable of forgetting or reconsidering their consent, affecting the legitimacy of any processing under it\n- Users may overlook processing which is not made apparent to them, allowing sensors to record data they would not otherwise\n- Controllers aim to ensure that consent is retained, they want to avoid collecting data against the user's wishes\n- Controllers want to prevent users from inadvertently sharing personal data which they regret being processed\n\n_A tray full of ambient notices may annoy or confuse users and inure them to ongoing practices. Take measures to avoid unnecessary notice. This must be balanced against the\nconcerns of an attacker's opting the user in without their knowledge._",
                "Solution": "Provide an unobtrusive but clearly visible notification while sensors are in use, without interrupting the flow of user activity. This notification should be interactive in order to prevent, delay, or further explain the data collection.\n\n\n\n\n\n\n#",
                "Implementation": "_The best place to provide transparency is the place where data is collected. The sensor is the first component noticed of a complex system, because the user is directly confronted with the sensor during collection. Hence, provided information in this place is easier to access by the user. Because of that, sensors should be equipped with a user interface for instant check of the collected data. Such an interface can consist of a simple display or message box. In more complex environments, optical codes and links can refer the user to more elaborated information sources._",
                "Examples": "* _**Location services icons: Mac OS X, Google Chrome, et al.**_\n\n!Lion Location Icon(/media/images/lion_location_icon.png)\n\n_Mac OS X Lion adds an ambient location services icon (a compass arrow) which appears in the task bar momentarily when an application is accessing the device's location._\n\n!Chrome Location Icon(/media/images/chrome_location_icon.png)\n\n_Chrome adds a cross-hair icon to the location bar when a web site accesses the device location via the W3C Geolocation API. Clicking on the icon provides potential actions: clearing the saved consent for this site and accessing settings._\n\n_Similar examples exist in at least Android, iOS and Windows._\n\n#",
                "Known Uses": "_QR-code based information access, smart meter display_\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern is an _alternative_ to Asynchronous Notice(Asynchronous-notice). While this pattern aims at non-intrusive and ongoing notification, the Asynchronous variant focuses on obtrusive and unavoidable notifications. As such it must be used more sparingly.\n\nThis pattern _complements_ Informed Implicit Consent(Informed-Implicit-Consent) and Single Point of Contact(Single-Point-of-Contact)(SPoC). Implicit consent is shown by the Ambient Notice, reminding the user of the system's assumption that their consent has not been retracted. A SPoC is an authority which validates requests and ensures secure and private communication, a usage of data which can be persistently displayed to remind the user of its (de)activation.\n\nThis pattern _refines_ Preventing Mistakes or Reducing Their Impact(Preventing-Mistakes-or-Reducing-Their-Impact). As it provides ongoing notice of data collection, a user is prevented from mistakenly producing data, or better has a good chance to cease doing so before having an impact. As an implicit relationship through Preventing Mistakes or Reducing Their Impact(Preventing-Mistakes-or-Reducing-Their-Impact), this pattern also _complements_ Impactful Information and Feedback(Impactful-Information-and-Feedback). However, in order to do so, the implementation must allow for a potentially indefinite delay, as the notification will not be modal.\n\n\n#",
                "Sources": "N. Doty, M. Gupta, and J. Zych, \u201cprivacypatterns.org - Privacy Patterns,\u201d privacypatterns.org, 2017. Online. Available: http://privacypatterns.org/. Accessed: 26-Feb-2015.\n\nC. Bier and E. Krempel, \u201cCommon Privacy Patterns in Video Surveillance and Smart Energy,\u201d in ICCCT-2012, 2012, pp. 610\u2013615.\n\nJ. Siljee, \u201cPrivacy transparency patterns,\u201d in EuroPLoP \u201915, 2015, pp. 1\u201311."
            }
        },
        {
            "filename": "Anonymity-set.html",
            "title": "Anonymity Set",
            "excerpt": "This pattern aggregates multiple entities into a set, such that they cannot be distinguished anymore.",
            "sections": {
                "Summary": "This pattern aggregates multiple entities into a set, such that they\ncannot be distinguished anymore.",
                "Context": "This pattern is applicable in a messaging scenario, where an attacker\ncan track routing information. Another possible scenario would be the\nstorage of personal information in a database.",
                "Problem": "In a system with different users we have the problem that we can often\ndistinguish between them. This enables location tracking, analyzing\nthe behaviour of the users or other privacy-infringing practices.",
                "Solution": "There are multiple ways to apply this pattern. One possibility is, to\nstrip away any distinguishing features from the entities. If we do not\nhave enough entities, such that the anonymity set would be too small,\nthen we could even insert fake identities.\n\n\nThe goal of this pattern is to aggregate different entities into a\nset, such that distinguishing between them becomes infeasible.",
                "Consequences": "One factor to keep in mind is that this pattern is useless if there\nare not many entities, such that the set of probable suspects is too\nsmall. What \"too small\" means depends on the exact scenario. Another\nfactor is a possible loss of functionality.",
                "Examples": "Assuming that there are two companies, one is a treatment clinic for\ncancer and the other one a laboratory for research. The Clinic\nreleases its Protected Health Information (PHI) about cancer victims\nto the laboratory. The PHI's consists of the patients' name, birth\ndate, sex, zip code and diagnostics record. The clinic releases the\ndatasets without the name of the patients, to protect their privacy. A\nmalicious worker at the laboratory for research wants to make use of\nthis information and recovers the names of the patients. The worker\ngoes to the city council of a certain area to get a voter list from\nthem. The two lists are matched for age, sex and location. The worker\nfinds the name and address information from the voter registration\ndata and the health information from the patient health data.\n\n#",
                "Known Uses": "Anonymity sets are in use in various routing obfuscation mechanisms\nlike Onion Routing. Hordes is a multicast-based protocol that makes\nuse of multicast routing like point-to-multipoint delivery, so that\nanonymity is provided. Mix Zone is a location-aware application that\nanonymizes user identity by limiting the positions where users can be\nlocated."
            }
        },
        {
            "filename": "Anonymous-reputation-based-blacklisting.html",
            "title": "Anonymous Reputation-based Blacklisting",
            "excerpt": "Get rid of troublemakers without even knowing who they are.",
            "sections": {
                "Summary": "Get rid of troublemakers without even knowing who they are.",
                "Context": "A service provider provides a service to users who access anonymously, and who may make bad use of the service.",
                "Problem": "Anonymity is a desirable property from the perspective of privacy. However, anonymity may foster misbehaviour, as users lack any fear of retribution.\n\nA service provider can assign a reputation score to its users, based on their interactions with the service. Those who misbehave earn a bad reputation, and they are eventually added to a black list and banned from using the service anymore. However, these scoring systems traditionally require the user identity to be disclosed and linked to their reputation score, hence they conflict with anonymity. This has made, for instance, Wikipedia administrators to take the decision to ban edition requests coming from the TOR network, , as they cannot properly identify users who misbehave.\n\nA Trusted Third Party (TTP) might be introduced in between the user and the service provider. The TTP can receive reputation scores from the service provider so as to enforce reputation-based access policies, while keeping the identity hidden from the service provider. However, this would require the user to trust the TTP not to be a whistle-blower indeed.\n\nHow can we make users accountable for their actions while keeping them anonymous?",
                "Solution": "First, the service provider provides their users with credentials for anonymous authentication.\n\nThen, every time an authenticated user holds a session at the service, the service provider assigns and records a reputation value for that session, depending on the user behaviour during the session. Note that these reputation values can only be linked to a specific session, but not to a specific user (as they have authenticated anonymously).\n\nWhen the user comes back and starts a new session at the service, the service provider challenges the user to prove in zero-knowledge that he is not linked to any of the offending sessions (those that have a negative reputation associated). Zero-knowledge proofs allow the user to prove this, without revealing their identity to the service provider. Different, alternative proofs have been proposed, e.g. prove that the user is not linked to any of the sessions in a set of session IDs, prove that the last K sessions of the user have good reputation, etc.\n\nIn practice, more complex blacklisting rules can be applied as well. For instance, several reputation scores can be assigned to the same session, each regarding different facets of the user behaviour. Then, the blacklisting thresholds may take the form of a Boolean combination or a lineal combination over individual session and facet reputation values.\n\n\nA service provider wants to prevent users who misbehave from accessing the service anymore, without gaining access to their identity.",
                "Consequences": "Different implementations may only be practical for services with a reduce number of users, require intense computations, limit the scope of the reputation to a constrained time frame, be vulnerable to Sybil attacks, etc. Nonetheless, protocols are being improved to overcome these and other issues. See the cited sources below for the specific discussion.",
                "Examples": "A wiki allows any visitor to modify its contents, even without having been authenticated. Some malicious visitors may vandalize the contents. This fact is signalled by the wiki administrators. If a visitor coming from the same IP address keeps vandalizing the site, they will earn a bad reputation, and their IP will be banned from modifying the contents anymore. However, users accessing through a Tor anonymity network proxy cannot be identified from their IPs, and thus their reputation cannot be tracked.\n\n#",
                "Known Uses": "- Au, M. H., Kapadia, A., & Susilo, W. (2012). BLACR: TTP-free blacklistable anonymous credentials with reputation.\n- Au, M. H., & Kapadia, A. (2012, October). PERM: Practical reputation-based blacklisting without TTPs. In Proceedings of the 2012 ACM conference on Computer and communications security (pp. 929-940). ACM."
            }
        },
        {
            "filename": "Appropriate-Privacy-Feedback.html",
            "title": "Appropriate Privacy Feedback",
            "excerpt": "Supplies the user with privacy feedback, especially concerning that which is monitored and accessed, and by whom.",
            "sections": {
                "Also Known As": "Notification on Access of Personal Data",
                "Context": "Users are frequently unaware or unsure about what personal data systems collect and otherwise process. When systems fade into the background users are less likely to take notice and adjust what information is collected. Data controllers who provide services (or products) to such users realize that consent is not valid without users first being sufficiently informed. They aim to do so in a manner which is appropriate for the service.\n\nThe controller may have relied on op-out mechanics, but now realizes that within the European General Data Protection Regulation (recital 32) 'silence, pre-ticked boxes or inactivity' no longer constitute consent. Unnecessarily disruptive notice is also not permitted.\n\nThe controller may already consider Fair Information Practices, and have an accessible privacy policy. They may also implement Respecting Social Organizations(Respecting-Social-Organizations) and Building Trust and Credibility(Building-Trust-and-Credibility). However, their service is not immediately obvious to the user when in use.",
                "Problem": "Many systems are designed to be seamless or ubiquitous. However, this can make personal data risks less apparent to the user.\n\nAs a result users may overlook services without fulling understanding the privacy risks involved. Potentially, these users may realize consequences long after, or worse, not realize them at all.\n\n##",
                "Forces/Concerns": "- Controllers want systems to do their tasks in the background without bothering the user, but need the user's informed consent\n- Controllers often do not want to process data which users feel uncomfortable about, but uninformed users may provide it\n- Users want to get the benefits of a service without having to interact with it, and may not do so at all if they do not have to\n- There are users who would avoid these services if they were aware of the privacy risks",
                "Solution": "Visible feedback loops, which capture the user's attention, are needed to help ensure that users understand what data is being collected, who can see that data, and how might it be used.\n\n\n\n\n\n\n#",
                "Implementation": "Notification should occur before access where possible, and during or shortly after access if earlier notification is not appropriate. In most cases this means preventing a user's use of a service before allowing the core functionality of the service to run at all. Where some features with variable privacy implications are not essential to the service, they may be provided as optional, defaulting to being disabled.\n\nUsers should be informed appropriately, providing both concise and understandable explanations of the personal data acquired, and warnings of the risks involved. The service should make a best effort to ensure that the user understands the implications of consent before commencing or resuming functionality. An effort should also be made to make these notifications non-invasive. Using Ambient(Ambient-notice) or Asynchronous Notice(Asynchronous-notice) is one way to achieve this.\n\nWhere users choose to be notified less immediately or less often, and after being warned of the risks involved, then the service may store logs of its privacy affecting activities. The user should then be able to retrieve these logs, in a human readable form, at will. As only the user should be able to access these, unless said user provides informed consent otherwise, it should also be secured. Use state of the art means of encryption to do this. If this functionality cannot be done in this manner, due to technical constraints for example, then do not provide logging functionality.",
                "Consequences": "The user will be informed before using a service, which will cause the user to be more careful according to their personal privacy preference. Those who find the service too invasive will not use it, or provide feedback towards its improvement. The service will not be liable for user activities where it has informed them of the risks those activities involve.\n\n#",
                "Constraints": "Preventing functionality until consent is acquired lessens the feasibility of various services. However, doing otherwise presents risks of high financial and good-will damages.\n\n# Examples\n\n\nWhen you share some content on Facebook, it sometimes asks you to review your fundamental privacy settings. In the short tour given, you can see what data is accessed by other users or by third party applications.\n\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern is a component of the compound pattern, Awareness Feed(Awareness-Feed). As such, this pattern _may be used_ by it.\n\nThis pattern _complements_ Privacy Awareness Panel(Privacy-Awareness-Panel), Who's Listening(Whos-Listening), Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides), and Increasing Awareness of Information Aggregation(Increasing-Awareness-of-Information-Aggregation).\n\nPrivacy Awareness Panel(Privacy-Awareness-Panel) provides the same information (what, who, and how) as this pattern, while using different mechanisms. Together these patterns cover future, present, and past disclosure. While this could be a _similar_ relationship, complementary aspects are also present. Similar to Privacy Awareness Panel(Privacy-Awareness-Panel), the complementary relationship with Who's Listening(Whos-Listening) allows for monitoring of access in a more holistic manner.\n\nTrust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides) provides visual highlights which alert the user to the estimated trustworthiness of a service. This functionality goes well with the aim to provide the user with useful feedback on risks to their privacy. Together, these patterns can illuminate the trustworthiness of entities which access the user's data, especially third parties.\n\nIncreasing Awareness of Information Aggregation(Increasing-Awareness-of-Information-Aggregation) aims to solve a different problem, though it may help future disclosure decisions through knowledge of its potential sensitivity when aggregated.\n\nFor ensuring the feedback provided is accurate and actionable, this pattern also _complements_ Privacy Sensitive Architectures(Privacy-Sensitive-Architectures) and Reasonable Level of Control(Reasonable-Level-of-Control).\n\nAppropriate Privacy Feedback _may be used_ by Privacy Mirrors(Privacy-Mirrors) as a means to provide feedback on personal data usage. Privacy Dashboard(Privacy-dashboard) also _may use_ it, as it empowers users to act on detail they have been drawn attention to. Notification may also be facilitated through _using_ Ambient(Ambient-notice) or Asynchronous Notice(Asynchronous-notice) to reduce intrusiveness.\n\n#",
                "Sources": "E. S. Chung, J. I. Hong, J. Lin, M. K. Prabaker, J. a. Landay, and A. L. Liu, \u201cDevelopment and Evaluation of Emerging Design Patterns for Ubiquitous Computing,\u201d DIS \u201904 Proceedings of the 5th conference on Designing interactive systems: processes, practices, methods, and techniques, pp. 233\u2013242, 2004.\n\nH. Baraki et al., Towards Interdisciplinary Design Patterns for Ubiquitous Computing Applications. Kassel, Germany, 2014.\n\nG. Iachello and J. Hong, \u201cEnd-User Privacy in Human-Computer Interaction,\u201d Foundations and Trends\u00ae in Human-Computer Interaction, vol. 1, no. 1, pp. 1\u2013137, 2007."
            }
        },
        {
            "filename": "Appropriate-Privacy-Icons.html",
            "title": "Appropriate Privacy Icons",
            "excerpt": "Use consistent icons in place of policy aspects. The icons should convey these aspects reliably, without allowing room for misinterpretation once explained to the user.",
            "sections": {
                "Also Known As": "Privacy Icons",
                "Context": "Controllers offering services (or products) to users have various policies regarding privacy. These typically exist within one document catering to legal evaluation, and thus one which is quite long and complex. Users are often encouraged to read such a policy, though as users are exposed to many of these, they mostly do not. As a countermeasure to this, controllers partition their policies, provide simplified versions, or bring relevant aspects to user attention when needed. One method of simplification is the use of privacy icons. This approach has its own issues for controllers to consider.",
                "Problem": "Privacy icons are easily misunderstood, as they are oversimplified concepts using imagery shared with numerous other concepts. Even when fully grasped, important information may be overlooked when finer details play a role.\n\n##",
                "Forces and Concerns": "- Users do not want to regularly read long and complex policies\n- Users want to understand what risks their data undergoes by using certain features of the service\n- Controllers want users to actually take note of the relevant policies rather than process their data without informed consent\n- Controllers want to save space so that they can have more appealing interfaces",
                "Solution": "Introduce the user to a consistent set of icons, carefully grouped and not excessive, and explain their meaning. Explanations should be short and concise, and these paired with the icons should be put through user tests. Users should be able to understand the icons when shown them in context.\n\nWhile these icons should be able to stand alone, it is still important that a user has access to clarification. As such provide a mechanism, such as an on hover tooltip, which further explains what the icon attempts to convey. The icon should also be machine readable.\n\n\n\n\n\n\n#",
                "Implementation": "When selecting appropriate icons for conveying information, take the following into account:\n\n- primarily prevent misunderstanding,\n- use icons users are familiar with,\n- do not reassign meaning to familiar icons, and\n- keep icon style and design consistent.\n\nPerform tests with actual users to determine whether there is any room for misunderstanding and adjust accordingly with further tests. If a concept cannot be reliably conveyed through an icon then it must not be primarily provided as one.\n\nRegardless of whether an icon perfectly conveys a policy, always allow users to investigate further. This can be achieved through hover, click or tap mechanisms. A tooltip, for example can provide a short explanation, but the full policy being depicted should also be available. As such, a context menu may also be appropriate, especially on single tap for mobile users.",
                "Consequences": "_Informed users are able to make informed decisions which lead to a more responsible handling of private information. Since icons are an integral part of any kind of interface, it is important that they convey the right information. Furthermore users are only able to use a service to its full extent when they trust it._ This effort towards transparency will assist in creating that trust.",
                "Examples": "- _The current version of the European Union's forthcoming General Data Protection Regulation includes a set of privacy icons that should be used within services which affect citizens in the EU, and by controllers who operate within the EU._\n- _https://disconnect.me/icons_ <br><img width=200 src=\"https://s3.amazonaws.com/images.disconnect.me/images/privacy_icons/how-privacy-icons-work-2-2x.png\"/>\n- _https://wiki.mozilla.org/Privacy_Icons_ <br>!Retention(https://wiki.mozilla.org/images/e/eb/Retention_3months.png) !3rd-party(https://wiki.mozilla.org/images/2/2e/Intended_thirdparty.png) !No-ad-share(https://wiki.mozilla.org/images/5/5a/Noshare_ads.png) !Statutory(https://wiki.mozilla.org/images/e/e8/Statutory_law.png)\n- Yle.edu privacy icons at the Internet Archive(https://web.archive.org/web/20151024095327/http://yale.edu:80/self/psicons.html)\n- Privacy Bird policy matching icons(http://www.privacybird.org/tour/1_3_beta/tour.html)\n- _https://netzpolitik.org/2007/iconset-fuer-datenschutzerklaerungen/_ <br>!icons from netzpolitik(https://cdn.netzpolitik.org/wp-upload/data-privacy-icons-v01.jpg)\n- _http://knowprivacy.org/policies_methodology.html_\n!KnowPrivacy.org Icons(http://knowprivacy.org/images/iconset.png)\n- _http://www.privicons.org/_ !dont-attribute(http://privicons.org/files/gimgs/dont-attribute.png) !dont-print(http://privicons.org/files/gimgs/dont-print.png) !delete-after(http://privicons.org/files/gimgs/delete-after.png) !keep-internal(http://privicons.org/files/gimgs/keep-internal.png) !please-share(http://privicons.org/files/gimgs/please-share.png) !keep-secret(http://privicons.org/files/gimgs/keep-secret.png)\n- _The EU-funded PrimeLife project also proposed a set of privacy icons_\n- _The Use of Privacy Icons and Standard Contract Terms for Generating Consumer Trust and Confidence in Digital Services CREATe Working Paper 2014/15 (October 2014)_\n\n_Currently, most of these are only applied by client-side solutions._",
                "See Also": "Recital 60 as well as Art. 12(7) of the General Data Protection Regulation suggests the use of standardized icons, informing users in an _easily visible, intelligible and clearly legible manner_.\n\n#",
                "Related Patterns": "This pattern _complements_ Impactful Information and Feedback(Impactful-Information-and-Feedback), Informed Secure Passwords(Informed-Secure-Passwords), Layered Policy Design(Layered-policy-design), Privacy Aware Wording(Privacy-Aware-Wording), Privacy-Aware Network Client(Privacy-aware-network-client), and Awareness Feed(Awareness-Feed). It also implicitly _complements_ Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides) through Awareness Feed(Awareness-Feed).\n\nAs a visual cue, this pattern aids in providing Impactful Information and Feedback(Impactful-Information-and-Feedback) by augmenting it with quickly interpreted information. These visual cues additionally help towards Informed Secure Passwords(Informed-Secure-Passwords), as they may indicate password strength and policy.\n\nVisual cues like this pattern also aid in providing accessible policies, and thus _complement_ Layered Policy Design(Layered-policy-design), Privacy Aware Wording(Privacy-Aware-Wording), and Privacy-Aware Network Client(Privacy-aware-network-client).\n\nLike many patterns which inform users, elements of Awareness Feed(Awareness-Feed) and its methods for establishing awareness also go well with visual cues like this pattern. It also implicitly aids Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides), which provides visual representation to highlight trust levels to the user.\n\nThis pattern is _led to_ from Icons for Privacy Policies(Icons-for-Privacy-Policies). While this pattern explains how privacy icons may be misused and proposes how to use them appropriately, Icons for Privacy Policies(Icons-for-Privacy-Policies) encourages their usage in the first place to describe a privacy policy. That usage is prone to pitfalls which this pattern addresses.\n\n#",
                "Sources": "S. Fischer-H\u00fcbner, C. K\u00f6ffel, J.-S. Pettersson, P. Wolkerstorfer, C. Graf, L. E. Holtz, U. K\u00f6nig, H. Hedbom, and B. Kellermann, \u201cHCI Pattern Collection - Version 2,\u201d 2010.\n\nC. Graf, P. Wolkerstorfer, A. Geven, and M. Tscheligi, \u201cA Pattern Collection for Privacy Enhancing Technology,\u201d The Second International Conferences of Pervasive Patterns and Applications, vol. 2, no. 1, pp. 72\u201377, 2010.\n\nHoltz, L. E., Zwingelberg, H., & Hansen, M. (2011). Privacy policy icons. In Privacy and Identity Management for Life, pp. 279-285.\n\nHeidelberg and Holtz, L. E., Nocun, K., & Hansen, M. (2011). Towards displaying privacy information with icons. In Privacy and Identity Management for Life (pp. 338-348). Springer Berlin Heidelberg.\n\nEuropean Parliament and Council of the European Union, \u201cGeneral Data Protection Regulation,\u201d Official Journal of the European Union, 2015."
            }
        },
        {
            "filename": "Asynchronous-notice.html",
            "title": "Asynchronous notice",
            "excerpt": "Proactively provide continual, recurring notice to consented users of repeating access to their personal data, including tracking, storage, or redistribution.",
            "sections": {
                "Context": "Many sensor related or other recurring forms of data collection are important for improving service (or product) quality, but occur in a manner which is not apparent to the user. Even where the user is informed of such processing, the nature of that processing may cause it to occur within contexts the user would not consent to. Users are also subject to forgetfulness. The controller processing this information therefore seeks to ensure that consent is retained. Some interfaces necessitate more restrictive use of screen real estate, however, and as such can not accommodate extensive information or persistent elements.",
                "Problem": "Users being tracked and monitored may not consent to processing they had previously consented to, as the context surrounding that processing is subject to change.\n\n_Also, initial consent may have been forged by an attacker or have been provided by another user of a shared device -- if synchronous notice is only provided at the time of consent, a user may inadvertently distribute personal information over a long period of time after having lost control of their device only momentarily._\n\n##",
                "Forces and Concerns": "- Users may change their minds or forget about consent they have given\n- Users may not realize the processing they consented to is currently in effect, potentially allowing collection of information they would not want collected\n- Controllers do not want to collect data for which consent is uncertain, where users may feel violated or otherwise let down\n- Controllers cannot remind users of their consent all the time\n\n\n_Providing an asynchronous notice requires a reliable mechanism to contact the user (a verified email address or telephone number, for example). Care should be taken to ensure that the mechanism can actually reach the person using the device being tracked. (For example, notifying the owner of the billing credit card may not help the spouse whose location is being surreptitiously tracked.)_\n\n_In contrast to the common privacy practice of providing consistent and reliable systems, you may wish to provide **random** asynchronous notice. If there is a concern that a malicious user may have opted-in the user without their knowledge, a notice that is sent once a week at the same time each week may allow the attacker to borrow the device at the appointed time and clear the notice._\n\n_Many repeated notices may annoy users and eventually inure them to the practice altogether. Take measures to avoid unnecessary notices and some level of configuration for frequency of notices. This must be balanced against the concerns of an attacker's opting the user in without their knowledge._",
                "Solution": "Whenever there is a context switch, sufficient duration, or random spot check, provide users with a simple reminder that they have consented to specific processing. The triggers and means for contacting the user may be chosen by the user themselves, who should be able to review and if necessary retract their consent.\n\n\n\n\n\n\n#",
                "Implementation": "Implementation depends on the medium chosen for conveying the notification, and also on the service facilitating collection. For mediums with less space, shorter messages should be provided, but even in more traditionally long-winded options such as email, brevity should be favored. The user should be able to obtain more information by a linking mechanism, also dependent on the medium. The most important information to provide is the fact that they have consented to specific data for specified purposes, and that a context change, spot check, or specified duration has triggered the reminder. Context changes are most notable, as these are most likely to affect the consent. Note that changes to purposes and means instead require new consent, not merely notification.\n\n_Asynchronous notices may also include a summary of the data recently collected (since the last notice, say) in order to provide clarity (and reminders) to the user about the extent of collection. By ensuring that users aren't surprised, asynchronous notice may increase trust in the service and comfort with continued disclosure of information._",
                "Examples": "1. _**Google Latitude reminder email**_\n\n   _Google Latitude users can configure a reminder email (see below) when their location is being shared with any application, including internal applications like the Location History service._\n\n   <hr>This is a reminder that you are sharing your Latitude location with the following application(s):\n\n   **Google Location History**\n   You may disable these applications at any time by going to <https://www.google.com/latitude/apps?hl=en]>\n\n   **Do more with Latitude**\n   Go to <https://www.google.com/latitude/apps> on your computer and try the following:\n\n   Google Location History lets you store your history and see a dashboard of interesting information such as frequently visited places and recent trips.\n   Google Talk Location Status lets you post your location in your chat status.\n   Google Public Location Badge lets you publish your location on your blog or site.\n\n   You are receiving this reminder once a week. To change your reminder settings, go to: <https://www.google.com/latitude/apps?hl=en&tab=privacyreminders><hr>\n\n2. _**Fire Eagle My Alerts**_\n\n   !Fire Eagle My Alerts configuration by npdoty, on Flickr(http://farm6.static.flickr.com/5001/5642647032_e74e815f6a.jpg)\n   Fire Eagle My Alerts configuration by npdoty, on Flickr(http://www.flickr.com/photos/npdoty/5642647032])\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _refines_ Preventing Mistakes or Reducing Their Impact(Preventing-Mistakes-or-Reducing-Their-Impact). As it provides notice of noteworthy processing when in context, a user is prevented from mistakenly producing data. As the notification is obtrusive, they are given every chance to cease doing so before it has an impact. As an implicit relationship through Preventing Mistakes or Reducing Their Impact(Preventing-Mistakes-or-Reducing-Their-Impact), this pattern also _complements_ Impactful Information and Feedback(Impactful-Information-and-Feedback).\n\nThis pattern is an _alternative_ to Ambient Notice(Ambient-notice). While this pattern provides contextually justified notice whenever necessary, the Ambient variant does so persistently and without contextual justification. Unlike this pattern, Ambient Notice(Ambient-notice) is unobtrusive.\n\nThis pattern _complements_ Single Point of Contact(Single-Point-of-Contact). A SPoC is an authority which validates requests and ensures secure and private communication, a usage of data which can be contextually displayed to remind the user of its (de)activation.\n\n#",
                "Sources": "N. Doty, M. Gupta, and J. Zych, \u201cprivacypatterns.org - Privacy Patterns,\u201d privacypatterns.org, 2017. Online. Available: http://privacypatterns.org/. Accessed: 26-Feb-2015.\n\nC. Bier and E. Krempel, \u201cCommon Privacy Patterns in Video Surveillance and Smart Energy,\u201d in ICCCT-2012, 2012, pp. 610\u2013615.\n\nE. S. Chung, J. I. Hong, J. Lin, M. K. Prabaker, J. a. Landay, and A. L. Liu, \u201cDevelopment and Evaluation of Emerging Design Patterns for Ubiquitous Computing,\u201d DIS \u201904 Proceedings of the 5th conference on Designing interactive systems: processes, practices, methods, and techniques, pp. 233\u2013242, 2004.\n\nJ. Siljee, \u201cPrivacy transparency patterns,\u201d in EuroPLoP \u201915, 2015, pp. 1\u201311."
            }
        },
        {
            "filename": "Attribute-based-credentials.html",
            "title": "Attribute Based Credentials",
            "excerpt": "Attribute Based Credentials (ABC) are a form of authentication mechanism that allows to flexibly and selectively authenticate different attributes about an entity without revealing additional information about the entity (zero-knowledge property).",
            "sections": {
                "Summary": "Attribute Based Credentials (ABC) are a form of authentication mechanism that allows to flexibly and selectively authenticate different attributes about an entity without revealing additional information about the entity (zero-knowledge property).",
                "Context": "ABC can be used in a variety of systems including Internet and smart cards.",
                "Problem": "Authentication of attributes classically requires full and unique authentication of an entity. For example, attributes (like age) could be put into a certificate together with name of the user, email address, public key, and other data about that entity. To corroborate an attribute (for example, that the user is an adult) the certificate has to be presented and all information have to be revealed. This is not considered a privacy-preserving solution.",
                "Solution": "There are multiple schemes to realize ABCs and implementations are also available. They typically all include a managing entity that entitles issuers to issue credentials to entities that could then act as provers of certain facts about the credentials towards verifiers.\n\nA formal model can be found here.\n\n\nTo allow a user to selectively prove specific attributes like age > 18 to a verifying party without revealing any additional information.",
                "Consequences": "ABC schemes require substantial compute power or optimization, so implementation may not be straightforward. Some projects like IRMA developed at Radboud University Nijmegen have shown that even resource restricted devices like smartcards can implement ABCs.",
                "Examples": "You want to issue an ID card that holds a users birthdate bd and can be used to prove that the card holder is old enough to view age-restricted movies in a cinema. Depending on the rating of the movie (minimum age x), the card holder can run a proof that:\n\n\"today - bd > x\"\n\nMultiple uses of the card at the same cinema should not be linkable.\n\n#",
                "Known Uses": "The most popular implementations include:\n\n- IBM's IDEMIX developed as part of the PRIME/PRIMELIFE project.\n- Microsoft's U-Prove.\n- Radboud University Nijmegen's IRMA project."
            }
        },
        {
            "filename": "Awareness-Feed.html",
            "title": "Awareness Feed",
            "excerpt": "Users need to be informed about how visible data about them is, and what may be derived from that data. This allows them to reconsider what they are comfortable about sharing, and take action if desired.",
            "sections": {
                "Summary": "An Awareness Feed warns the user about the potential consequences of sharing their personal data. It does so before that data is collected or used, and continues to do so whenever a change in context is detected. This change may include newly provided information by the user, and changes in the environment in which the controller (i.e. provider) operates or processes personal data.\n\nThis pattern allows users to make informed decisions regarding if, when, and how they share their personal data. As more information is collected, the user may become more identifiable, and the data relating to them may become more invasive. Awareness Feed keeps users aware of both the short-term and long-term repercussions in their data sharing choices.",
                "Context": "In a situation where user data is collected or otherwise processed, particularly personal data, many users are concerned about the potential repercussions of their actions. Controllers (e.g.~organizations), which have dynamic and evolving services (or products) which users interact with, may share this concern. This may be for legal, ethical, or public appearance reasons.\n\nThese controllers also care about the monetary implications of a solution, often including the opportunity cost of informed users against the risks and profits of over-sharing. For-profit organizations regularly want to bolster their market share by overcoming competition with state of the art technologies. These changes may have important consequences, unintentional or otherwise, for users of the system. Controllers want to limit the exposure of these risks to their userbase, even if from a third party, as they are responsible for their data.\n\nSuch controllers may already have in place a Privacy Dashboard(Privacy-dashboard), seeking to complement it, or wish to maintain awareness through various other services. They likely consider Lawful Consent(Lawful-Consent) and thus seek to ensure that their users are properly and priorly informed before making regrettable decisions. They would nonetheless need to prevent notification fatigue if they were Preventing Mistakes or Reducing Their Impact(Preventing-Mistakes-or-Reducing-Their-Impact) like in this pattern.",
                "Problem": "Users are often unaware of the privacy risks in their data sharing activities, especially risks which are indirect or long-term. How can we best ensure that users become aware of these risks?\n\nThis problem is agitated by the organizational aim to provide novel and competitive services while keeping users informed. The difficulty of this is frequently underestimated. The pitfalls controllers face as a consequence manifest both in taking shortcuts and in unexpected long-term effects.\n\n##",
                "Forces/Concerns": "- Users do not necessarily realize the effects of their information sharing, but often want to use new or interesting features\n- Some users are discouraged from sharing as they do realize that they are not informed about risks to their privacy, but cannot reasonably change that themselves\n- Controllers aim to provide or utilize novel and or competitive services, but explaining potential risks to privacy in those services is often non-trivial and generates a fear of upsetting the userbase and endangering trust\n- Some controllers wish to empower users by informing them, but do not want to jeopardize their business model, or ability to process in a timely fashion\n\n##",
                "Shortcuts": "The appeal of convenience features may sway controllers into flawed implementations which undermine user privacy. Automated decisions, influenced by past actions or by other potentially inaccurate metrics, may result in sharing decisions which users do not approve of. The same holds for features which are not adequately assessed. While a controller might intend all the necessary tools for informed decisions to be present, short-sighted process flows may violate user trust all the same.\n\n##",
                "Long-term Effects": "Over time, supposedly harmless data may amass into more revealing information, especially when paired with the right metadata. Being able to link user activity to other sources of information may also result in far more exposing situations than expected.\n\nNot only are users often unaware of the potential consequences of their actions, even controllers themselves regularly fail to anticipate how revealing their services can be. While some users approach this uncertainty with caution, others will risk their privacy in hopes of using the services. Though the uncertainty might not prevent their participation, it may still jeopardize their trust in the system.",
                "Solution": "Warn users about potential consequences before collecting or otherwise processing personal data, early enough to be appreciated and late enough to be relevant.\n\nThis information should be provided before the point where privacy risks could materialize. If there is some delay before further processing after collection, the user has some time to review the risks. Until the user accepts them however, that further processing should not take place.\n\nThis pattern is a compound pattern, one in which multiple patterns work together to address a broader problem. It combines the following patterns:\n\n- Impactful Information and Feedback(Impactful-Information-and-Feedback);\n- Increasing Awareness of Information Aggregation(Increasing-Awareness-of-Information-Aggregation);\n- Privacy Awareness Panel(Privacy-Awareness-Panel);\n- Appropriate Privacy Feedback(Appropriate-Privacy-Feedback); and\n- Who's Listening(Whos-Listening).\n\n##",
                "Rationale": "It is not likely enough that users are informed prior to being provided a service, nor is it reasonable to expect that consent acquired in bulk is properly informed. Consent is not necessarily freely given, either, if the lack of consent presents a wall to a service that the user wants or believes to need.\n\nA concerted effort needs to be made to present the user with unintimidating information relevant to their privacy risks for a service. Providing too much information lessens the chances that the user will read it, while too little information may not properly inform the user. Informing the user too late also puts the user at unnecessary risk.\n\nBy making this effort, the controller avoids accusations of negligence in informing their users.\n\n\n\n\n\n\n#",
                "Implementation": "Every service which makes use of personal information should be investigated by its creators during its creation, or retrospectively if already available. The controller in question is responsible for this. Not only will this affect the user's understanding once presented to them in layperson terms, but it will also allow the controller to realize the privacy impact of their services. This may encourage them to improve the services to be more respecting of privacy. A good solution composes of accessibility, as well as transparency and openness.\n\n##",
                "Accessibility": "There needs to be a balance between the user effort required both to use a service and maintain their privacy. Information about the risks should not be deceptive, or difficult for laypersons to comprehend. Meeting this balance may also be challenging, as fully comprehending the risks involved might require a certain understanding of the system itself.\n\nIn order to reduce the quantity of the presented information, only the contextually significant information need be presented. Furthermore, the information should be available in the level of detail sought by the user: in both concise and detailed variants. A short description may be used in Preventing Mistakes or Reducing Their Impact(Preventing-Mistakes-or-Reducing-Their-Impact). A more in depth variation may give them confidence that even if they cannot comprehend it, someone would speak out if something were amiss. In a similar vein, detailed descriptions should be comprehensible enough to avoid accusations of being deliberately complex or misleading.\n\nOne way in which to explain the risks involved in a process is through example. This is particularly useful in the case of information aggregation. Visualizing the publicity of data is also useful, users can see how visible information would be, or is, to the outside world. Similar decisions by those who choose to set examples may also help in influencing informed sharing behaviour.\n\n##",
                "Transparency and Openness": "Users need to be able to trust that a system does not pose unnecessary risks. Fostering a familiarity with openness and transparency about the processes involved may garner this trust. It allows those who invest time an opportunity to be certain, and those who trust in public perception to be at ease.",
                "Consequences": "The solution of this pattern will cause users to have a better understanding of the potential consequences of information they share. It may empower some to share knowing they may do so safely, though it will cause less activity overall, as many users will be more careful about what they put online. This is not necessarily a negative consequence, though, since regretted decisions merely garner mistrust and prevent future activity. The controller will be able to introduce new services or update old ones with confidence that users are given the opportunity to consider their decisions in full light of the service's potential consequences.\n\nIn addition to lower adoption of risky services, due to public consequences, there will be more cost involved in reworking them. Unattended and system-wide process changes, which negatively affect consequences, will be more difficult to perform. They will not be possible without first disabling the affected services. This is similar to the way some controllers (e.g. Google) handle changes in privacy policies.\n\nDue to more privacy-minded implementations, the system will not anticipate users as easily, though for many this will be a worthwhile tradeoff. While there is cost in creating good solutions, the long-term cost of bad ones (especially in good faith) can often be higher.\n\n#",
                "Constraints": "By informing users prior to the activation of any services which use personal data, many aspects of a system are less fluid and thus require additional forethought. Instead of quick integration into the system, which may have come with many privacy oversights, users will be exposed to consequences that they might not have otherwise realized. Care will need to be taken to ensure that these users do not become overwhelmed. As a consequence of better informed users, however, questionable services are more open to scrutiny and thus many shortcuts will no longer be viable.",
                "Examples": "Full adoption of this pattern is not yet commonplace, yet there exist examples of feedback loops to users about activities corresponding to them. This includes notifications such as 'user X wants to access Y', or retrospectively, 'user X accessed Y'. There also exist services which require opt-in, accompanied by explanations of their effects. Conversely telemetry is often opt-out, but occasionally explains what information is at stake.\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "Users must be assured of the controller's dedication to transparency and openness, which will be enabled by the consistent presentation of that relevant information, along with other forms of Building Trust and Credibility(Building-Trust-and-Credibility). As in Preventing Mistakes or Reducing Their Impact(Preventing-Mistakes-or-Reducing-Their-Impact), both users and controllers themselves need to be aware of the potential for certain services to leak unwarranted personal information. Where the value of the service is nonetheless still high, even after efforts made to reduce leakage risks, users need to be informed enough to choose for themselves exactly what they share (see Lawful Consent(Lawful-Consent) and Selective Disclosure(Selective-Disclosure)).\n\nThis approach may be partnered with accessible policies, including Privacy Aware Wording(Privacy-Aware-Wording), Layered Policy Design(Layered-policy-design), and Privacy Aware Network Client(Privacy-aware-network-client). It may also benefit from visual cues, like Icons for Privacy Policies(Icons-for-Privacy-Policies), Appropriate Privacy Icons(Appropriate-Privacy-Icons) in general, Privacy Labels(Privacy-Labels), or Privacy Color Coding(Privacy-color-coding), which aid in alluding to those policies.\n\nThis compound pattern benefits from also using Task-based Processing(Task-based-Processing), where personal data is separated according to purpose. In this case, only use data for which any necessary consent has been granted, and which is within the scope of the personally enabled purposes. This precludes the application of unattended process changes which would induce new consequences.\n\nThis pattern _complements_ Privacy Dashboard(Privacy-dashboard), Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides), Appropriate Privacy Icons(Appropriate-Privacy-Icons), Icons for Privacy Policies(Icons-for-Privacy-Policies), Privacy Color Coding(Privacy-color-coding), Privacy Aware Wording(Privacy-Aware-Wording), Layered Policy Design(Layered-policy-design), and Privacy-Aware Network Client(Privacy-aware-network-client).\n\nAs this pattern keeps users informed of processed data, as well as what can be derived, and Privacy Dashboard(Privacy-dashboard) provides collective summaries of such data, these patterns can work together. In doing so, users are better equipped to take actions which are in line with their personal privacy preferences. Similar to this argument is the benefit of Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides), which highlights criteria which a service meets to build trust in the user. With this pattern, it can also inform the user of which parties with access to their data comply with these criteria.\n\nThis pattern and its components also work well with visual cues like Appropriate Privacy Icons(Appropriate-Privacy-Icons), Icons for Privacy Policies(Icons-for-Privacy-Policies), and Privacy Color Coding(Privacy-color-coding). These assist in providing awareness quickly through easily interpreted visual information.\n\nAs this pattern seeks to inform users of policies in addition to notifying them of important information, it benefits from the application of accessible policies. Patterns which therefore _complement_ this pattern include Privacy Aware Wording(Privacy-Aware-Wording), Layered Policy Design(Layered-policy-design), and Privacy-Aware Network Client(Privacy-aware-network-client).\n\nThis pattern is a compound pattern, one which builds off of its component patterns. These include:\n\n- Impactful Information and Feedback(Impactful-Information-and-Feedback);\n- Increasing Awareness of Information Aggregation(Increasing-Awareness-of-Information-Aggregation);\n- Privacy Awareness Panel(Privacy-Awareness-Panel);\n- Appropriate Privacy Feedback(Appropriate-Privacy-Feedback); and\n- Who's Listening(Whos-Listening).\n\n##",
                "Related Pre-patterns": "- Privacy Options in Social Networks;\n- Selective Access Control in Forum Software; and\n- Privacy Enhanced Group Scheduling.\n\n#",
                "Sources": "G. Aggarwal and E. Bursztein, \u201cAn Analysis of Private Browsing Modes in Modern Browsers.,\u201d USENIX Security \u2026, pp. 1\u20138, 2010.\n\nS. Ahern, D. Eckles, N. Good, S. King, M. Naaman, and R. Nair, \u201cOver-Exposed ? Privacy Patterns and Considerations in Online and Mobile Photo Sharing,\u201d CHI \u201907, pp. 357\u2013366, 2007.\n\nH. Baraki, K. Geihs, A. Hoffmann, C. Voigtmann, R. Kniewel, B. E. Macek, and J. Zirfas, \u201cTowards Interdisciplinary Design Patterns for Ubiquitous Computing Applications,\u201d Kassel, Germany, 2014.\n\nE. S. Chung, J. I. Hong, J. Lin, M. K. Prabaker, J. a. Landay, and A. L. Liu, \u201cDevelopment and Evaluation of Emerging Design Patterns for Ubiquitous Computing,\u201d DIS \u201904 Proceedings of the 5th conference on Designing interactive systems: processes, practices, methods, and techniques, pp. 233\u2013242, 2004.\n\nC. Graf, P. Wolkerstorfer, A. Geven, and M. Tscheligi, \u201cA Pattern Collection for Privacy Enhancing Technology,\u201d The Second International Conferences of Pervasive Patterns and Applications (Patterns 2010), vol. 2, no. 1, pp. 72\u201377, 2010.\n\nG. Iachello and J. Hong, \u201cEnd-User Privacy in Human-Computer Interaction,\u201d Foundations and Trends\u00ae in Human-Computer Interaction, vol. 1, no. 1, pp. 1\u2013137, 2007.\n\nT. Sch\u00fcmmer, \u201cThe Public Privacy \u2013 Patterns for Filtering Personal Information in Collaborative Systems,\u201d in Proceedings of CHI workshop on Human-Computer-Human-Interaction Patterns, 2004.\n\nE. Freeman, E. Robson, B. Bates, and K. Sierra, Head First Design Patterns. O\u2019 Reilly & Associates, Inc., 2004."
            }
        },
        {
            "filename": "Buddy-List.html",
            "title": "Buddy List",
            "excerpt": "By default, isolate users to a selection of social connections in a user-defined circle of trust. Allow them to expand this circle or create new ones based on the existing members.",
            "sections": {
                "Also Known As": "Contact List, Address Book",
                "Context": "Users frequently interact upon various media, forums, and communication channels. There are however far more users on these channels than most would be comfortable wading through. As controllers for such channels, many services wish to aid their users in finding familiar and comfortable interactions. Users may also seek to participate outside their immediate circles, but may aim not to stray too far.",
                "Problem": "_When many users are able to interact in the interaction space, it is hard to maintain an overview of relevant interaction partners since the number of users exceeds the number of relevant contacts for a specific user. User lists grow very large and it is hard to find people who the local user knows. On the other hand, the local user is more interested in close contacts._\n\nA service aims to provide users with shortcuts to interaction with users who they are most likely to interact with within a particular context (close contacts within social circles).\n\n##",
                "Forces/Concerns": "- Large socially oriented or interaction oriented mediums often hold more participants overall than any one user can manage\n- Users want to interact in a way which is familiar and comfortable, most likely with people they know\n- Some users aim to make new interactions with people bordering their friend circles, or sharing connections",
                "Solution": "Allow users to find and assign others to a user-maintained directory of social circles and contexts to interact with. This is optionally only visible to the users themselves.\n\n\n\n\n\n\n#",
                "Implementation": "Users should be able to view the Buddy List on demand, either during a search operation or persistently. They should be able to add or remove users from the relevant list with minimal effort.\n\nThe list may be seen as a set of user objects. This buddy list has the possibility of adding or removing user objects. In the first case, whenever the local users interact with another user, they can add the other user to their buddy list. To reach this goal, in the user interface, the local users can select the representation of the another user and execute a command for adding (e.g. a menu item associated to the user object). For removing users, when the buddy list is shown, the local users can select the representation of the another user and execute a command for removing (e.g. a menu item associated to the user object).\n\n##",
                "Extending Functionality": "The Buddy List may fuse with other common interaction idioms to constitute a more comprehensive approach to the problem, making it more than an idiom.\n\n- The list may extend to the full User Gallery during a search operation, listing 'buddies' distinctively before the rest of the userbase;\n- Common connections or nearby outliers can be suggested to the user, both during search and while viewing the list itself;\n- The list may indicate the activity or status of each user, as a User List, additionally doing so where consented for users outside the list;\n- Users who also list the local user in their Buddy List may be indicated, perhaps even when not explicitly in the local user's list; and\n- Users may choose to block other users from seeing them.",
                "Consequences": "##",
                "Benefits": "_Connecting the means for adding users to the buddy list with the user\u2019s representation (or the interface elements that are used to interact with the other user) makes the process of adding a user to the buddy list intuitive and reminds a user to consider adding the user._\n\nBy using the Buddy List to make connections about the user, the service can recommend relevant contact suggestions.\n\n##",
                "Liabilities": "_If users only consider buddy lists for maintaining contacts to other users, they will hardly find new users in the system. Thus you should ensure that users can also browse other users who are not on their buddy list (e.g. by providing a User Gallery)._\n\nThe service can trivially derive the social structure of its userbase which may put trust at jeopardy.",
                "Examples": "- Instant Messaging Systems\n- Email address books and mailing lists\n- Reddit Subreddits\n- Facebook Friends\n- LinkedIn Connections\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "Buddy List(Buddy List) may be used by Masquerade(Masquerade), as it may assist in choosing whom to reveal potentially or deliberately identifying information to. It may also be complemented by Reciprocity(Reciprocity) as quid pro quo for connections. Those who are on a user's list will have the user on their own lists. This same property holds for Incentivized Participation(Incentivized-Participation) if it _uses_ Reciprocity(Reciprocity).\n\nThis pattern allows users to monitor one another in a variety of ways, such as their status, or activity. Therefore a Buddy List(Buddy List) _must use_ Lawful Consent(Lawful-Consent) so that participants are given the ability to agree or disagree in an informed and unforced manner.\n\n##",
                "Idioms": "- User Gallery (all users) / User List (online/active users);\n- Who\u2019s Listening (Buddy Lists the user appears in);\n\n#",
                "Sources": "Based on:\n\nT. Sh\u00fcmmer, \u201cThe Public Privacy \u2013 Patterns for Filtering Personal Information in Collaborative Systems,\u201d in Proceedings of CHI workshop on Human-Computer-Human-Interaction Patterns, 2004."
            }
        },
        {
            "filename": "Data-breach-notification-pattern.html",
            "title": "Data Breach Notification Pattern",
            "excerpt": "Ensure that unauthorized access and processing of personal data is detected and reported to the supervisory authority and any sufficiently affected users without any undue delay.",
            "sections": {
                "Context": "Controllers of services (or products) provided to users collect mass amounts of data, a lot of it personal, to improve the quality and user experience of that service. This is all to be done under the informed consent of the user, who should properly understand the risks involved for their data. One such risk is that of unauthorized access, modification, removal, or sharing of data. If such a data breach occurs, notification is required. Any controller within (or providing services or products within) the EU must notify the supervisory authority of their main establishment or representative. This must occur within 72 hours unless justified. Notifying users is dependent on whether they are sufficiently affected.",
                "Problem": "When data breaches occur, numerous risks become apparent for multiple parties, these parties need to be notified and the risks need to be mitigated. Subsequent instances should be prevented through lessons learned.\n\n##",
                "Forces and Concerns": "- Users want to know if anything has happened to compromise their data, their security, or their privacy\n- Users want the controller to mitigate the risks before and after a breach to the best of their ability\n- Controllers want to prevent risks from materializing and place measures against breaches happening in future\n- Controllers also want to prevent users from suffering consequences from the breach, or from ignorance of the breach",
                "Solution": "Detect and react to data breaches quickly, notifying the supervisory authority of details, particularly risk mitigation, in order to establish whether users must also be informed. Properly handling these events will strengthen user trust rather than weaken it.\n\n\n\n\n\n\n#",
                "Implementation": "_A monitoring system logs access to personal data along with a time-stamp. A notification process continuously verifies that only authorized access is listed in this log file, and in case of unauthorized access notifies the data owner and logs the notification action in the log file, again accompanied by a time-stamp. A notification monitoring process finally continuously checks that t_n - t_l <= max_np (t_n denoting the time of notification, t_l the time of data leakage, max_np the maximally allowed period of notification). In case t_n - t_l > max_np it alerts the associated Incident Manager. A formal model can be found here(http://sit.sit.fraunhofer.de/smv/pattern-models/Data-Breach-Notification-pattern-model.pdf)._\n\nIn the event of a breach, the controller should first notify the supervisory authority within 72 hours of it's discovery, and no later without sufficient justification. The processor of personal data, where not also the controller, should notify the controller immediately.\n\nNotification to the authority should include the nature and extent of the personal data affected, the contact for follow up, likely consequences, and the measures proposed or taken to mitigate the breach's effects. If absolutely necessary these details can be provided as they become available. Any breaches should also be documented for future review.\n\nWhere users are affected in a manner which risks their personal rights and freedoms, they shall also be informed of at least the contact, consequences, and measures to be taken, without undue delay. This is not the case if disproportionate effort would be needed, the data remains protected, or the risk is already sufficiently mitigated. The supervisory authority shall assist in determining whether informing users is necessary.\n\nNote that associations or other representative bodies may prepare codes of conduct for data breach notifications. These notifications may also be affected by binding corporate rules, or guidelines, recommendations, and best practices from the board, to promote consistency.",
                "Consequences": "_In order to detect the breach, the controller must have in place an access control mechanism and a monitoring mechanism for personal data. The pattern cannot ensure that the relevant Incident Manager will take adequate actions, hence this process has to be established and controlled by other means._",
                "Examples": "_Assume a company stores all employees' data through a controller's service. There is a contractual agreement between them that each data leakage is reported within one hour. Now Bob, an employee of the controller and not authorized to read the company's data, succeeds in circumventing the access control mechanisms and reads personal data. This represents a data breach of which the company has to be notified within an hour._\n\n#",
                "Known Uses": "_This pattern is based on the privacy principle \"Accountability\" specified in ISO/IEC 29100(https://www.iso.org/standard/45123.html) that is also used in Annex A of ISO/IEC 27018(https://www.iso.org/standard/61498.html). More specifically, it addresses A.9.1 Notification of a data breach involving Personally Identifiable Information (PII). Uses of the pattern as a concrete instantiation of A.9.1 are not known._\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ Unusual Activities(Unusual-activities). These patterns work in an overlapping context. While this pattern focuses on informing and reacting when a data breach has occurred, Unusual Activities(Unusual-activities) focuses on detecting and dealing with unauthorized access. The patterns can work together to handle unauthorized access to personal data.\n\n#",
                "Sources": "\u201cprivacypatterns.eu - collecting patterns for better privacy,\u201d privacypatterns.eu, 2017. Online. Available: https://privacypatterns.eu/. Accessed: 20-Oct-2015."
            }
        },
        {
            "filename": "Decoupling-[content]-and-location-information-visibility.html",
            "title": "Decoupling [content] and location information visibility",
            "excerpt": "Allow users to retroactively configure privacy for location information with respect to the content's contextual privacy requirements.",
            "sections": {
                "Also Known As": "Suggested: Retroactive Location Sharing",
                "Context": "Users often share content in socially oriented services on the Internet. The applications used for uploading this content may attach location information. Controllers can use or publicize this information, allowing others to use it. Sufficient correlations can infringe upon the user's privacy expectations.\n\nThe organization in question (likely the controller) does not wish to undermine these expectations, and seeks to enable the user to assign contextually specific privacy settings.",
                "Problem": "_Concerns about disclosing location information conflict with the appeal of location information for content organization._\n\n##",
                "Forces/Concerns": "- _Location is highly indicative of life patterns and significant contexts of the users' daily lives._\n- _Location data is increasingly available in various consumer devices._\n- Users want streamlined processes for organizing their content in socially oriented services. That simplicity could be achieved by using location automatically.\n- Users do not want to set privacy requirements every time they generate content, nor to sweepingly deny all sharing if they intend to use the service.",
                "Solution": "Allow users to retroactively decide upon the disclosure of location information with respect to the context of the particular content. Record location information by default, but do not automatically share it.\n\n#",
                "Structure": "Give users an interface or control to configure an access policy regarding the privacy of location information. That is, a place where users may, granularly or in bulk, define who may access location information of their content.\n\n#",
                "Implementation": "A basic solution could feature an interface or control for selecting the allowed users from all the types of users of the socially oriented service (e.g. built-in or user-defined groups, individuals, or anonymous users). This control could apply to individual content, or to multiple selections, or groups.\n\nPrior to this grant of additional consent the content itself, or versions containing location, might only be available by unpublished Private Link(Private-link). The protection of the content itself is however not the focus of this pattern.\n\nIf a user chooses, certain individuals or groups may have default access to the attached location information. Default access like this, however, invalidates the following approach.\n\n##",
                "Removing Controller Trust Requirement": "An extended solution may aim to be further privacy preserving.\n\nThe service may accept ciphertext as the location coupled with the content. When (and only if) the user chooses to make that specific location accessible, their client-side device decrypts the location and provides the service with the plaintext location.\n\nThe user may choose how granular the location is before the service receives it. In this way, by default the controller only needs Lawful Consent(Lawful-Consent) to store the content itself. This solution, like many, is dependent on the trustworthiness of the client's own device.",
                "Consequences": "##",
                "Benefits": "- Users can define in one place, or where contextually relevant, the granular privacy settings for the location information of their content.\n- Users do not need to consider settings when generating content, only later when sharing them, or if they choose, automatically with select individuals or groups.\n\n##",
                "Liabilities": "- If users do not configure the policy, then the default configuration shares nothing and the service is not being used.\n- Users could require fine-grained location configuration, such as how specific the location is per content. This could be addressed with additional settings.\n- This pattern assumes the controller is trustworthy, as all location information attached to the content is still given to the service. Alternatively, the service could endeavor to by default also restrict its own access to the information (e.g. client-side decryption).\n\n#",
                "Constraints": "By applying this pattern the controller prevents location access by default, and thus risks a low location sharing rate. This is due to the tendency of users to leave settings in the default state. However, depending on the effort, the controller may encourage positive public image, and raise adoption overall.",
                "Examples": "- Flickr (basic implementation)\n- Twitter (basic implementation)\n- Facebook (basic implementation)\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern is one of various foundations for Support Selective Disclosure(Support-Selective-Disclosure), and thus may be used by it. This pattern _must use_ Lawful Consent(Lawful-Consent) however, as information is recorded by default and only interacted with afterward. This requires the users true and informed approval.\n\nDecoupling content and location information visibility may be complemented by the use of a Private Link(Private-link).\nThis could allow location information sharing with specific unauthenticated individuals, retaining the ability to decide later.\n\nThe pattern _complements_ Discouraging Blanket Strategies(Discouraging-blanket-strategies), which considers having a different privacy level for any content posted while this pattern mentions the privacy level for the location of that content.\n\nIt also _complements_ Negotiation of Privacy Policy(Negotiation-of-Privacy-Policy). The latter defines privacy settings at the beginning. This pattern however gives the chance to change privacy settings every time content is being shared.\n\nAdditionally, this pattern _refines_ Reasonable Level of Control(Reasonable-Level-of-Control). It provides means of control for location attached to content, so it complies with the the latter's solution in a more specific scenario.\n\nFinally, this pattern _may use_ the Buddy List(Buddy List) pattern. The location information could be seen by different types of users, one of them could be featured in a Buddy List(Buddy List) or one of its user/search directories.\n\n#",
                "Sources": "Based on:\n\nS. Ahern, D. Eckles, N. Good, S. King, M. Naaman, and R. Nair, \u201cOver-Exposed ? Privacy Patterns and Considerations in Online and Mobile Photo Sharing,\u201d CHI \u201907, pp. 357\u2013366, 2007."
            }
        },
        {
            "filename": "Discouraging-blanket-strategies.html",
            "title": "Discouraging blanket strategies",
            "excerpt": "Give users the possibility to define a privacy level from a range of options each time they share content.",
            "sections": {
                "Context": "Socially oriented services on the Internet allow their often diverse userbase to share content. These masses of users and shared content are also varied enough to discourage individual attention. Controllers prefer to protect themselves from additional complexity and investment into features which provide them with less data. Users, however, feel in need of privacy settings to distinguish their personal risk appetite from that of the norm. They each have their own ideas about the sensitivities of their information, which makes sufficient controls difficult to implement.",
                "Problem": "Overly simplified privacy settings following all or nothing strategies could result in over-exposure, self-censoring, and unsatisfied users.\n\nThese all or nothing strategies could refer to privacy settings which holistically apply to all content, or to binary (or otherwise deficient) choices for public visibility.\n\n##",
                "Forces/Concerns": "- The level of invasiveness depends upon the context of the content being shared.\n- Users have differing levels of sensitivity attributed to contexts, and thus different levels to provide their content.\n- They trust the controller to different extents.\n- Controllers do not want to violate user privacy.\n- They want to protect themselves from blame if a user's privacy is violated.\n- They want users to produce content which is at least somewhat valuable. (For instance, when nobody can see the content there won\u2019t be an impact in collaborative environments)",
                "Solution": "Provide users with the possibility to define a privacy level for content being shared with the controller, or with other users. Give them a range of visibilities, so that they can decide the access-level of the content being shared according to different users, or service-defined groups.\n\n\n\n\n\n#",
                "Implementation": "Provide users easily-recognizable visual elements to define the privacy level for each content submission. Use controls, such as (drop-down) lists, combo boxes, etc. to provide a range of possible privacy levels.\n\nThe privacy levels could be defined in terms of social group of the users in question to the user who is sharing content. For instance, family, closest friends, colleagues, acquaintances, everybody. This is in line with Reasonable Level of Control(Reasonable-Level-of-Control) and Selective Access Control(Selective-Access-Control), where a user might be given the opportunity to define their own groups or set individual privacy levels.\n\nThe privacy controls themselves also need to be designed in such a way that it is very clear to users what each setting does and what it means for their privacy.",
                "Consequences": "##",
                "Benefits": "- Grants users complete control over the privacy of the content being shared, which may lower the bar for them to share certain data they otherwise would not.\n\n##",
                "Liabilities": "- Users could find having to set privacy settings every time they share content to be tedious. It would be necessary to define reasonable defaults for privacy settings (least effort for minimal sharing).",
                "Examples": "- Facebook.\n- Google Plus.\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern may be used by Support Selective Disclosure(Support-Selective-Disclosure), as it makes up a foundation for a compound pattern. Discouraging blanket strategies(Discouraging-blanket-strategies) may also be complemented by Selective Access Control(Selective-Access-Control) and by Decoupling [content and location information visibility](Decoupling-content-and-location-information-visibility). These patterns support each other to provide more flexible privacy setting management to users.\n\nDiscouraging blanket strategies(Discouraging-blanket-strategies)\n _complements_ Reasonable Level of Control(Reasonable-Level-of-Control), which features selective and granular sharing and may consider a range of options. These methods complement each other where considering this range.\n\n This pattern additionally _complements_ the Negotiation of Privacy Policy(Negotiation-of-Privacy-Policy) pattern. While Negotiation of Privacy Policy(Negotiation-of-Privacy-Policy) aims to let users opt-in or opt-out, this pattern handles the way in which users configure their privacy settings. If users were not able to opt-in/out then a blanket strategy would probably be in place.\n\nFinally, this pattern also _may use_ Buddy List(Buddy-List). Content the user decides to share could be selectively shown only to certain users on the Buddy List(Buddy-List).\n\n#",
                "Sources": "Based on:\n\nS. Ahern, D. Eckles, N. Good, S. King, M. Naaman, and R. Nair, \u201cOver-Exposed ? Privacy Patterns and Considerations in Online and Mobile Photo Sharing,\u201d CHI \u201907, pp. 357\u2013366, 2007."
            }
        },
        {
            "filename": "Dynamic-Privacy-Policy-Display.html",
            "title": "Dynamic Privacy Policy Display",
            "excerpt": "Provide standardized contextual policy information on the nature and risks of disclosure through tooltips.",
            "sections": {
                "Context": "Controllers are mandated by various laws and regulations to ensure that users, their data subjects, are adequately informed before requesting consent. Failing this, the consent loses legitimacy and the controller may face repercussions. However, the main mechanism for supplying this information resides with privacy policies, which must also conform to legislative norms. The language this necessitates is long and complex, which jeopardizes the chances of users understanding it. This information can be summarized, and otherwise reworded to make the content more accessible to users, though typically the length of such summaries are still quite long.",
                "Problem": "Not all contexts are suitable for extensive privacy policy information, yet users often still need to be able to obtain additional data without breaking those contexts.\n\n##",
                "Forces and Concerns": "- Controllers need informed consent for collection, sometimes with limited screen space available, yet users do not typically read privacy policies on their own\n- Users do not want to spend time and effort reading through privacy policies\n- Controllers want users to actually use their service (or product), but users will not do so if the cost of doing so entails disproportionate effort\n- Users want to be able to get to using the service quickly, without needing to visit multiple policy pages",
                "Solution": "Provide the user with additional relevant policy information on hover or tap, by way of 'tooltips', to best inform them given contextual limitations. In a mobile setting these tooltips may unobtrusively become available to tap when the relevant control is most in focus (i.e. selected, centered, or occupies most of the screen).\n\nThis information may highlight the nature and potential consequences of the disclosure, and should be displayed consistently.\n\n\n\n\n\n\n#",
                "Implementation": "_The information should be provided to the user where it is needed. Therefore the tooltip should appear on demand (i.e., need of information). This could be for example in a login dialog as soon as the user navigates the mouse into the concerning part of the interface. The tooltip should then be made visible to the user and contain all necessary information for making an informed decision._",
                "Consequences": "_By displaying the relevant information pertaining to privacy policies whenever they apply to what the user is currently doing or about to do, the user's awareness of what will happen with the information they're about to share is increased._\n\nHowever, users may also happen to not trigger the tooltip, especially when using a mobile device. As such it is important that they are aware of its existence, and its importance, given the current context.",
                "Examples": "When a user needs to login and is given numerous options, with limited space provided, each option can have an assigned tooltip. These can appear on hover, tap, or scroll, where necessary appearing with less opacity until the user taps the tooltip itself. It can also lead to further detail through '(see more)' in a recognizable blue underlined hyperlink format. To encourage use of this a variant may either scroll through detail or show a visible scroll bar. Not needing the user to leave the application or webpage will require less effort on their part.\n\n#",
                "Known Uses": "The PrimeLife HCI Pattern Collection (V2) features a prototype using tooltips to convey policy information on hover. \n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ Policy Matching Display(Policy-matching-display) and Platform for Privacy Preferences(Platform-for-Privacy-Preferences). In both cases the solutions are different, but share the same context.\n\nWith Policy Matching Display(Policy-matching-display), this pattern may add mismatches between preferences and the standardized policies to 'tooltips' therein. Against the Platform for Privacy Preferences(Platform-for-Privacy-Preferences) pattern, however, they may work together to show the user how the privacy policy compares to user preferences.\n\nThis pattern _may use_ Privacy Policy Display(Privacy-Policy-Display). While this pattern adds additional elements to the solution presented by Privacy Policy Display(Privacy-Policy-Display), it is a _uses_ relationship rather than _extends_, as both patterns approach different problems.\n\n#",
                "Sources": "S. Fischer-H\u00fcbner, C. K\u00f6ffel, J.-S. Pettersson, P. Wolkerstorfer, C. Graf, L. E. Holtz, U. K\u00f6nig, H. Hedbom, and B. Kellermann, \u201cHCI Pattern Collection - Version 2,\u201d 2010.\n\nC. Graf, P. Wolkerstorfer, A. Geven, and M. Tscheligi, \u201cA Pattern Collection for Privacy Enhancing Technology,\u201d The Second International Conferences of Pervasive Patterns and Applications (Patterns 2010), vol. 2, no. 1, pp. 72\u201377, 2010."
            }
        },
        {
            "filename": "Enable-Disable-Functions.html",
            "title": "Enable/Disable Functions",
            "excerpt": "Allow users to decide granularly what functions they consent to before the function is used.",
            "sections": {
                "Context": "Users frequently have data collected about them, often in situations where it needn't be. Many of these cases are due to good intentioned, expansive, functionality. Not all users seek to take advantage of all functions, however. Some controllers aim to consider this in their designs.",
                "Problem": "Not all users desire or benefit from all functionality.\n\n_Consider users living in an Ambient Assisted Living environment: these users are surrounded by various sensors such as video cameras, motion sensors or electrical current sensors that are used to monitor the actual situation of a person. Another example are the acceleration sensors included in smartphones. A service (or product) can recommend places of interest to the user by considering the gathered data. With regard to these examples it becomes obvious that services often unobtrusively collect highly critical and personal context data of users._\n\n##",
                "Forces/Concerns": "- Informational self-determination: _The pattern considers a user's basic right of informational self-determination. This is due to the fact that a user is able to explicitly agree or disagree to a certain function depending on the context data needed by the function. Therefore, the user has direct control of the context data collection process. This satisfies the principles of necessity, transparency, giving consent and responsibility. They are part of the user's right of informational self-determination and are described in detail in Kuner and Hornung & Schnabel._\n- Trust: _The pattern increases a user's trust in the service by offering the possibility to prevent the collection and inference of certain personal context data. Hence, users can be sure that personal data that is critical to them is not gathered, stored or further processed by third parties._\n- Transparency: _The pattern provides transparency to the user by giving an overview, which function needs which personal context data of a user to work properly. For this reason a user is aware of the context data that is gathered..._",
                "Solution": "Enable users to choose which functions they do not consent to using, nor wish to provide the required data for.\n\n\n\n\n\n\n#",
                "Implementation": "_A solution is given if the user can explicitly agree or disagree to certain functions. For this purpose, the service has to display every function and its required context data. A possible way of displaying these functions and the used context data may be the use of the privacy consent form, which is included in every application._",
                "Consequences": "_By enabling the user to explicitly agree or disagree to certain functions, a context aware application like Support-U might not be able to provide all of its possible functionalities to the user anymore. However, the usage of this pattern in the development process of context-aware applications might additionally strengthen the user's confidence in the usage of UC systems._",
                "Examples": "##",
                "Support-U": "_In the shown privacy consent form each function, which utilises personal context information, is listed. Furthermore, the user is able to activate or to deactivate the functions, e.g., to enable a live stream or to enable predicting her next context._\n\n##",
                "Meet-U": "_Meet-U provides several functions that make use of localization mechanisms and the personal data the user supplies. That includes the user's interests, buddy list and their preferred means of transportation. For indoor navigation a RFID sensor attached to the user is exploited. The user can now switch off the navigation function so that neither the indoor nor the outdoor localization continue to operate. The user's preferences concerning transportation will be no longer available. Further functions can be disabled correspondingly. Turning off, for example, the advanced search engine would stop using the user's interests._\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "Enable/Disable Functions(Enable/Disable-Functions) is _similar to_ Negotiation of Privacy Policy(Negotiation-of-Privacy-Policy). Choosing between activated or deactivated privacy settings and functionalities is in-line with negotiating a policy which reflects these choices, but from a more functional perspective.\n\nLike many patterns, despite providing the user with enhanced choice, it is important to ensure that user decisions are informed, made without being pushed, and are understood explicitly. As such, this pattern _must use_ Lawful Consent(Lawful-Consent) as means to this end.\n\n- Configurability: The application shall enable users to activate or deactivate functions. (See Reasonable Level of Control(Reasonable Level of Control)).\n- Agreement to Functionality: The application shall ask for users' consent regarding the functionality before use. The application should enable users to alter their consent regarding the functionality. (See Lawful Consent(Lawful-Consent)).\n\n#",
                "Sources": "Based on:\n\nBaraki, H., Geihs, K., Hoffmann, A., Voigtmann, C., Kniewel, R., Macek, B. E., & Zirfas, J. (2014). Towards Interdisciplinary Design Patterns for Ubiquitous Computing Applications. Kassel, Germany. Retrieved from https://books.google.nl/books?id=D40vBgAAQBAJ\n\n##",
                "From the above": "C. Kuner, European Data Protection Law, Corporate Compliance and Regulation. Oxford University Press, 2007.\nG. Hornung and C. Schnabel, \u201cData protection in germany: The population cen- sus decision and the right to informational self-determination,\u201d Computer Law & Security Review, vol. 25, no. 1, pp. 84\u201388, 2009."
            }
        },
        {
            "filename": "Encryption-user-managed-keys.html",
            "title": "Encryption with user-managed keys",
            "excerpt": "Use encryption in such a way that the service provider cannot decrypt the user's information because the user manages the keys.",
            "sections": {
                "Summary": "Use encryption in such a way that the service provider cannot decrypt the user's information because the user manages the keys.\n\n\nEnable encryption, with user-managed encryption keys, to protect the confidentiality of personal information that may be transferred or stored by an untrusted 3rd party.\n\nSupports user control(User-control), cloud computing(Cloud Computing) and mobile(Mobile).",
                "Context": "User wants to store or transfer their personal data through an online service and they want to protect their privacy, and specifically the confidentiality of their personal information. Risks of unauthorized access may include the online service provider itself, or third parties such as its partners for example for backup, or government surveillance depending on the geographies the data is stored in or transferred through.",
                "Problem": "How can a user store or transfer their personal information through an online service while ensuring their privacy and specifically preventing unauthorized access to their personal information?\n\n\nRequiring the user to do encryption key management may annoy or confuse them and they may revert to either no encryption, or encryption with the online service provider managing the encryption key (affording no protection from the specific online service provider managing the key), picking an encryption key that is weak, reused, written down and so forth. \n\nSome metadata may need to remain unencrypted to support the online service provider or 3rd party functions, for example file names for cloud storage, or routing information for transfer applications, exposing the metadata to risks of unauthorized access, server side indexing for searching, or de-duplication. \n\nIf the service provider has written the client side software that does the client side encryption with a user-managed encryption key, there can be additional concerns regarding whether the client software is secure or tampered with in ways that can compromise privacy.",
                "Solution": "Encryption of the personal information of the user prior to storing it with, or transferring it through an online service. In this solution the user shall generate a strong encryption key and manage it themselves, specifically keeping it private and unknown to the untrusted online service or 3rd parties.",
                "Examples": "* Spider Oak(https://spideroak.com/): online backup, sync, sharing enabling user managed personal information in zero knowledge privacy environment.\n* Least Authority(https://leastauthority.com/): secure off-site backup system with client side encryption.\n* LastPass(https://lastpass.com/): encrypted credentials and personal information database with user managed encryption keys.\n\nSome(http://zeroknowledgeprivacy.org/) have used the term \"zero-knowledge\" to describe this pattern; however, \"zero-knowledge proof\" is a cryptographic term with a distinct meaning(https://en.wikipedia.org/wiki/Zero-knowledge_proof)."
            }
        },
        {
            "filename": "Federated-privacy-impact-assessment.html",
            "title": "Federated Privacy Impact Assessment",
            "excerpt": "The impact of personal information in a federation is more than the impact in the federated",
            "sections": {
                "Summary": "The impact of personal information in a federation is more than the\nimpact in the federated",
                "Context": "Identity Management scenarios (that is, when the roles of the Identity\nProvider and the Service Provider are separated).",
                "Problem": "Identity Management solutions were introduced to decouple the\nfunctions related to authentication, authorization, and management of\nuser attributes, on the one hand, and service provision on the other\nhand. Federated Identity Management allows storing a data subject's\nidentity across different systems. All together, these form a\nFederation that involves complex data flows.\n\nFederated Management solutions can be used to improve privacy (e.g. by\nallowing service providers to offer their services without knowing the\nidentity of their users). However, the complexity of data flows and\nthe possibility of collusion between different parties entail new\nrisks and threats regarding personal data.",
                "Solution": "A Privacy Impact Assessment is conducted by all the members of the\nfederation, both individually and in conjunction, so as to define\nshared privacy policies, prove they are met, and demonstrate the\nsuitability of the architecture, in the benefit of all the members.\n\n\nDeal with privacy risks associated from the federation of different\nparties in an Identity Management solution.",
                "Consequences": "The consequences depend on the results of the privacy-impact analysis.",
                "Examples": "An Identity Provider issues pseudonyms to authenticate users at\nthird-party Service Providers, which can in turn check the\nauthenticity of these pseudonyms at the Identity Provider, without\ngetting to know the real user identity. However, the Identity Provider\nknows all the services requested by the users, which discloses\npersonal information to the Identity Provider and allows it to profile\nthe users.\n\n#",
                "Known Uses": "The New Federated Privacy Impact Assessment (F-PIA). Building Privacy\nand Trust-enabled Federation. Information and Privacy Commissioner of\nOntario & Liberty Alliance Project, January 2009"
            }
        },
        {
            "filename": "Icons-for-Privacy-Policies.html",
            "title": "Icons for Privacy Policies",
            "excerpt": "Icons are capable of conveying information more quickly than a document, and are therefore a useful way to augment policies.",
            "sections": {
                "Also Known As": "Privacy Icons",
                "Context": "Services (and products) which users use usually handle user data in ways which justify the use of a privacy policy. These documents are however made for legal purposes first and foremost and thus must cover a lot of detail rigorously. Users however are exposed to many of these documents when they seek to delve into the practices of each of the services they use. Controllers of these services realize the difficulty apparent in understanding full policy documents, but need users to understand risks if their processing consent is to be valid. Some approaches used to simplify policy are the layering of detail levels, general summarization, and contextual explanations. However, even these are subject to shortcomings.",
                "Problem": "Users struggle to understand privacy policies, even when reduced to a reasonable length. This discourages them from putting in the effort required to understand risks to their data, and invalidates consent.\n\n##",
                "Forces and Concerns": "- Users want to understand the risks to their data in using a service, but do not want to read long or overly complex policies\n- Many users want to be able to decide for themselves which policies apply to them, but do not want to read complex or time consuming summaries just to identify them\n- Controllers need users to be informed before their data may be processed\n- Controllers do not want to inconvenience users by making them read the privacy policy document intended for lawyers",
                "Solution": "Use privacy icons to aid in describing, grouping, and distinguishing the various policies in a privacy policy document. The icons should not allow for misinterpretation, which shall require user testing. Using consistent icons in a standardized way will promote understandability.\n\n\n\n\n\n\n#",
                "Implementation": "In this pattern, privacy icons should not be used in place of the full policy document, but used to augment it. They should be shown in a manner which explains the policy explanation, excerpt, summary, or full detail as appropriate. Examples of usage include describing kinds of data processed, means, purposes, and legitimate interests or other justifications.\n\nThis usage should aid users in determining not only whether to further explore a policy, but also a rough idea of what each policy entails. More than one icon may be used per policy to achieve this, so long as the content becomes less complex.\n\nIcons should be consistent and yet distinguishable from one another. This may justify a certain size limit. The icons should also be self-explanatory. These aspects need verification from a representative sample of the user population.\n\nFurthermore, using standardized icons aids in both understanding and in promoting further use, but should not conflict with the norm. Doing otherwise may confuse users. _If Icons are used in the same way on many of the applications or websites the user visits, it will be easy for the user to learn their purpose and to accept them as assistance. When users are aware of the icons from other purposes it will be also become more easy for them to create a mental model which supports them when reading a policy_.",
                "Consequences": "Without dedicating too much effort, a user may quickly determine the potential risks of processing under a given policy. The user will be able to also quickly locate the other relevant policies both when first using a service and when revisiting policy.\n\nWhen the icons are sufficiently standardized, or at least for the subset which are, the user will not first need to familiarize themselves with explanations. Where not the case, education can assist in changing this if the icons are indeed widely used and consistent.\n\nThe use of this measure will make policy more transparent, which will enhance the level of trust placed by users. Users which provided an invalid form of consent due to lack of policy understanding may then choose to retract it, or modify permitted usage.",
                "Examples": "_Alice buys a fitness tracker and she is aware that the device collects her location, and sends it to a central web service in order to provide her with her fitness statistics (her fitness routes, the time spent...). She immediately consents to this even though it asks to first read a privacy policy. The device controller consequently aggregates this data and provides a business analytics service to third parties._\n\n_Alice is totally unaware of this secondary use of her data and may not agree to it. But accessing this policy involves accessing a website and going through a lengthy and legally oriented document._\n\nComparatively, the tracker could have provided a short policy summary on the packaging using icons to convey more information with less space. Alice would have noticed an icon she recognized to convey third party sharing. Curious of whom this third party might be, and what extra risks she might be taking, she searches the online policy and finds it to be a company she does not trust. As a result she would not have consented, and potentially not purchased the device.\n\n_See also the Privacy Icons entry at Ideas for a Better Internet(https://cyber.harvard.edu/i4bi/Privacy_Icons) (kind of a pattern repository by the Berkman Klein Center for Internet and Society in Harvard)._",
                "See Also": "Recital 60 as well as Art. 12(7) of the General Data Protection Regulation suggests the use of standardized icons, informing users in an _easily visible, intelligible and clearly legible manner_.\n\n#",
                "Related Patterns": "This pattern _complements_ Impactful Information and Feedback(Impactful-Information-and-Feedback), Informed Secure Passwords(Informed-Secure-Passwords), Layered Policy Design(Layered-policy-design), Privacy Aware Wording(Privacy-Aware-Wording), Privacy-Aware Network Client(Privacy-aware-network-client), Awareness Feed(Awareness-Feed), and Privacy Color Coding(Privacy-color-coding). It also implicitly _complements_ Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides) through Awareness Feed(Awareness-Feed).\n\nAs a visual cue, this pattern aids in providing Impactful Information and Feedback(Impactful-Information-and-Feedback) by augmenting it with quickly interpreted information. These visual cues additionally help towards Informed Secure Passwords(Informed-Secure-Passwords), as they may indicate password strength and policy.\n\nVisual cues like this pattern also aid in providing accessible policies, and thus _complement_ Layered Policy Design(Layered-policy-design), Privacy Aware Wording(Privacy-Aware-Wording), and Privacy-Aware Network Client(Privacy-aware-network-client).\n\nLike many patterns which inform users, elements of Awareness Feed(Awareness-Feed) and its methods for establishing awareness also go well with visual cues like this pattern. It also implicitly aids Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides), which provides visual representation to highlight trust levels to the user.\n\nThis pattern _leads to_ Appropriate Privacy Icons(Appropriate-Privacy-Icons). This pattern encourages the use of privacy icons to describe a privacy policy, but this usage has opportunities for misuse which Appropriate Privacy Icons(Appropriate-Privacy-Icons) exists to address.\n\nLike this pattern, Privacy Color Coding(Privacy-color-coding) provides its own way to tackle an overlapping and quite similar problem. This features the understanding of the privacy policy in both cases, as well as privacy settings in Privacy Color Coding(Privacy-color-coding). These patterns may work together to integrate a solution illustrating with both color and imagery.\n\n#",
                "Sources": "S. Fischer-H\u00fcbner, C. K\u00f6ffel, J.-S. Pettersson, P. Wolkerstorfer, C. Graf, L. E. Holtz, U. K\u00f6nig, H. Hedbom, and B. Kellermann, \u201cHCI Pattern Collection - Version 2,\u201d 2010.\n\nC. Graf, P. Wolkerstorfer, A. Geven, and M. Tscheligi, \u201cA Pattern Collection for Privacy Enhancing Technology,\u201d The Second International Conferences of Pervasive Patterns and Applications, vol. 2, no. 1, pp. 72\u201377, 2010.\n\nEuropean Parliament and Council of the European Union, \u201cGeneral Data Protection Regulation,\u201d Official Journal of the European Union, 2015."
            }
        },
        {
            "filename": "Identity-federation-do-not-track-pattern.html",
            "title": "Identity Federation Do Not Track Pattern",
            "excerpt": "All information has been extracted from http://blog.beejones.net/the-identity-federation-do-not-track-pattern  The Do Not Track Pattern makes sure that neither the Identity Provider nor the Identity Broker can learn the relationship between the user and the Service Providers the user us.",
            "sections": {
                "Summary": "All information has been extracted from\nhttp://blog.beejones.net/the-identity-federation-do-not-track-pattern\n\nThe Do Not Track Pattern makes sure that neither the Identity Provider\nnor the Identity Broker can learn the relationship between the user\nand the Service Providers the user us.",
                "Context": "This pattern is focused on identity federation models",
                "Problem": "When an identity system provides identifying information about a user\nand passes this to a third party service, different parties can do\ncorrelation and derive additional information.",
                "Solution": "Include an orchestrator component, that must act in behalf and be\ncontrolled by the user. The orchestrator makes sure that the identity\nbroker can\u2019t correlate the original request from the service provider\nwith the assertions that are returned from the identity provider. The\ncorrelation can only be done within the orchestrator but that\u2019s no\nissue because this acts on behalf of the user, possibly on the device\nof the user.\n\n\nAvoid the correlation of end user and service provider data",
                "Consequences": "In practice, the orchestrator could run in the browser of the user as\na javascript program or as an App on his device\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Known Uses": "Identity federations and ecosystems"
            }
        },
        {
            "filename": "Impactful-Information-and-Feedback.html",
            "title": "Impactful Information and Feedback",
            "excerpt": "Provide feedback about who a user will disclose their information to using certain privacy settings before that information is actually published.",
            "sections": {
                "Context": "Users are frequently in a rush to use services at the same pace as their own ever quickening lifestyles. Such value for time can leave them unaware of the potential for mistakes, such as in automatic media sharing, or the careless disclosure of information in their contributions. These mistakes may disclose personally identifiable information, or otherwise undesirable associations. Sometimes whether the information is appropriate is dependent on the audience, or some other contextual element. Controllers who provide services to these users do not fare well when these instances occur, as they provide the means for it to happen. As such, they tend to want to be proactive in handling such issues.",
                "Problem": "A lack of user awareness in the moment can lead to regretted disclosure, whether this disclosure is manually or automatically performed.\n\n##",
                "Forces/Concerns": "- Users want to use a service in an immediate and streamlined fashion, but in doing so expose themselves to mistakes.\n- Many users disclose unintentional information during the use of a service, especially when participating without caution.\n- Controllers do not want users to use a service in a way which fosters regret.\n- Controllers want users to learn to use a service responsibly without having to make mistakes.",
                "Solution": "Use contextual privacy warnings, through analytical measures and historical queues to provide relevant information and suggestions regarding pending disclosures.\n\n\n\n\n\n\n#",
                "Implementation": "Prior to submissions taking place, and provided that the user has consented to contextual privacy warnings, analyze the content of the disclosure using natural language processing. This may also entail additional metadata, such as factors pertaining to the expected audience, social comparisons against similar users or ones which the user in question has connected with. All users from which the analysis is derived should also first have provided their explicit, informed, and freely-given consent.\n\nSearch for strings which are likely to heighten the sensitivity of the content, and evaluate this against the expected audience. Where users disregard warnings, take note for improvement of future predictions through a feedback loop. Additionally, allow users to signify that despite ignoring the warning, they later regretted the post (or detect deletions which imply this) to distinguish false positives from inaccurate warnings.\n\nOne way to increase user understanding of the risks involved is to demonstrate by example a disclosure which matches the approximated sensitivity or contextual appropriateness of their content. This example will need to be one which they could usually view on their own, so as not to inadvertently cross the boundary of another user's privacy. This approach is also susceptible to inaccuracies, and would also need to be improved overall by the userbase.\n\nThe learning algorithm may at first be trained using text mining from logs of users who have opted-in to the, at first, experimental feature. While assumptions may be made, possibly inaccurately, users could also give feedback about regretted submissions or contextual appropriateness. Which type of learning is chosen is dependent on what information the controller has at their disposal at the time. If starting fresh, the implementation will likely be less sophisticated. While if available, solutions can be as complex as a reinforced classification learning algorithm.",
                "Consequences": "By applying this pattern, users who choose to partake will have a better realization of what might happen when they disclose certain content. This can apply to any information they put online, and may show who will be able to see what. This can be both beneficial and disadvantageous, as this means users will be more cautious and less likely to contribute. They may also have worries about the trustworthiness of the learning algorithm which may access their content before they themselves have seen it fit for publication.",
                "Examples": "_Systems can reduce user uncertainty about factors important to disclosure choices. For example, systems may be able to estimate the audience for a particular disclosure at decision-time,\nthereby reducing uncertainty and influencing user choices. Systems could use social comparison, such as decisions made by friends or other users in similar context, to reduce uncertainty about relevant norms for disclosure. Finally, tools for viewing photo \u201cdisclosures\u201d in ways similar to how others will view these photos could help users understand the content and appearance of their disclosures._\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern is a component of the compound pattern, Awareness Feed(Awareness-Feed). As such, this pattern _may be used_ by it.\n\nThis pattern _complements_ Privacy Mirrors(Privacy-Mirrors), Unusual Activities(Unusual-activities), Preventing Mistakes or Reducing Their Impact(Preventing-Mistakes-or-Reducing-Their-Impact), and Privacy Awareness Panel(Privacy-Awareness-Panel).\n\nThrough Unusual Activities(Unusual-activities), this pattern can inform users from insights having an effect on authentication and authorization. Extending this is an implicit connection to Informed Secure Passwords(Informed-Secure-Passwords), which benefits from having these complementary and impactive insights into authentication decisions. As an even further connection, this pattern also loosely benefits from Informed Credential Selection(Informed-Credential-Selection) in much the same way.\n\nOn the other hand, Preventing Mistakes or Reducing Their Impact(Preventing-Mistakes-or-Reducing-Their-Impact) serves as a complementary pattern through its intent to prevent automatic sensitive disclosure in addition to this pattern's reflective approach.\n\nWithin Awareness Feed(Awareness-Feed), Privacy Awareness Panel(Privacy-Awareness-Panel) may take analytical provisions from this pattern to supply feedback on potentially sensitive activity. These same provisional warnings allow for protection from the controller and reflection on sharing decisions in Privacy Mirrors(Privacy-Mirrors). This similarity is short of a _similar_ relationship, however, especially as the problems addressed are quite distinct. This pattern is also _complemented_ by Privacy Dashboard(Privacy-dashboard) in a similar fashion, along with other components of Awareness Feed(Awareness-Feed).\n\nAs this pattern focuses on providing relevant information before disclosure as with Awareness Feed(Awareness-Feed), visual cues and accessible policies implicitly help work towards this end. These include Appropriate Privacy Icons(Appropriate-Privacy-Icons), Icons for Privacy Policies(Icons-for-Privacy-Policies), Privacy Color Coding(Privacy-color-coding), Privacy Aware Wording(Privacy-Aware-Wording), Layered Policy Design(Layered-policy-design), and Privacy-Aware Network Client(Privacy-aware-network-client).\n\nIt also implicitly _complements_ Appropriate Privacy Feedback(Appropriate-Privacy-Feedback), which focuses on informing users of what happens with their data. It does so through the same vein as Privacy Awareness Panel(Privacy-Awareness-Panel), and also through Increasing Awareness of Information Aggregation(Increasing-Awareness-of-Information-Aggregation).\n\nFinally, this pattern _may use_ Increasing Awareness of Information Aggregation(Increasing-Awareness-of-Information-Aggregation). As this pattern is based on analytics about historical queues or measures for providing warnings, it benefits from informing the user about the pitfalls of data aggregation.\n\n#",
                "Sources": "Based on:\nS. Ahern, D. Eckles, N. Good, S. King, M. Naaman, and R. Nair, \u201cOver-Exposed ? Privacy Patterns and Considerations in Online and Mobile Photo Sharing,\u201d CHI \u201907, pp. 357\u2013366, 2007."
            }
        },
        {
            "filename": "Incentivized-Participation.html",
            "title": "Incentivized Participation",
            "excerpt": "Users are more willing to contribute valuable input when they can do so without leaking personal data, or perceive an equal or greater exchange in value either monetarily or socially.",
            "sections": {
                "Also Known As": "Reciprocity / Fair distribution of efforts / Win-win situation / Pay-Back",
                "Summary": "Users of a system have varying privacy concerns, and different sensitivities associated with their personal information. These users need ways to contribute without leaking sensitive details, or to perceive a worthwhile tradeoff for those details. This can be achieved through social encouragement (i.e. participation and shared trust), direct value exchanges (discounts and giveaways), or some other derived value (e.g. positive reinforcement).",
                "Context": "A data controller derives various values from the participation of its users (i.e. data subjects). The more that these users participate, explicitly providing context and implicitly providing metadata (e.g. statistics and telemetry), the better the controller fares in a number of respects. Despite this key relation, over-sharing can greatly infringe upon a user's right to privacy. Many controllers therefore aim to respect this right when benefiting from user interactions.\n\nAs the controller should recognise the necessity of specific, informed, and freely given Lawful Consent(Lawful-Consent), users are made aware of the pitfalls of such a system. As they are informed, perhaps through a combination of a Privacy Dashboard(Privacy-Dashboard) or Awareness Feed(Awareness-Feed), users may balance the privacy related tradeoffs.\n\nThis minimises the privacy risks taken according to the user's personal informed choices, and protects the controller from inadvertently undermining the user's privacy. The controller still desires participation, however, and may therefore make additional concessions or provisions to help make the tradeoff worthwhile or non-existent. The controller may complement its strategy with more granular choice in order to achieve this, such as with Selective Disclosure(Selective-Disclosure) and Selective Disruption(Selective-Disruption).",
                "Problem": "Controllers which gain from user activity want to push for participation, but this can negatively affect users.\n\nUsers have varying degrees of concern about their privacy, and do not respond to different forms of encouragement the same way. By penalising under-sharing and inactivity, or being misleading, users become alienated and distrusting of the system. As such this problem has multiple elements. These include asymmetric returns on investment, and the standard incentive deficiency, where users lack the encouragement to participate.\n\n##",
                "Asymmetric Returns on Investment": "In many situations, some benefit more than others. In extreme cases, users may benefit through minimal participation and thus contribute very little to the system's derived value. Those who do not perceive an acceptable value despite considerable contribution may then withdraw.\n\nAn example of this behaviour might be seen in dating sites where users with only a flattering picture may succeed more than those with detailed profiles. Similar cases can be made for other social media, as well as with asymmetric bandwidth on peer to peer sharing. With torrent technologies, this is often referred to as 'leeching'.\n\n##",
                "Standard Incentive Deficiency": "Users which provide limited or vague information due to privacy concerns may have less opportunity for participation. Another way this occurs is when they are not driven by positive social reinforcement. The lack of friends, followers, potential matches, etc. leads to user inactivity.\n\n##",
                "Forces/Concerns": "- Controllers want to encourage users to grow their networks and further participate, though this may increase their exposure to privacy concerns and bad user experience.\n- User concerns over privacy may cause for adverse reactions to unwelcome changes or discoveries in policy, especially attempts to goad or guilt-trip users into activity (e.g. \"This user does not participate\").\n- Where controllers sanction users for inactivity, or undesirable activity, they affect user experience, for better or for worse.\n- Controllers may wish to lock secretive users out of certain services (or products), but this is likely to alienate them.\n- Users may want to use a limited set of functions which do not undermine their privacy, whereas controllers derive less value from these users.",
                "Solution": "Privacy concerns need to be met with valid reassurances about issues which matter to the user. Firstly, users should know that the system holds their preferences in high regard. Secondly, they should perceive real value in their participation. Finally, if desired, users should be assisted in a smooth transition into the ecosystem.\n\n##",
                "Rationale": "#",
                "Implementation": "The three elements of the solution are elaborated on in the following sections.\n\n##",
                "Adherence to Preferences": "Users need to know they are able to participate without the system undermining their personal preferences. This should apply from the very first usage of a system. Everything the system does globally must adhere to privacy friendly defaults. Any service which cannot uphold these expectations should be deactivated for new users, and only be enabled once these users consent to the additional processing. Attempts to solicit this should not be invasive.\n\n##",
                "Value Perception": "With privacy concerns at ease, encouraging equal participation entails reciprocity. These can be in both social and financial forms.\n\nAll participation should result in value derivation (social or otherwise) for all participants, and not just individuals. As a consequence of this mindset, the derived benefits of users who do not participate are limited. This secondary effect may also be the primary mechanism for reciprocity, though positive sum approaches will be met with more support.\n\nAs an additional measure, or where equality is not feasible, provide an alternative incentive. If not social, then financial incentives (discounts, waived fees) can be provided to active users. This can be limited to those who the system can identify as receiving poor value returns on their contributions. User retention examples tend to be less frequent, with the odd website sending 'come back' emails which promise fee reductions.\n\n>_Note that attempting to pinpoint users based on activity levels may reveal more sensitive characteristics, and as such should in any case require their prior informed consent_.\n\nAnother approach is the explicit provision of virtual currency necessary to benefit from the system, those who contribute will then have more currency at their disposal. They may opt to be applauded for their efforts publicly, but again should not be forced to.\n\nExamples of social value perception are the Facebook like/reaction, Google's +1, Reddit Gold, and Twitter's reposting. These approaches are enacted by the users instead of the system, and are therefore less intrusive.\n\n>_The system should permit participation itself without a risk to privacy. Those with low identifiability should not be barred from participation_.\n\n##",
                "Transition Assistance": "In terms of computer aided pairing, greater participation may be achieved if users consent to intelligent nudging. Sh\u00fcmmer suggests that users are more likely to participate when their interests are shared with others, and thus, a system would help users identify those with similar interests. This is another solution which relies on prior consent, however. By encouraging interaction between these users, a system would derive more activity and therefore further value.\n\nOn the other hand, Sh\u00fcmmer points out that mixing dissimilar users may also result in unexpected activity. It may allow the system to discover notions about its users which were not previously apparent. This is yet another way to increase value, though will likely be far more intrusive than the former. Users should be properly informed of the possible consequences of 'mixing it up'.\n\nIn order to ensure that recommendations made by the system do not have increasingly negative side effects, the system should learn from ineffective suggestions. This is limited to where it has permission to do so. Where user activity drops, a system should aim not continue in the same fashion as before. When it climbs, however, the system should improve whatever characteristics likely resulted in that climb.\n\nThis can be made more explicit by soliciting feedback from the user themselves, as also suggested by Sh\u00fcmmer. Even this, though, is subject to negative reactions. However, acclimating users to an environment of openness and transparency will also build trust - potentially resulting in the use of services users would not have used otherwise.",
                "Consequences": "Applying the concepts represented in this pattern may have certain trade-offs associated.\n\n* Some users respond negatively to being nudged into participation, it is also intrusive\n* Learning about interests may be considered invasive, and should require an opt-in, along with assurances for privacy concerns. Furthermore, any assumptions a system makes about a user due to incomplete or misleading data may lead to further reduced activity. Suggesting unappealing interactions might cause the user to seek alternative social media, or withdraw from sharing altogether.\n* Where the system is quite large, it is more resilient against inactive users, and thus can sustain a considerable amount of inequality. However, if an adequate balance is not maintained it may result in an unpredictable ecosystem. Social media giants such as Twitter have struggled to turn a profit(https://finance.yahoo.com/news/snap-low-ball-ipo-valuation-202105572.html \"Snap trying to avoid missteps of Twitter\"), while Facebook's stock price has climbed continually(https://finance.yahoo.com/quote/FB \"FB stock price history\").\n\n#",
                "Constraints": "Isolating users, and learning from their actions, based on feedback loops requires prior informed and explicit consent, as potentially invasive conclusions may be derived",
                "Examples": "1. Examples of Adherence to Preferences\n * TUKAN; a collaborative software development environment which introduces Modes of Collaboration: lightweight contexts which filter collaboration possibilities according to user privacy preferences\n   T. Sch\u00fcmmer, and J. M. Haake (2001). \u201cSupporting distributed software development by modes of collaboration,\u201d in Proceedings of ECSCW 2001, Bonn.\n * Permission restricted Buddy Lists in Instant Messaging, or more extensive social networks; Allowing users to filter their sharing by access groups which they define.\n\n2. Examples of Value Perception\n * Bulletin Board Systems once limited access to content by the amount shared by the user, similarly torrent systems may employ techniques to throttle those who 'leech' excessively without 'seeding'.\n * Facebook like/reaction, Google's +1, Reddit Gold, and Twitter's reposting\n\n3. Examples of Transition Assistance\n * Comparing public interests or activities with that of other consenting users, to indicate potentially like-minded or counterpart individuals; The system may, at the discretion of the user, also compare elements which are not public, without revealing them, to derive more accurate metrics. This is still however limited to the information the user chooses to provide to the system voluntarily.\n * Birds of a Feather Sessions at Conferences are physical analogues to automated grouping of interests in systems, they can take form in less academic examples as well;\n * Collaborative filtering systems make suggestions based on prominent topics within the entire user base without revealing specific user interests or activities. It then makes recommendations based on the norm.\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "Incentivized Participation(Incentivized-Participation) is a compound pattern. It _may use_ a combination of Pay Back(Pay-Back) and Reciprocity(Reciprocity), while also taking ideas from the notions of Sh\u00fcmmer's Train the Recommender and Birds of a Feather patterns. Alone, these patterns are not formulated in the interest of privacy. However, with the addition of Incentivized Participation(Incentivized-Participation) and its constituents having a _must use_ relationship with Lawful Consent(Lawful-Consent), they are a privacy-respecting compound pattern.\n\n* Pre-patterns\n Pay Back; Who\u2019s Listening; Show the Expert; Reciprocity;\n Elephant\u2019s Brain; Find the Guru; Opposites Attract\n\n#",
                "Sources": "T. Sh\u00fcmmer, \u201cThe Public Privacy \u2013 Patterns for Filtering Personal Information in Collaborative Systems,\u201d in Proceedings of CHI workshop on HCHI Patterns, 2004."
            }
        },
        {
            "filename": "Increasing-Awareness-of-Information-Aggregation.html",
            "title": "Increasing awareness of information aggregation",
            "excerpt": "Inform users about the potentially identifying effects of information aggregation to prevent them from unknowingly endangering their privacy.",
            "sections": {
                "Context": "Controllers process mass amounts of user data in order to provide enhanced services (or products). Aggregating this data with other sources unlocks new insights which could not be determined alone. This kind of aggregation is distinct from the notion of abstracting information away from personal data, effectively making it less sensitive. Instead this may turn seemingly harmless data into identifying, intrusive, or inferred information, some of which not even the user is aware of. This makes aggregation very useful for marketing, as well as other more usability-centric features, but places a heavier burden on users to disclose with care.",
                "Problem": "Poor awareness of data aggregation capabilities can lead to unintentionally revealing information being disclosed. Processing this personal data goes against the principles of data protection.\n\n##",
                "Forces/Concerns": "- Users do not want to inadvertently disclose information which may become sensitive or identifying\n- Users are less familiar with the risks of information only becoming invasive sometimes long after disclosure\n- Controllers do not want users to unwittingly consent to disclosures they later regret due to poor awareness\n- Controllers want users to be cognizant of the sensitivity and contextual applicability of their disclosures and how these may be changed by aggregation",
                "Solution": "Provide users with knowledge of data aggregation's ability to reveal undesirable information to prevent them from over sharing. Take users through a hypothetical example to aid in conveying this.\n\n\n\n\n\n\n#",
                "Implementation": "Prior to allowing users to submit content to the controller or other parties, provide them with a warning about data aggregation. This warning is only necessary where aggregation is applied. As such if it is determined after collection that data should be aggregated, this warning would be given prior to obtaining consent for that further processing.\n\nThe warning must make it clear to the user that content they disclose may be more sensitive that it first appears. The context in which they provide it may be subject to changes, and these potential contexts should be provided to the user, or else consented to as they become applicable. The user should not have to deal with broad or otherwise unclear usage of their data.\n\nAt the same time, the user should not be exposed to deep, complex, and lengthy detail unless they choose to review it further. Instead, concise and clear explanations should be used. One approach to this is to provide a hypothetical example in which a controller reveals surprising characteristics about a user from combinations of data, which alone are less informative.\n\nConsider the use of user tests to determine the level of clarity an explanation or example provides. It is important that if a user chooses to accept the risks (and benefits) of aggregation, then they do so knowingly. It is also important not to force aggregation onto users if they choose not to consent. This may prevent the user from gaining a feature, but should not lock them out of functionality which does not require it.",
                "Consequences": "If users understand the power of data aggregation better, they are better able to put any new data they're about to share in perspective to all the data they've already shared, and may consider the total picture this creates of them more carefully. But this also means that it becomes harder for organizations to create accurate profiles of people and may result in improper labeling based on the little data that is known.",
                "Examples": "#",
                "Known Uses": "CryptPad(https://blog.cryptpad.fr/2017/07/07/cryptpad-analytics-what-we-cant-know-what-we-must-know-what-we-want-to-know/) Provides a thorough and clear explanation of their Data Aggregation usage which is linked to from the 'What is CryptPad' page in every instance. Towards the end of the blog post they include graphs to show how useful the data can be, but they also explain what they access, can (but do not) access, and what they cannot access. While this example explains aggregation well, and features a concise summary at the beginning, it could still be better highlighted before a user's first use of the service.\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern is a component of the compound pattern, Awareness Feed(Awareness-Feed). As such, this pattern _may be used_ by it.\n\nThis pattern _refines_ Privacy Awareness Panel(Privacy-Awareness-Panel) and _complements_ Appropriate Privacy Feedback(Appropriate-Privacy-Feedback).\n\nWhile it only aims to solve an overlapping problem, Privacy Awareness Panel(Privacy-Awareness-Panel) considers past and future disclosure decisions and does not differ much from the knowledge of potential sensitivity when aggregated. This pattern therefore provides more a specific application.\n\nAppropriate Privacy Feedback(Appropriate-Privacy-Feedback) provides the same information as Privacy Awareness Panel(Privacy-Awareness-Panel), only through a different mechanism and with a different problem. Through it, the benefit of more general awareness is sought.\n\nThis pattern _may be used_ by Impactful Information and Feedback(Impactful-Information-and-Feedback). As it focuses on analytics about historical queues and measures for warning users, it should inform the user about the risks involved, such as aggregation.\n\n\n#",
                "Sources": "S. Ahern, D. Eckles, N. Good, S. King, M. Naaman, and R. Nair, \u201cOver-Exposed ? Privacy Patterns and Considerations in Online and Mobile Photo Sharing,\u201d CHI \u201907, pp. 357\u2013366, 2007."
            }
        },
        {
            "filename": "Informed-Consent-for-Web-based-Transactions.html",
            "title": "Informed Consent for Web-based Transactions",
            "excerpt": "This pattern describes how controllers can inform users whenever they intend to collect or otherwise use a user's personal data.",
            "sections": {
                "Context": "User data is frequently collected for various purposes. Sometimes this data is personal, personally identifying, or otherwise sensitive. The data may serve to improve a service (or product) offered by a controller, or to provide relevant suggestions or advertisements to users. This is particularly prevalent on the web, as many websites derive most of their income from this data. Where income is instead in the form of purchase, user data is nonetheless needed to provide billing or shipping information. This includes auditing, logging, or other non-repudiation purposes to facilitate transactions.",
                "Problem": "Before collecting data, controllers must make sure users provide informed consent.\n\nControllers utilize persistent local or server-side storage to process potentially identifiable or sensitive information about users in order to perform a transaction. However, _users are often resistant to disclosing personal information because they are uncertain if it will be used without their consent or against their interests_.\n\nControllers need to be able to inform their users about these purposes and means before the user consents.\n\n##",
                "Forces/Concerns": "- Users want to visit websites and make use of the services (or products) offered, but do not want their privacy to be undermined.\n- Users want to have control over their personal information.\n- Controllers may need to process data to conduct business, and may in some cases deny service to those who withhold their data.\n- Controllers may profit from additional user data, and users may too enjoy enriched services.\n- They wish to protect their users from privacy violations, and protect themselves from responsibility, but also aim to secure a viable business model.",
                "Solution": "Provide the user with clear and concise information regarding what may be learned from their data, and how that data can be used to offer or improve the service. Then acquire their explicit, freely-given consent.\n\n#",
                "Structure": "_To the extent possible given the limits imposed by web technology, provide the user with the six elements of informed consent: Disclosure of purpose specification and limitation, Agreement and disagreement capabilities, Comprehension through easily understandable, comprehensive\u00a0and concise explanations, Voluntariness showing that consent is freely-given, Competence to make reasonable legally binding decisions, and Minimal Distraction which may otherwise aggravate the user._\n\n#",
                "Implementation": "Human Computer Interaction concepts expressed in the work of Fischer-H\u00fcbner et al. (2010) allow implementing this pattern in various ways:\n\n- _Just-In-Time-Click-Through Agreements (JITCTAs), i.e. click-trough agreements that instead of providing a large list of service terms confirm the user's understanding or consent on an \"as-needed basis\u201d._ The information shown in JITCTAs includes what data is requested, the controller\u2019s identity and the purpose of processing.\n- _Selection via cascading context menus, where users have to choose more consciously the menu options of data to be released._ This option is intended for simple data request forms with not many fields to be filled.\n- _Drag-and-Drop Agreements (DADAs), which also requires user to make more conscious drag and drop actions for consenting to data disclosures._ The user has to choose an icon that represents some kind of personal data and drag and drop it to an icon representing the controller.",
                "Consequences": "##",
                "Benefits": "- _Helps to reduce information asymmetry between the user and the controller._\n- _Empowers users to make informed decision that do not conflict with their tolerance for private information disclosure._\n- _Provides a basis for trust between the consumer and website owner by establishing an expectation of practice by the website. Consider the risk of lost trust for ecommerce, medical and financial companies such as eBay, Amazon, Bank of America, ehealthinsurance.com, etc.._\n- _This pattern can be applied to many other systems that interact with the user and external systems such as email and location aware devices (e.g. cellphones, PDAs)._\n\n##",
                "Liabilities": "- _This pattern cannot provide any assurance that a website will comply with the informed consent model._\n- _Privacy policies are generally known to be confusing for the user to read and fully understand._\n- _The website may not wish to disclose their ability to track users without their knowledge._\n- _The website may not have the infrastructure to offer and support each of the solution elements for every user. For example, the ability for users to opt-out of the agreement._\n- _If the distraction due to implementing this pattern is sufficiently great, the user may simply cancel the transaction altogether._\n- _Information provided to gain consent is necessarily a) limited and b) manipulated by the site to obtain consent \u2013 this implies that the actual consequences of the revelation of personal information may remain unknown to the user._",
                "Examples": "* Yahoo! Registration Form\n* Intuit Registration Form\n* Google Registration Form\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "Informed Consent for Web-based Transactions(Informed-Consent-for-Web-based-Transactions) may be used by Lawful Consent(Lawful-Consent), as it is one of the compound pattern's possible constituents.\n\nThis pattern _refines_ Obtaining Explicit Consent(Obtaining-Explicit-Consent). In either case the controller in question focuses on informing and getting the user's consent explicitly, with more emphasis on one or the other. In the case of this pattern, it is applied for Web-based transactions in particular.\n\nAdditionally, Privacy Policy Display(Privacy-Policy-Display) or similar is also used by this pattern.\n\n#",
                "Sources": "Based on:\n\nS. Romanosky, A. Acquisti, J. Hong, L. F. Cranor, and B. Friedman, \u201cPrivacy patterns for online interactions,\u201d Proceedings of the 2006 conference on Pattern languages of programs - PLoP \u201906, p. 1, 2006.\n\nFischer-H\u00fcbner, S., K\u00f6ffel, C., Pettersson, J.-S., Wolkerstorfer, P., Graf, C., Holtz, L. E., \u2026 Kellermann, B. (2010). HCI Pattern Collection \u2013 Version 2.\n\nC. Bier and E. Krempel, \u201cCommon Privacy Patterns in Video Surveillance and Smart Energy,\u201d in ICCCT-2012, 2012, pp. 610\u2013615.\n\nC. Graf, P. Wolkerstorfer, A. Geven, and M. Tscheligi, \u201cA Pattern Collection for Privacy Enhancing Technology,\u201d The Second International Conferences of Pervasive Patterns and Applications (Patterns 2010), vol. 2, no. 1, pp. 72\u201377, 2010."
            }
        },
        {
            "filename": "Informed-Credential-Selection.html",
            "title": "Informed Credential Selection",
            "excerpt": "Ensure users are informed of the potential privacy consequences of sharing various authenticating data.",
            "sections": {
                "Also Known As": "Credential Selection",
                "Context": "Controllers offering services (or products) often provide a means to authenticate users in order to permit them access. This access can be to a secure function, such as fulfilling a transaction. Since this action may have difficult to reverse consequences, the controller needs to be certain of the user's identity and informed consent. In order for consent to be valid, the controller must ensure that it is informed, as well as freely given, specific, and unambiguous. In order to determine identity, however, personally identifying information is needed. Some methods of authentication are also more invasive than others, allowing users to provide more information than necessary.",
                "Problem": "Credentials which users supply may be more invasive than necessary, this is a kind of consent which legally must be informed.\n\n##",
                "Forces and Concerns": "- Users want to authenticate so that they know only they can obtain access\n- Users do not want to provide more information than they feel comfortable or than is necessary\n- Controllers want to prevent unauthorized access to user actions, as this can seriously affect their experience\n- Controllers do not want to process user data for which they do not have valid consent",
                "Solution": "Allow granular credential selection which explains to users the various ways in which personal data can be used, including who may access it, and how it may be used to derive further information.\n\n\n\n\n\n\n#",
                "Implementation": "_Present the user with a selection mechanism that shows the user what possible choices are available and then show a summary page that contains the data to be sent._ The explanation of consequences must be shown as the user investigates the available credentials. It should be clear to the user which information authenticates them with the least privacy impact.\n\nOne mental model for this could be the use of a credit card for identification. See the HCI Pattern Collection for further information on this example.\n\n_Independent of a mental model, the credential selection UI should contain two steps, namely, selection and summary. During the first step, all graphical elements of the selection mechanism should be based on the mental model. Thus, if working with the card based metaphor this should be apparent from the UI. During the second step, the invoked mental model is not as important as the key issue is to clearly convey which selected data and which meta-data is being sent._",
                "Consequences": "_Allows a user to identify themselves in a granular way, controlling how much information they reveal by doing so._\n\n_This approach should be used to make it easy for users to select the appropriate credentials. It also should inform them about which (personal) data and meta-data the recipient of the information will have after the transaction._",
                "Examples": "Jiang et al. (2010). \"A Classified Credential Selection Scheme with Disclosure-minimizing Privacy\". International Journal of Digital Content Technology and its Applications, 4 (9), December 2010. 201 - 211.\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ Informed Secure Passwords(Informed-Secure-Passwords). This pattern focuses on informing users about the data released for authentication in certain contexts, elaborating on how such data might be used. Informed Secure Passwords(Informed-Secure-Passwords) focuses on encouraging better use of password-based authentication. With overlapping contexts, these patterns both provide assistance around password-based authentication, together enhancing awareness and usage. Preventing Mistakes or Reducing Their Impact(Preventing-Mistakes-or-Reducing-Their-Impact) may also benefit from the use of this pattern. It seeks to prevent users from unintentionally having their personal data accessed, particularly from automatic disclosure. However due to this contextual distinction, the benefit is less clearly complementary.\n\nThis pattern has an implicit relationship with Unusual Activities(Unusual-activities). This _complements_ relationship stems from Informed Secure Passwords(Informed-Secure-Passwords). While not as strongly connected, this pattern may also benefit from detection and response to compromised authentication methods.\n\n#",
                "Sources": "S. Fischer-H\u00fcbner, C. K\u00f6ffel, J.-S. Pettersson, P. Wolkerstorfer, C. Graf, L. E. Holtz, U. K\u00f6nig, H. Hedbom, and B. Kellermann, \u201cHCI Pattern Collection - Version 2,\u201d 2010.\n\nC. Graf, P. Wolkerstorfer, A. Geven, and M. Tscheligi, \u201cA Pattern Collection for Privacy Enhancing Technology,\u201d The Second International Conferences of Pervasive Patterns and Applications, vol. 2, no. 1, pp. 72\u201377, 2010."
            }
        },
        {
            "filename": "Informed-Implicit-Consent.html",
            "title": "Informed Implicit Consent",
            "excerpt": "Controllers must provide unavoidable notice of a users implicit consent to the processing of their data, where reasonable to do so.",
            "sections": {
                "Also Known As": "Permission to Use Non-sensitive Personal Data - Implicit Consent",
                "Context": "Processing of user (data subject) information, particularly that which potentially identifies a user or group, requires their explicit informed consent. Inaction is not considered valid consent. However, not all instances make this feasible. As such there are circumstances in which legitimate interests of the controller may justify collection without first obtaining a clear statement of permission to do so. Security footage around a controller's premises, or fraud detection, for example, cannot reasonably be made optional to users of the service (or product). What constitutes legitimate interests in these contexts depends on the relationship and reasonable expectations between the controller and user. As such, sensitive data, or special categories of data, are more difficult to justify.",
                "Problem": "A controller needs to collect and otherwise process reasonable information to fulfill their legitimate interests regarding a user, but cannot feasibly acquire each user's explicit consent.\n\n##",
                "Forces and Concerns": "- Users should not have to frequently and explicitly consent for regular, everyday, ubiquitous services which are expected and acceptable for legitimate interests\n- Users do not want to have certain data processed, and need a way to avoid implicitly consenting to it\n- Controllers do not want to have to obtain explicit consent in real-time bulk for expected and acceptable legitimate interests\n- Controllers want to ensure that legitimate consent exists before processing",
                "Solution": "Provide clear and concise notice that by using the service, the user implicitly consents to the processing necessary to fulfill legitimate interests. Ensure that this notice is perceived prior to the application of the effects it describes.\n\n\n\n\n\n\n#",
                "Implementation": "Ensure that users are informed sufficiently prior to any processing with clear and concise notice, the complete detail of which should also be accessible. In digital mediums, this is straightforward, working similarly to Cookie Walls on websites. Users should be given the opportunity to choose not to use the service and therefore not be subject to the processing it requires.\n\nIn physical instances it is more difficult to be sure that users take note of this. On devices, lights have often been used to convey a recording state. This, while clear once already subject to processing, is not sufficient however. Instead, large signs are commonplace to indicate the use of data collection. The most familiar example would be \"Smile, you're on camera\". Of course, this is less clear than \"Our premises is recorded for security purposes, by entering you consent to this processing. See more info at address\". These signs should be posted, visible prior to recording, at all entrances or otherwise where applicable.",
                "Consequences": "Users will be informed before implicitly providing consent to reasonable processing for legitimate interests of the controller.",
                "Examples": "Given a Sensor Network, Provider, and Controller, collected data is delegated by the Controller through the Provider to the Sensor Network. The Sensor Network collects some data with explicit consent, but this data may also be personal for a user who has not given such consent. This data may be potentially identifying, and thus the user should be informed prior to its processing. The Controller must ensure that the Provider of the Sensor Network provides any potential users with unambiguous warning of the collection, and that individual consent is infeasible. This may make use of a clear and legible warning sign. The Sensor Network itself should also be visible and obvious, clearly indicating when collection is ongoing. Societal norms may dictate this, such as security cameras in some contexts (commercial areas where valuables may be stolen) needing little warning.\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ Ambient Notice(Ambient-notice). By extension, it may also be implicitly _complemented by_ Asynchronous Notice(Asynchronous-notice) as an alternative approach. Furthermore, this implicit connection has ties to Preventing Mistakes or Reducing Their Impact(Preventing-Mistakes-or-Reducing-Their-Impact).\n\nIn all these cases, a user needs to be made aware of the implicit nature of their consent. Ambient Notice(Ambient-notice) can complement this intention with continuous, but unobtrusive notice. Its alternative can do so in a model, continual manner, where context changes might justify it. This is less complementary depending on how it is applied. In either case, users need to be prevented from mistakenly sharing personal data.\n\n#",
                "Sources": "Y. Asnar, V. Bryl, R. Bonato, L. Campagna, D. Donnan, P. El Khoury, P. Giorgini, S. Holtmanns, M. Martinez-Juste, F. Massacci, J. Porekar, C. Riccucci, A. Saidane, M. Seguran, R. Thomas, and A. Yautsiukhin, \u201cInitial Set of Security and Privacy Patterns at Organizational Level,\u201d 2007."
            }
        },
        {
            "filename": "Informed-Secure-Passwords.html",
            "title": "Informed Secure Passwords",
            "excerpt": "Ensure that users maintain healthy authentication habits through awareness and understanding.",
            "sections": {
                "Also Known As": "Secure Passwords",
                "Context": "Credentials are required by numerous services (and products) in order to ensure that only authenticated and authorized users have access to certain features. Controllers typically provide authentication mechanisms in the form of usernames and passwords. Although these provide a weak form of security when used incorrectly, they are more convenient for users than many less popular and more secure alternatives. Controllers often try to circumvent the shortcomings of passwords by encouraging users to change them frequently, use stronger variations, check them, and prevent disclosure and reuse. However users make use of many services, and use many passwords, thus discouraging proper application. This misapplication can result in personal data being accessed by unauthorized persons.",
                "Problem": "Users must regularly maintain many strong passwords, remember them, and protect them, but are not well equipped to do so. So instead many choose weak ones and reuse them.\n\n##",
                "Forces and Concerns": "- Users do not want to remember many long or complex passwords\n- Users do not want others to access their secured services\n- Controllers want to protect accounts from unauthorized access\n- Controllers do not want to apply too much pressure to their users to maintain and protect strong and unique passwords",
                "Solution": "Provide users with assistance in understanding and maintaining strong passwords which are easier to remember.\n\n#",
                "Structure": "Assistance is typically provided in the following ways:\n\n- _Passive mechanisms (e.g. help button)_\n- _Static mechanisms (e.g. pop-ups)_\n- _Dynamic mechanisms (e.g. dynamically adjusting message) the method that is most noticed by the users and therefore also most helpful_\n\n#",
                "Implementation": "Short passwords, those at character lengths which are feasible for brute forcing, are not secure. The difficulty to brute force is affected by the known complexity, such as using a variety of character types. However, complexity affects password memorability more than strength. It is more important that passwords are long enough, and varied enough. This does not mean they should be difficult to remember. A couple unrelated words strung together can be a very secure yet memorable password.\n\nThese aspects can be weighted together to provide the user with a strength meter, as well as the explanations behind it. Examples of secure passwords should also be provided, but not accepted as the actual password. Do not enforce the use of special characters and numbers. Length, along with sufficient variation, should be the deciding factor in password strength.\n\nGiven enough resources and time however, state of the art character lengths can be overcome. It is as such useful to change them more regularly than the time it would take to brute force them. Otherwise, the longer that a password remains unchanged, the more likely it is that the password has been compromised.\n\nTherefore a mechanism should also be provided to remind a user when it is time to start thinking of a new password. Based on how strong the original was this may be more or less often. Unusual Activities(Unusual-activities) may also justify a more frequent update.\n\nWhen verifying whether a user used the same password in a second field, to prevent mistypes, simply indicate whether the fields match with a recognizable affirmation. Typically this uses a green theme, and may use a check mark.",
                "Consequences": "_Secure passwords are very important in an interconnected world. Users generally tend to use familiar words such as names of pets and family members and no special characters when creating a password. These passwords can hence be easier hacked using social engineering than longer and more complex passwords. Secure passwords are a necessary step towards personal security. Using the above approach, the user obtains more feedback on the safety of the entered password and is therefore able to create safe passwords that can be remembered._",
                "Examples": "#",
                "Known Uses": "Strongpasswordgenerator.com both provides explanation on state of the art approaches to secure passwords in a layperson friendly manner and helps generate them.\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ Unusual Activities(Unusual-activities), Informed Credential Selection(Informed-Credential-Selection), Appropriate-Privacy-Icons(Appropriate-Privacy-Icons), Icons-for-Privacy-Policies(Icons-for-Privacy-Policies), and Privacy-color-coding(Privacy-color-coding).\n\nWhile Unusual Activities(Unusual-activities) establishes access norms for authentication, this pattern focuses on encouraging better use of password-based authentication. The patterns may work together to aid in detection and response to compromised access, and in users learning from these instances. In Informed Credential Selection(Informed-Credential-Selection), the pattern focuses on informing users about the data released for authentication in certain contexts, elaborating on how such data might be used. With overlapping contexts, these patterns both provide assistance around password-based authentication, together enhancing awareness and usage.\n\nIt has a complementary relationship with the visual cues Appropriate-Privacy-Icons(Appropriate-Privacy-Icons), Icons-for-Privacy-Policies(Icons-for-Privacy-Policies), and Privacy-color-coding(Privacy-color-coding) as these can help provide simple information on password strength and policies.\n\nIt also _complements_ the Auto Create Password pattern.\n\n#",
                "Sources": "S. Fischer-H\u00fcbner, C. K\u00f6ffel, J.-S. Pettersson, P. Wolkerstorfer, C. Graf, L. E. Holtz, U. K\u00f6nig, H. Hedbom, and B. Kellermann, \u201cHCI Pattern Collection - Version 2,\u201d 2010.\n\nC. Graf, P. Wolkerstorfer, A. Geven, and M. Tscheligi, \u201cA Pattern Collection for Privacy Enhancing Technology,\u201d The Second International Conferences of Pervasive Patterns and Applications, vol. 2, no. 1, pp. 72\u201377, 2010."
            }
        },
        {
            "filename": "Lawful-Consent.html",
            "title": "Lawful Consent",
            "excerpt": "A crucial element in privacy protection is ensuring that all sensitive processing is preceded by the acquisition of freely given, informed, specific, and explicit consent.",
            "sections": {
                "Summary": "This pattern covers in detail the legal and social obligations surrounding a data subject's consent to processing of their data in specific circumstances. Every use of the subject's personal data should be covered by an explicit agreement in which the data subject was made aware of the implications of their consent.",
                "Context": "Where data controllers (e.g. organisations) aim to provide a service (or product) to users, there may be opportunities to reuse data, gather feedback, or make use of user data to further their system's value. Many controllers seek to continually collect and utilise this data, often in ways which warrant privacy concerns. For any data processing (including collection), controllers should first obtain consent from the users in question.\n\nThere are social norms surrounding the use of personal data which need to be adhered to if an controller wishes to avoid scrutiny. Users do not inherently trust controllers to handle their personal data with care for privacy. Without clearly defined boundaries, these users may have justifiable concerns about what is learned about them, and how this information may be used. Additionally, various jurisdictions supply varying compliance requirements, and these controllers need to cater to every market they provide to.\n\nDoing otherwise, possibly by disinterest or negligence, may have financial consequences in addition to potential public outcry. Despite this, controllers regularly consider the impact that their decisions may have on competitive edge and resulting profits. The link between better decision making, possibly less sharing, and reduced monetary gains sways some controllers into unlawful forms of consent.\n\nConcerned controllers aim to promote trust in any number of ways, potentially including an Awareness Feed(Awareness-Feed) and or Privacy Dashboard(Privacy-Dashboard) to properly inform their users. The controller in this context may wish to adhere to the corresponding laws for their users, or above that, genuinely value their users' rights to self-determination.",
                "Problem": "An controller aims to maximise the value of their services by gathering as much sharing and participation as possible, potentially seeing user consent as a barrier to functionality and efficiency. They may inadvertently subvert notions of consent by unnecessarily bundling together desirable services with needs for personal information, or downplaying the significance of the data involved. They undermine self-determination at the risk of losing trust from their users, and attracting legal investigations which may rule their practices unlawful.\n\n##",
                "Forces/Concerns": "- Controllers want to encourage participation, and thus may be less concerned with investigating or revealing tradeoffs\n- Controllers may be tempted to bundle various services under a single broad consent request, pressuring users into agreements they might not otherwise accept\n- Users often want to make use of new and exciting features, and therefore easily overlook downplayed privacy risks\n- Some users avoid certain services as they realise the potential privacy risks are not being acknowledged",
                "Solution": "A user should be given every opportunity to assess their sharing choices prior to making their consent. The controller should aid the user in comprehending the tradeoffs apparent in using each of their services, without over-burdening the user. These consented services should be purposed-separated, so that users may make use of functionality without first granting unnecessary consent.\n\n##",
                "Rationale": "Controllers need to ensure that anything they do with a user's sensitive or potentially identifying data is legal. This pertains to lawfully obtained consent, for purposes which are clear and lawful in their own right. Additionally, anything they do should be resistant to backlash from users.\n\n\n\n\n\n#",
                "Implementation": "##",
                "Separate Purposes": "Services should be separated into distinct processes for which distinct consent is acquired. Each purpose requires its own consent. These permissions need to be given subsequent to ascertaining sufficient awareness in the user about the consequences of that consent.\n\n##",
                "Freely Given Consent": "The users should not be pressured into providing consent. Instead, the benefits may be presented along with the trade-offs so that the users may make an informed decision. Some users are not necessarily capable of making these decisions themselves (e.g. children) and thus provisions need to be made to cater to this. The provided information should not be misleading, as coerced consent is not a valid form of permission. One way to present policies in an accessible manner is through comparative examples (e.g. in addition to further detail, what is unique about our privacy policy?).\n\nProviding too much information may also intimidate users into making uninformed decisions, and thus awareness must be garnered in a way which is broadly accessible (see Awareness Feed(Awareness-Feed)). Opportunities for further reading should be available, though should not be necessary to understand the trade-offs involved.\n\n##",
                "Personalized Negotiation": "In more personal services (i.e. one-on-one), personal privacy policies may undergo a formal negotiation. As opposed to user preferences (both at sign-up and through appropriate defaults), understanding a user's personal privacy requirements may benefit from the facilitation of a human representative. This, however, suffers from it's own drawbacks where the representative may misunderstand the user's requirements. Even in interpersonal exchanges, controllers should err on the side of caution. Where available, explicit signing of an agreement aids in proving consent.",
                "Consequences": "With the ability to choose exactly what tradeoffs are agreeable to them, users will be more content, and trusting of the system. They may as a result use more services, and participate more than they otherwise would. Being aware of what information is actually needed to perform certain functionality may also prevent its use, but rightfully so as to prevent backlash.\n\nThe need for certain information for some services will bring inappropriate business processes to the foreground to be rectified, or otherwise questioned. This will likely bring the controller towards better practices, and may affect others as well. Once the public sees the controller's willingness to cooperate, trust will grow even further.\n\nOverall adoption will grow for controllers who are shown to be trustworthy and upfront about their data processing practices. This may very well offset the costs involved in maintaining transparency.\n\n#",
                "Constraints": "Allowing informed and specific consent prevents controllers from soliciting misplaced consent, which greatly reduces the adoption of invasive services. These are often the most profitable services.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "Lawful Consent(Lawful-Consent) is a compound pattern of various other consent-based patterns. Therefore it _may use_ a combination of Informed Consent for Web-based Transactions(Informed-Consent-for-Web-based-Transactions), Obtaining Explicit Consent(Obtaining-Explicit-Consent), and Sign an Agreement to Solve Lack of Trust on the Use of Private Data Context(Sign-an-Agreement-to-Solve-Lack-of-Trust-on-the-Use-of-Private-Data-Context) (or simply, Contractual Consent).\n\nSince it contains crucial elements from each of its constituents, with the potential for additional focus based on context, this compound pattern is useful for every pattern that needs to consider user consent. As such, the list of patterns which _must use_ this pattern is extensive and listed here non-exhaustively. Within patterns for Control they include:\n\n- Decoupling [content and location information visibility](Decoupling-content-and-location-information-visibility);\n- Discouraging blanket strategies(Discouraging-blanket-strategies);\n- Single Point of Contact(Single-Point-of-Contact);\n- Buddy List(Buddy-List);\n- Reasonable Level of Control(Reasonable-Level-of-Control);\n- Outsourcing [with consent](Outsourcing-with-consent);\n- Negotiation of Privacy Policy(Negotiation-of-Privacy-Policy);\n- Private link(Private-link)\n- Active broadcast of presence(Active-broadcast-of-presence);\n- Pay Back(Pay-Back);\n- Reciprocity(Reciprocity);\n- Selective Access Control(Selective-Access-Control);\n- Enable/Disable Functions(Enable/Disable-Functions);\n- Incentivized Participation(Incentivized-Participation); and\n- Support Selective Disclosure(Support-Selective-Disclosure).\n\n##",
                "Based-on": "Explicit Consent / Obtaining Explicit consent via privacy agreement / Permission to Use Sensitive Data via Privacy Agreement / Sign an Agreement to Solve Lack of Trust on the Use of Private Data Context\n\n##",
                "Pre-patterns": "- Creating/Maintaining Privacy Policy;\n- Privacy Dashboard;\n- Policy Matching Display;\n- Visual Cues;\n- Accessible Policies; and\n- Awareness Feed.\n\n#",
                "Sources": "European Parliament, & Council of the European Union. (2015). General Data Protection Regulation. Official Journal of the European Union. Retrieved from http://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1487245302979&uri=CELEX:32016R0679\n\nArticle 29 Data Protection Working Party. (2007). Opinion 4/2007 on the concept of personal data. Working Party Opinions. Retrieved from http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Opinion+4+/+2007+on+the+concept+of+personal+data#0\n\nJ. Porekar, A. Jerman-Bla\u017ei\u010d, and T. Klobu\u010dar, \u201cTowards organizational privacy patterns,\u201d Proceedings - The 2nd International Conference on the Digital Society, ICDS 2008, 2008.\n\nC. Bier and E. Krempel, \u201cCommon Privacy Patterns in Video Surveillance and Smart Energy,\u201d in ICCCT-2012, 2012, pp. 610\u2013615."
            }
        },
        {
            "filename": "Layered-policy-design.html",
            "title": "Layered Policy Design",
            "excerpt": "Make privacy policies easier for users to understand by layering detail behind successively more concise and summarized information.",
            "sections": {
                "Also Known As": "Layered Privacy Policies / Multi-Layered Notices",
                "Context": "As the law in various parts of the world requires a number of considerations, policies tend to be long, complex documents which are difficult to understand. The same holds true for privacy, which supplies its own legislative concerns, particularly regarding data protection. The data controller in these instances, provides users (data subjects) with services (or products) to which privacy policies apply. These suffer the same detail rich and superfluous content pitfalls as other policies, though are legally required to be available to users in a manner which is both understandable and complete.",
                "Problem": "The controller needs to balance comprehension and comprehensiveness in their privacy policies in order to ensure that users choose to inform themselves. If they do not, then processing their information is unlawful.\n\n##",
                "Forces and Concerns": "- Users do not want to read complex and long policies, and most will simply not read them unless they are very concise\n- Users still want to understand any important distinctions which might cause them risks they would rather not take\n- Controllers want to comply with legal requirements to avoid punitive measures as well as bad publicity\n- Controllers also want users to know what they are signing up for when using a service, without being unpleasantly surprised",
                "Solution": "Extract the most crucial aspects of the privacy policy, which users are most likely to read, to the foreground. Nest successive detail levels within these components so that users can quickly find information that is relevant to them.\n\n\n\n\n\n\n#",
                "Implementation": "_A short notice may provide a summary of the practices that deal with personal data, highlighting those which may not be evident to the data subject. Then, a longer policy may provide specific information, split into sections, detailing any uses of personal data. And finally, the whole legal text of the privacy policy can be specified._",
                "Consequences": "_Helps users understand what they can expect about their personal data from a data controller (in terms of which data is managed, for which purposes, etc.)_ Also _fosters simplicity, transparency and choice._\n\n_However, multiple versions of the privacy policies need to coexist, which may introduce potential contradictions; in particular, the data controller must ensure that updates are performed in parallel and coherently._",
                "Examples": "_See examples at Terms of Service Didn't Read(https://tosdr.org/). The average user would take 76 work days to read the privacy policies they encounter each year(http://www.theatlantic.com/technology/archive/2012/03/reading-the-privacy-policies-you-encounter-in-a-year-would-take-76-work-days/253851/)_.\n\n#",
                "Known Uses": "- _An early example of layered privacy policy by TRUSTe(http://www.truste.com/labs/layered-notice/short-notice/example-policy_SN.html) and its mobile version, which are discussed in Pinnick, T. Layered Policy Design(http://www.truste.com/blog/2011/05/20/layered-policy-and-short-notice-design/). TRUSTe Blog, 2011._\n- _There are several sites that use this pattern nowadays, albeit not always with that name. One example is Banksia Villages, which provides a Simplified Privacy Policy(http://www.banksiavillage.com.au/simplified-privacy-policy/) as well as an Extended(http://www.banksiavillage.com.au/privacy-statement/) one._\n- _It is recommended by British Information's Commissioner Office in its Privacy Notices Code of Practice(https://ico.org.uk/media/for-organisations/documents/1610/privacy_notices_cop.pdf) (p.55)_\n- _This concept is quite similar to the Creative Commons license layers(http://creativecommons.org/licenses/) in the field of copyright management._\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ Awareness Feed(Awareness-Feed), Appropriate Privacy Icons(Appropriate-Privacy-Icons), Icons for Privacy Policies(Icons-for-Privacy-Policies), Privacy Labels(Privacy-Labels), Privacy Color Coding(Privacy-color-coding), Abridged Terms and Conditions(Abridged-Terms-and-Conditions), Privacy Aware Wording(Privacy-Aware-Wording), and Privacy Policy Display(Privacy-Policy-Display).\n\nLike many patterns which inform users, elements of Awareness Feed(Awareness-Feed) (like Impactful Information and Feedback(Impactful-Information-and-Feedback)) and its methods for establishing awareness go well with accessible policy aspects like this pattern.\n\nInterpretations of privacy policies and their expression in easily understood summaries could be improved with Appropriate Privacy Icons(Appropriate-Privacy-Icons), Icons for Privacy Policies(Icons-for-Privacy-Policies), and Privacy Color Coding(Privacy-color-coding). This makes for a more accessible solution with visual cues.\n\nAccessible policies like these go well with Abridged Terms and Conditions(Abridged-Terms-and-Conditions), as they _complement_ its need for policy summarization.\n\nAdditionally, where this pattern extracts the most crucial aspects of the privacy policies into layers, these layers could be written following Privacy Aware Wording(Privacy-Aware-Wording). This improves the accessibility of the layered privacy policy. Similarly, Privacy Policy Display(Privacy-Policy-Display) benefits from both of these, in this pattern particularly from its multi-layered approach.\n\nImplicit complementary relationships to this pattern include Dynamic Privacy Policy Display(Dynamic-Privacy-Policy-Display) and Policy Matching Display(Policy-matching-display). Both of these exist through their use of Privacy Policy Display(Privacy-Policy-Display).\n\n#",
                "Sources": "Pinnick, T. Layered Policy Design. TRUSTe Blog, 2011.\n\nChristoph Boesch, Frank Kargl, Henning Kopp, and Patrick Mosby, \u201cprivacypatterns.eu - collecting patterns for better privacy,\u201d 2017. Online. Available: https://privacypatterns.eu/#/?limit=6&offset=0. Accessed: 18-Jul-2017.\n\nMulti-Layered Notices Explained, White Paper, The Center for Information Policy Leadership, Hunton & Williams, http://mddb.apec.org/documents/2005/ECSG/DPM1/05_ecsg_dpm1_003.pdf"
            }
        },
        {
            "filename": "Location-granularity.html",
            "title": "Location Granularity",
            "excerpt": "Support minimization of data collection and distribution. Important when a service is collecting location data from or about a user, or transmitting location data about a user to a third-party.",
            "sections": {
                "Summary": "Support minimization of data collection and distribution. Important when a service is collecting location data from or about a user, or transmitting location data about a user to a third-party.\n\n\nSupport minimization(Minimization) of data collection and distribution.",
                "Context": "When a service is collecting location data from or about a user, or transmitting location data about a user to a third-party.",
                "Problem": "Many location-based services collect current or ongoing location information from a user in order to provide some contextual service (nearest coffee shop; local weather; etc.). Collecting more information than is necessary can harm the user's privacy and increase the risk for the service (in the case of a security breach, for example), but location data may still need to be collected to provide the service. Similarly, users may want the advantages of sharing their location from your service to friends or to some other service, but sharing very precise information provides a much greater risk to users (of re-identification, stalking, physical intrusion, etc.).\n\n\nAccepting or transmitting location data at different levels of granularity generally requires a location hierarchy or geographic ontology agreed upon by both services and a more complex data storage model than simple digital coordinates.  \n\nTruncating latitude and longitude coordinates to a certain number of decimal places may decrease precision, but is generally not considered a good fuzzing algorithm. (For example, if a user is moving in a straight line and regularly updating their location, truncated location information will occasionally reveal precise location when the user crosses a lat/lon boundary.) Similarly, using \"town\" rather than lat/lon may occasionally reveal more precise data than expected when the user crosses a border between two towns.",
                "Solution": "Since much geographic data inherently has different levels of precision (see geographic ontologies(Geographic ontologies), for example) -- like street, city, county, state, country -- there may be natural divisions in the precision of location data. By collecting or distributing only the necessary level of granularity, a service may be able to maintain the same functionality without requesting or distributing potentially sensitive data. A local weather site can access only the user's zip code to provide relevant weather without ever accessing precise (and therefore sensitive) location information.\n\nA similar pattern is location fuzzing(Fuzzing) which uses an algorithm to decrease the accuracy of location data without changing its lat/lon precision. This may be useful if the application only functions on latitude/longitude data, but can be vulnerable to attack.\n\nIn some cases, less granular data may also better capture the intent of a user (that tweet was about Sproul Plaza in general, not that particular corner) or be more meaningful to a recipient (\"Nick is in Berkeley, CA\" means more to my DC relatives than the particular intersection). For more along these lines, see, for example, the Meaningful Location Project(http://www.meloproject.com/team).",
                "Examples": "1. _Fire Eagle location hierarchy_\n\n   !Fire Eagle granularity screenshot(/media/images/Fire_Eagle_granularity.png)\n\n   Yahoo! Fire Eagle allows user to provide location information to applications using eight different \"levels\" of granularity in their hierarchy(http://fireeagle.yahoo.net/developer/documentation/location): \n\n   * No information\n   * As precise as possible\n   * Postal code\n   * Neighborhood\n   * Town\n   * Region\n   * State\n   * Country\n\n   Fire Eagle specifically requires that recipient applications be written to handle data at any of the levels, and allows updating the user's location at any level of granularity.\n\n2. _Twitter \"place\" vs. \"exact location\"_\n\n   Twitter(https://support.twitter.com/articles/78525-about-the-tweet-location-feature) allows users to tag a tweet with either exact coordinates, a Twitter \"place\" (a town, neighborhood or venue) or both.\n\n3. _Geode_\n\n   One of the fore-runners to the W3C Geolocation API, Firefox's experimental Geode feature allowed JavaScript access to the current location at four different levels of granularity.{{fact}}"
            }
        },
        {
            "filename": "Masquerade.html",
            "title": "Masquerade",
            "excerpt": "Let users filter out some or all personal information they would otherwise provide to a service.",
            "sections": {
                "Also Known As": "Anonymous Interaction",
                "Context": "Users are frequently monitored for various reasons by a service (or product), for instance to associate them with shared activity. Monitoring is sometimes needed to allow users to know certain attributes about one another which can assist them in communicating or otherwise participating. This monitoring is sometimes apparent to the user, opted-in, or unavoidable. This may cause some users distress, or affect their actions for better or for worse. Many working environments additionally feature productivity tracking software or the ability to _Gaze Over the Shoulder_. This of course allows any altered activity to have an effect on work performance, or its perception. Mandatory tracking is commonly undesirable for users, and in these cases can negatively affect user experience.",
                "Problem": "Users act differently under active supervision, and this may negatively impact their content generation.\n\n##",
                "Forces/Concerns": "- Controllers may require monitoring for the functioning of the service or depend on it as a business model.\n- Users have an interest in restricting the amount to which they are monitored.\n- Every user could require a different level of identifiability depending on the context.\n- It would be necessary to at least have Partially Identification(Partial Identification) of the user when implementing Reciprocity(Reciprocity).",
                "Solution": "Allow users to select their desired identifiability for the context in question. They may reveal some subset of the interaction or account attributes and filter out the rest.\n\n\n\n\n\n\n#",
                "Implementation": "For implementing this pattern, a configuration interface will be required. Two approaches could be considered: levels of publicity or publicity profiles.\n\nIn levels of publicity, all possibly revealed information could be arranged on a scale depending on how identifying each kind of information is alone or when shown together. A visual element could be used to select a specific publicity level. When the users select one level, all information with the same or smaller publicity level will be revealed. This is taken into account when measuring where upon the scale a piece of information falls.\n\nIn publicity profiles, all possibly revealed information could be depicted using visual elements and the users have to select each kind of information that they want to reveal. Furthermore, depending on the kind of information, the users could define different granularity for each one (E.g. regarding location it is possible to define the country, region, city, department and so on).\n\nReciprocity(Reciprocity) could implemented by _connecting privacy levels with permissions for interaction._",
                "Consequences": "##",
                "Benefits": "- _Since users can explicitly control how much personal information they provide to other users, they no longer have to fear that their personal information is being misused by other users. This provides them with an environment that is as private as the situation demands._\n- _Users can decide to discuss private matters without the possibility of being monitored by other users by simply changing their privacy profile or privacy level._\n\n##",
                "Liabilities._": "- _Anonymous interaction with the system may lower the inhibition threshold for destructive or forbidden behavior. The users do not have to fear that destructive activities are associated with their identity. Thus, the controller should provide only limited functionality for anonymous users (e.g. only read access or only moderated postings to a discussion board)._",
                "Examples": "- Video systems: NYNEXPortholes (Lee, Girgensohn, and Schlueter 1997);\n- TUKAN (Schummer and Haake 2001);\n- Anonymous access in web-based communities.\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern may be used by Reasonable Level of Control(Reasonable-Level-of-Control), as contextual identifiability may be featured in the application of Reasonable Level of Control(Reasonable-Level-of-Control). It is also complemented by Private link(Private-link), which is one such method to provide information to a specific audience, and Active broadcast of presence(Active-broadcast-of-presence), broadening the scope for the audience instead.\n\nThis pattern _complements_ Support Selective Disclosure(Support-Selective-Disclosure), as it allows setting identifiability per context while the other provides granular information which could lead to identifiability. Together they focus more on this aspect than disclosure as such.\n\nIt also _may use_ Buddy List(Buddy-List), as when one is deciding to whom their info is going to be shared, a Buddy List(Buddy-List) could assist that selection.\n\nAdditionally, Masquerade(Masquerade) _leads to_ Reciprocity(Reciprocity). The application of this pattern creates a potential avenue for abuse or misuse by users who choose to remain anonymous. In order to prevent this, users may be given reciprocal capabilities according to their identifiability level.\n\nAs per Sch\u00fcmmer et al. (2004), it also is complemented by:\n\n- Don\u2019t Disturb;\n- Gaze Over the Shoulder (dark-pattern);\n- Reciprocity(Reciprocity)\n\n#",
                "Sources": "Based on:\n\nT. Sch\u00fcmmer, \u201cThe Public Privacy \u2013 Patterns for Filtering Personal Information in Collaborative Systems,\u201d in Proceedings of CHI workshop on Human-Computer-Human-Interaction Patterns, 2004."
            }
        },
        {
            "filename": "Minimal-Information-Asymmetry.html",
            "title": "Minimal Information Asymmetry",
            "excerpt": "Prevent users from being disenfranchised by their lack of familiarity with the policies, potential risks, and their agency within processing.",
            "sections": {
                "Context": "Users frequently interact with controllers whose services (or products) they have not used before. At this point the knowledge the user has about the controller and its practices, especially regarding privacy, is typically nonexistent. The controller as a whole has a much clearer understanding of its policies. It also begins to know a lot about the user in a short time period, if not already well informed. The user needs to put in sufficient effort to investigate the controller to know about its practices to provide valid consent. The controller needs this valid consent to lawfully process the user's information.",
                "Problem": "Controllers have far more information than the users who utilize their services, which makes the users vulnerable to exploitation.\n\n_Information asymmetry is generally described as one party having more or better information about a transaction than the other._ In order for a healthy consumer relationship to ensue, users should know close to as much about the controller's practices as it would be expected to itself.\n\n##",
                "Forces and Concerns": "- Users sometimes want to use services of an unknown party, and are cautious about what it might do with their data\n- Users may not want to provide any more information than necessary, but want the services to function properly\n- Controllers want users to understand the intentions behind the data they collect, and be content with how they use it\n- Controllers need to ensure that users understand purposes and means for processing before their consent will be valid",
                "Solution": "Require minimal information from the user, so that only as much personal data as is required, explained, and consented to, is processed. Further reduce the imbalance of policy knowledge by writing clear and concise policies rather than, or in addition to, complex and verbose ones.\n\n\n\n\n\n\n#",
                "Implementation": "Limit the amount of data needed to provide the services necessary to the users, and where appropriate, prefer less sensitive data to do so. Give users the option to opt in to features which require more data, but keep it minimal by default. If the amount of data needed is minimized, then users have less they need to understand, and less to disagree with. This also allows for more simple policies.\n\nMaking policies more clear and concise is also crucial, as users will not want to sift through long-winded texts to understand what would happen with their data. Highlight important aspects for users themselves, rather than allowing them to become cluttered with legal jargon, detail, and complexity. While certain elements cannot be explained adequately without doing so at length, not all aspects are relevant at once. Some elements may be summarized without the detail, so that users may better understand the current focus. The full detail should still exist however, and be easily located.",
                "Examples": "#",
                "Known Uses": "_Many online organizations provide signals to their customers. Often they are publicly and freely available, but can also be purchased by third parties. The online auction site, eBay, for example, uses a reputation system to assist other buyers in feeling more comfortable purchasing from an unknown seller. Many other ecommerce sites (such as Amazon) rely heavily on the reputation and referral systems in order to help customers make a more informed decision._\n\n_Websites are more commonly publishing their privacy policies in order to assuage the privacy concerns of their users ECC2005. Users are also stating that they would be more comfortable interacting online if the site had displayed the TRUSTe(http://www.truste.org) or BBBOnline(http://www.bbbonline.org) symbols, or had a privacy policy CRA1999._\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ Privacy Mirrors(Privacy-Mirrors) and Personal Data Table(Personal-Data-Table).\n\nThis pattern supports informed user agency through explanations of policy and potential risks. This is compatible with the solution suggested in Privacy Mirrors(Privacy-Mirrors), as it provides a general solution for managing identify through informing and controlling sharing decisions. Together they could compose a better identity management solution for the user.\n\nPersonal Data Table(Personal-Data-Table), like this pattern, allows a user to see what personal data is acquired by the controller. It provides a tabular overview of what is still retained for that user. Together these patterns show a clearer representation for the user to consider.\n\n#",
                "Sources": "S. Romanosky, A. Acquisti, J. Hong, L. F. Cranor, and B. Friedman, \u201cPrivacy patterns for online interactions,\u201d Proceedings of the 2006 conference on Pattern languages of programs - PLoP \u201906, p. 1, 2006.\n\nS. Engelman, L. F. Cranor, A. Chowdury, \u201cAn analysis of P3P-Enabled web sites among Top-20 Search Results\u201d Carnegie Mellon University, 2005.\n\nL. Cranor, J. Reagle, M. Ackerman, \u201cBeyond Concern: Understanding Net Users\u2019 Attitudes About Online Privacy\u201d AT&T Labs, 1999."
            }
        },
        {
            "filename": "Negotiation-of-Privacy-Policy.html",
            "title": "Negotiation of Privacy Policy",
            "excerpt": "Over time, build user preferences from a privacy-preserving default semi-automatically, through opt-in/opt-out, semantics, and informed solicitations.",
            "sections": {
                "Context": "Often when users find a service (or product) they would like to use, and begin signing-up, they are immediately exposed to assumptions which may not hold for them. As users have differing privacy priorities, a controller cannot guess as to what settings best accommodate them. Since these preferences may be intricate, users cannot be expected to specify them in detail all at once or before using the service.",
                "Problem": "Users have sometimes wildly different priorities regarding their privacy, though a controller does not know these details when a user first joins a service. There is a temptation to provide these users the settings the average user uses.\n\n##",
                "Forces/Concerns": "- Users are different and do not all fall under one universal setting without some being unsatisfied.\n- The controller wants to cater to user individuality.\n- Getting users to specify all of their individual tastes before using a service will make some users abandon the process. Some settings may be missed, and many users will be upset.",
                "Solution": "As users begin to use a service, determine their individual privacy sensitivities by allowing them to opt-in/opt-out of account details, targeted services, and telemetry. When a user's preference is not known, assume the most privacy-preserving settings. It should always take more effort to over-share than to under-share.\n\n\n\n\n\n\n#",
                "Implementation": "Unauthenticated users should enjoy the most privacy-preserving defaults. When a user joins the service, they may be presented with excerpts or summaries of a privacy policy, which they can use to inform their choices. Using simple, recognizable controls, users can be asked to opt-in (for explained benefits) or opt-out (at explained costs) before any of their data is used. They can then be asked for additional consents further down the line as they become contextually relevant.\n\nIn this way, only the needed consent is asked for as the controller's understanding of the user's preferences improves. This can allow the service to determine which solicitations users are individually likely to consider, and which ones will only waste their time or upset them.",
                "Consequences": "Private defaults will often not be the appropriate settings for a user, as most users may be less privacy-concerned. The additional effort taken to share more, with users or the controller, will reduce the valuable data collected. However, providing users with invasive defaults would risk public outrage by the vocal few, who may affect opinions holistically.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern is used by Support Selective Disclosure(Support-Selective-Disclosure), a compound pattern. It is also complemented by Discouraging blanket strategies(Discouraging-blanket-strategies) (avoiding all or nothing strategies for privacy settings) and Decoupling [content and location information visibility](Decoupling-content-and-location-information-visibility) (change the privacy every time content is being shared).\n\nNegotiation of Privacy Policy(Negotiation-of-Privacy-Policy) _refines_ Reasonable Level of Control(Reasonable-Level-of-Control), which describes methods which allow users to share their information (selectively and granularly), while this pattern targets the beginning of the service use.\n\nIt is _similar to_ Enable/Disable Functions(Enable-Disable-Functions), where users may switch between functionalities which affect their privacy. This solution is quite similar to opting in or out of those features. Specifically a similar problem is addressed from non-functional as opposed to functional perspectives.\n\nThis pattern _must use_ Lawful Consent(Lawful-Consent) in order to be implemented correctly. Additionally, due to the same need for notified and informed users in this pattern, the following patterns also complement this pattern:\n\n- Ambient(Ambient-Notice)/Asynchronous Notice(Asynchronous-Notice),\n- Preventing mistakes or reducing their impact(Preventing-mistakes-or-reducing-their impact),\n- Awareness Feed(Awareness-Feed) (and components), and\n- Privacy Dashboard(Privacy-Dashboard) (and components).\n\n\n#",
                "Sources": "Based on:\n\nJ. Porekar, A. Jerman-Bla\u017ei\u010d, and T. Klobu\u010dar, \u201cTowards organizational privacy patterns,\u201d Proceedings - The 2nd International Conference on the Digital Society, ICDS 2008, 2008."
            }
        },
        {
            "filename": "Obligation-management.html",
            "title": "Obligation Management",
            "excerpt": "The pattern allows obligations relating to data sharing, storing and processing to be transferred and managed when the data is shared between multiple parties.",
            "sections": {
                "Summary": "The pattern allows obligations relating to data sharing, storing and\nprocessing to be transferred and managed when the data is shared\nbetween multiple parties.",
                "Context": "The developer aims to make sure that multiple parties are aware of and\ncomply with required user/organisational policies as personal and\nsensitive data are successively shared between a series of parties who\nstore or process that data.",
                "Problem": "Data may be accessed or handled by multiple parties that share data\nwith an organisation in ways that may not be approved by the data\nsubject.",
                "Solution": "Service providers use an obligation management system. Obligation\nmanagement handles information lifecycle management based on\nindividual preferences and organisational policies. The obligation\nmanagement system manipulates data over time, ensuring data\nminimization, deletion and notifications to data subjects.",
                "Consequences": "Benefits: privacy preferences and policies are communicated and adhered\nto among organisations sharing data. Liabilities: additional effort to\nset obligations.",
                "Examples": "A service provider subcontracts services, but requires that the data\nto be deleted after a certain time and that the service provider\nrequires to be notified if there is further subcontracting.\n\n#",
                "Known Uses": "Pretschner et al (2009) provide a framework for evaluating whether a\nsupplier is meeting customer data protection obligations in\ndistributed systems. Researchers at IBM propose Enterprise Privacy\nAuthorization Language (EPAL) (2004) to govern data handling practices\naccording to fine-grained access control. Casassa Mont (2004) discusses\nvarious important aspects and technical approaches to deal with\nprivacy obligations. Pretschner, A., Schtz, F., Schaefer, C., and\nWalter, T.: Policy Evolution in Distributed Usage Control. Electron.\nNotes Theor. Comput. Sci. 244, 2009 IBM, The Enterprise Privacy\nAuthorization Language (EPAL), EPAL specification,\nhttp://www.zurich.ibm.com/security/enterprise-privacy/epal/, 2004\nMont, M. C., Dealing with Privacy Obligations, Important Aspects and\nTechnical Approaches, TrustBus, 2004"
            }
        },
        {
            "filename": "Obtaining-Explicit-Consent.html",
            "title": "Obtaining Explicit Consent",
            "excerpt": "Controllers require consent to be given willingly and specifically when in any way processing the personal data of their users.",
            "sections": {
                "Also Known As": "Explicit Consent / Obtaining Explicit consent via privacy agreement / Permission to Use Sensitive Data via Privacy Agreement - Explicit Consent",
                "Context": "In order to offer services (or products) to users (data subjects), controllers often need to collect (process) user data. Sometimes this is sensitive, identifying, or just metadata or other information which may be correlated to become more invasive. This nonetheless enables them to offer competitive features and functionality.\n\nHowever, controllers are required to obtain unambiguous consent from their users in order to process their personal data in any way. Depending on the legal jurisdiction, there are additional considerations to take into account depending on the type of data in question. Typically, sensitive data requires especially rigorous care.",
                "Problem": "Controllers which aim to make use of user data, especially that which can be used to identify the user or sensitive aspects about the user, may not do so without a legally binding and sound acquisition of the user's consent.\n\n##",
                "Forces/Concerns": "- Users want to use services without having to invest an inordinate amount of effort into discovering privacy risks.\n- Controllers need to be sure that users do not consent out of impatience or intimidation.\n- Users do not want to consent many times to the same service under the same privacy policy for each and every purpose.\n- Controllers need to be able to prove that users consented.",
                "Solution": "Provide a clear and concise notification of all pertinent information the service could derive provided it had all the data it asks for. Indicate what this means for features and functionality. Then ask the user whether this tradeoff is something they consent to. If true, digitally signify and timestamp their response, or use Contractual Consent(Sign-an-Agreement-to-Solve-Lack-of-Trust-on-the-Use-of-Private-Data-Context).\n\n\n\n\n\n\n#",
                "Implementation": "The controller must ensure each user's sufficient understanding of the potential consequences. Otherwise the consent might not be informed. They must verify their users' willingness despite those consequences to provide their data for the specific purposes they need. If they do not, the consent might not be freely given.\n\nEnsuring that users do not consent based on time constraints, or the intimidation of the information provided, may require testing with a sample. If the sample is representative, it will give the controller a defense against any claims of coercion.\n\nThe mechanism used for users to signify their consent should be clear. For example, if it is a button, it could read \"I consent.\"",
                "Consequences": "##",
                "Benefits": "Controllers can derive clearer potential consequences when the data collected is the same for every consenting user. Users therefore can look over these risks and spend less time making a valid decision. This reduces the chances of users consenting without informing themselves due to the difficult or verbose content presented.\n\n##",
                "Liabilities": "Users do not however want to consent to all purposes necessarily since they might not all be compatible with what they feel comfortable sharing. In these cases users can be presented with a type of Selective Disclosure(Selective-Disclosure).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "Thus pattern may be used by Lawful Consent(Lawful-Consent), as it is one of the patterns featured within it as a compound pattern.\n\nObtaining Explicit Consent(Obtaining-Explicit-Consent) is _similar to_ Sign an Agreement to Solve Lack of Trust on the Use of Private Data Context(Sign-an-Agreement-to-Solve-Lack-of-Trust-on-the-Use-of-Private-Data-Context). This Contractual Consent merely focuses on the need for non-repudiation more so than Obtaining Explicit Consent(Obtaining-Explicit-Consent). Their perspectives are different while their overall solution is more or less the same.\n\nIt also is refined by Informed Consent for Web-based Transactions(Informed-Consent for-Web-based-Transactions). It is a refinement of, and is used by, Lawful Consent(Lawful-Consent). In both cases the controller aims to inform users prior to obtaining their consent, though in the other pattern's case it is applied specifically for Web-based transactions.\n\nPorekar et al. (2008) also highlight this pattern's complementing Enforce patten relationships:\n\n- Constructing Privacy Policy(Creating-Privacy-Policy);\n- Maintaining Privacy Policy(Maintaining-Privacy-Policy);\n- Privacy Policy Negotiation(Negotiation-of-Privacy-Policy);\n- Maintaining agreements over longer periods of time\n\n#",
                "Sources": "Based on:\n\nJ. Porekar, A. Jerman-Bla\u017ei\u010d, and T. Klobu\u010dar, \u201cTowards organizational privacy patterns,\u201d Proceedings - The 2nd International Conference on the Digital Society, ICDS 2008, 2008.\n\nC. Bier and E. Krempel, \u201cCommon Privacy Patterns in Video Surveillance and Smart Energy,\u201d in ICCCT-2012, 2012, pp. 610\u2013615.\n\nY. Asnar et al., \u201cInitial Set of Security and Privacy Patterns at Organizational Level,\u201d no. December 2006, 2007."
            }
        },
        {
            "filename": "Onion-routing.html",
            "title": "Onion Routing",
            "excerpt": "This pattern provides unlinkability between senders and receivers by encapsulating the data in different layers of encryption, limiting the knowledge of each node along the delivery path.",
            "sections": {
                "Summary": "This pattern provides unlinkability between senders and receivers by\nencapsulating the data in different layers of encryption, limiting the\nknowledge of each node along the delivery path.",
                "Context": "A system in which data is routed between different nodes.",
                "Problem": "When delivering data, the receiver has to be known. If the system\nprovides the functionality that the receiver of data should be able to\nanswer, than the receiver should also know the address of the sender.\nWhen forwarding information over multiple stations then, in a naive\nimplementation, each station on the delivery path knows the sender and\nthe final destination.",
                "Solution": "The solution is to encrypt the data in layers such that every station\non the way can remove one layer of encryption and thus get to know the\nimmediate next station. This way, every party on the path from the\nsender to the receiver only gets to know the immediate successor and\npredecessor on the delivery path.\n\n\nThe goal of this pattern is to achieve unlinkability between senders\nand receivers.",
                "Consequences": "If there are too few hops, the anonymity set is not big enough and the\nunlinkability between sender and receiver is at risk. The same problem\noccurs when there is too few communication going on in the network.\nThe multiple layers of encryption will bloat up the data and consume\nbandwidth. If all nodes on the delivery path collaborate in deducing\nthe sender and the receiver, the pattern becomes useless.",
                "Examples": "Alice is a whistle-blower and tries to forward data to Bob who works at\nthe press. She sends the corresponding documents as an\ne-mail-attachment. Eve monitors the traffic and can see who sent this\nmail to whom. The next day, police raids Alice's apartment and sends\nher to jail. Bobs mail account gets seized.\n\n#",
                "Known Uses": "The TOR-browser, a web-browser specifically designed to ensure\nanonymity makes heavy use of onion routing."
            }
        },
        {
            "filename": "Outsourcing-[with-consent].html",
            "title": "Outsourcing [with consent]",
            "excerpt": "\u201cThe controller has to obtain additional specific, informed, explicit, and freely given consent before outsourcing data processing to a third party.\u201c",
            "sections": {
                "Context": "Controllers often do not have the means to feasibly or sufficiently process the data they oversee to the extent they desire. In these cases they seek an external processor or third party to handle the process. This typically conflicts with their already obtained consent from their users (their data subjects), as further processing by a third party is not necessarily compatible with the agreed upon purposes. In these situations the controller does not have legally obtained consent for this processing and will be liable if they carry it out.",
                "Problem": "Third party processors do not inherent user consent granted to a controller, but need each user's consent before they may process their information. The processor cannot contact the necessary users as they have no lawful access to any means to identify them.\n\n##",
                "Forces/Concerns": "- Controllers wish to outsource processing when it is not feasible or viable to do so themselves.\n- Third party processors want to process information efficiently without needing to address other considerations.\n- The controller does not want to be liable, or damage their reputation.\n- Outsourcing _has a strong impact on the security and privacy requirements of organizations_.\u00a0A contract will bind both parties.\n- _The outsourced third party will be obliged by all data protection principles_ to which the controller is, in addition to stricter measures imposed on processors.",
                "Solution": "Obtain additional (Lawful Consent)Lawful-Consent for the specific purposes needed from each user before allowing the third party to process their data. Do not process the data of users who do not consent.\n\n_The consent can be seen as a contract establishing what and how data will be processed by the third party. The controller must also ensure, preferably by a written agreement, that the third party strictly follows all conditions relating to data processing that were imposed on them._\n\n\n\n\n\n#",
                "Implementation": "Before outsourcing data processing, it is necessary to obtain consent from the user and create an agreement between the controller and the third party. The consent itself needs to be freely given, informed, specific, and explicit. It should indicate purposes and means (physical or informational) regarding the controller and the third party. There is also an execution dependency between the controller and the user.\n\nFigure 2(b) shows an SI* model explaining the solution of Compagna et al. (2007)",
                "Consequences": "##",
                "Benefits": "_The pattern solves the problem of granting the consent necessary to perform out-sourced data processing by assuring users that their information is processed according to the contract._\n\n##",
                "Liabilities": "_The controller may want assurance that the third party does not repudiate the data processing agreement and the user does not repudiate the consent._ As such the controller may decide to use the Non-repudiation(Non-repudiation) pattern.",
                "Examples": "The scenario described by Compagna et al. (2007) features a Health Care Centre (data controller) and a user (data subject), Bob, who needs constant supervision. The subcontractor, a Sensor Network Provider (third party supplier), installs and maintains the network responsible for automated monitoring of Bob's health. This subcontractor needs additional specific, informed, explicit, and freely given consent from Bob.\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _must use_ Lawful Consent(Lawful-Consent) in order to be implemented. It also benefits from using the Non-repudiation(Non-repudiation) pattern.\n\n#",
                "Sources": "L. Compagna, P. El Khoury, F. Massacci, R. Thomas, and N. Zannone, \u201cHow to capture, model, and verify the knowledge of legal, security, and privacy experts : a pattern-based approach,\u201d ICAIL \u201907, 2007."
            }
        },
        {
            "filename": "Pay-Back.html",
            "title": "Pay Back",
            "excerpt": "Give users some benefits in exchange for providing information or content.",
            "sections": {
                "Context": "In services where users may contribute content, or provide the system with account or profile information, the information is only valuable if relevant and accurate. For controllers providing this service (or product), worthless information does not typically generate income or future participation. Without consistent usage, a service becomes less popular and eventually may run at loss. This is particularly true in socially oriented services. To keep the service working, it is crucial that its users maintain content. Users however, might not feel inclined to do so. Keeping content up to date, or adding it in the first place, requires effort, and in some cases an acceptance of privacy risk.",
                "Problem": "Users do not necessarily want to provide and maintain content, they need a motivation to do so. Without this, a service will not flourish.\n\nNot all users will be equally motivated, so the service may not receive contribution at the level required to keep the service competitive. Furthermore, some users might not contribute at all. _Thus, it is difficult to maintain Reciprocity(Reciprocity)_.\n\n##",
                "Forces/Concerns": "- A service that depends on information flow requires a continuous feed of user activity.\n- If users are not motivated they likely will not continue to contribute content.\n- Some users do not require much motivation, and the use of the service could be enough for them to contribute. But this alone is insufficient for most services to run.",
                "Solution": "Provide users with different kinds of benefits when they contribute or maintain content for the service and make sure they do so consensually.\n\n\n\n\n\n\n#",
                "Implementation": "Depending on the kind of service that is provided, different benefits could be considered: virtual or real currency, use of services, social benefits, and so on.\n\nWhen using virtual or real currency, the controller should first define how much in value users would receive depending on the contributions. In the case of virtual currency, the places where the currency could be used should be defined.\n\nRegarding use of service, some criteria could be considered non-exhaustively: feedback on content, frequency of contributions, the use of service for a minimum duration, access to a service earlier than others, or use of special features within the service.\n\nWhen users reach a limit, they could additionally assist with virtual or physical events for learning, meeting people, etc. In virtual scenarios, users could receive attention (feedback) from one another.",
                "Consequences": "##",
                "Benefits": "- More users will be motivated to provide information, so the service could continue to be competitive.\n- It could help to maintain Reciprocity(Reciprocity).\n\n##",
                "Liabilities": "- It could be necessary to monitor the quality of the contributions before giving the user benefits.\n- Consent will not be genuine if users are coerced into providing their personal data. An example of this is the sunk cost fallacy. As the user builds emotional investment, the controller has more power over them. A service which was once available freely, or anonymously, can push users into accepting terms they do not truly consent to. When using this pattern it is important to make sure that Lawful Consent(Lawful-Consent) is also used.\n\n\n\n\n\n\n\n\n\n\n*YouTube financial retribution.\n*Dropbox increasing storage programs.\n*Local guides for Google Maps.\n*Likes, comments, followers in Facebook, Instagram.\n\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "Pay Back(Pay-Back) _complements_ Reciprocity(Reciprocity). These two patterns may work together to incentivize users to provide data. It may be used by Incentivized Participation(Incentivized-Participation), which builds on this relationship.\n\nAdditionally, as Pay Back(Pay-Back) encourages users to provide additional data, it must be sure to obtain Lawful Consent(Lawful-Consent). This is a _must use_ relationship.\n\n#",
                "Sources": "Based on:\n\nT. Sch\u00fcmmer, \u201cThe Public Privacy \u2013 Patterns for Filtering Personal Information in Collaborative Systems,\u201d in Proceedings of CHI workshop on Human-Computer-Human-Interaction Patterns, 2004."
            }
        },
        {
            "filename": "Personal-Data-Table.html",
            "title": "Personal Data Table",
            "excerpt": "In order for users to see what information a controller has about them, they can be provided with a detailed tabular overview of that data upon request.",
            "sections": {
                "Context": "Controllers which maintain software systems that process user data, especially identifying or sensitive data, are subject to various laws. In the case of personal data, transparency about processing is particularly important. Users (the data subjects) also care to know about what data is used, and what might be done with that data, at various degrees. Users do not often want to be constantly notified or reminded, as many of them would rather spend their time actually using the system. Some users, however, care about more intricate detail, and are entitled to it. Nonetheless, if verbose information is provided, it should be sensible.",
                "Problem": "The controller wants to be upfront about what they know and can do with personal data which might be of importance to those users. They only want users to know about data and risks pertaining to them specifically.\n\n##",
                "Forces and Concerns": "- The controller wants to show the actual data they process, as well as what they do with it, as opposed to just describing policy\n- Users want full transparency, with detailed explanation as well as easily and quickly understood overviews\n- Controllers do not want this transparency to ruin trust, but to strengthen it\n- The controller wants to keep the data on their servers, while still allowing users to automatically view their own data",
                "Solution": "Keep track of the processing that occurs on personal data so that users can view the activities associated with their data and review their preferences in a tabular environment.\n\n#",
                "Structure": "_Which information_\n_A table that shows the overview. The overview could show:_\n\u2212 _Which data_\n\u2212 _Why collected_\n\u2212 _How used/for which purpose collected_\n\u2212 _Who has access to the data_\n\u2212 _Who the user authorized for access_\n\u2212 _Which consent the user has given for specific data_\n\u2212 _To which parties the data is disclosed_\n\u2212 _Who has seen the data_\n\u2212 _Whether the data can be hidden_\n\u2212 _Whether the data can be removed_\n\u2212 _How long the data is stored_\n\u2212 _How datasets are combined to create richer (privacy sensitive) information. Note that this may violate local laws and regulations_\n\u2212 _With which other information the data is combined_\n\n_Where in the application flow Options are (not mutually exclusive):_\n\u2212 _At the service\u2019s help section_\n\u2212 _At the service\u2019s privacy section_\n\u2212 _Through a separate menu item_\n\u2212 _At a myData section of the service_\n\n_Amount of information_\n_A table can show a lot of information or can be adjustable by the user to tweak which information to show, and which values (e.g. which range). From the table links to applicable other pages/screens can be given, to allow a user to easily change privacy settings (or possibly delete data) or visit websites of data buyers. A way to present more detail than visible at the overview table is to apply the Overview beside detail user interface pattern (Laakso 2003)._\n\n#",
                "Implementation": "Provide users with access to an interface which displays their data in useful dataset views, and give them the option for raw information. See the following table for an example.\n\n|Type of Data|Data|Date Recorded|Accessed by|\n|--|--|--|--|\n|data type a|data itself|date a|person one|\n|data type b|data itself|date b|person one, person two|\n\n_To be really transparent, also show things like how and why data was used, who of your organization has access to the user\u2019s personal data, what was downloaded or sent to a specific third party, and when all these events happened. The table can present all the data at once, or order it in categories, that may be further detailed when the user selects a category._",
                "Consequences": "_Benefits:_\n\u2212 _Actual data: Users can see the actual personal information you have, real-time*._\n\u2212 _Details: A table can show all the personal information at once, in a structured way._\n\u2212 _Details: Users may see errors in their data and ask for rectification, thereby improving the data quality._\n\u2212 _Security and Availability: Data can remain stored in a secure place and still be available to your users whenever they want to see it._\n\u2212 _Usability: Users get a better understanding of the personal data your systems holds and how you handle their data. Users may even decide to better control access to their data (not part of this pattern), increasing their own privacy and limiting the risks of privacy incidents, caused by e.g. an external attack on the system._\n\u2212 _Trust: Providing transparency in a user-friendly manner increases the trust that users have of you as an organization. \u2212 Automation: A table is relatively easy to implement and automatically generate, compared to for example graphic data visualisations._\n\nLiabilities:\n\u2212 _Actual data: Everything that happens to all user data must be logged. This may impose a privacy problem of its own._\n\u2212 _Details: Users may be overwhelmed by the amount of data you have and decide to stop using your system_\n\u2212 _Security and Availability: Some users may want to have the data on their own systems, for example to run their own analyses. This pattern does not make that possible, but the functionality could be easily provided._\n\u2212 _Trust: Users may decide to delete some of their data or otherwise restrict access to their data in a way that decreases the amount of data available for your systems. Or users may even decide that the privacy infringement is too large and stop using your system all together._\n\n*_Providing real-time insight in all personal data that a system contains is not common practice; currently people usually have to put in a formal request (e.g. by email) and wait for a couple of weeks until they receive a reply with zip-file attached._",
                "Examples": "#",
                "Known Uses": "_Figure 1 shows the actual design of the personal data table pattern implementation for a Quantified Self data store, the Nutritional Research Cohort (NRC). The NRC is a cohort of researchers in nutrition and health sciences who gather self-assessment data on their lifestyle and their health. NRC gives access to information on personal health trajectory, and the effects of diet on personal health. For each column, a mouse overlay details the meaning of the column name. This solution implements an overview of which data is collected, whether data is private or shared with others, for which purpose the data is used, which external parties requested the data, and who downloaded the data and when. This overview is shown on a special page in a myData section of the NRC application._",
                "See Also": "#",
                "Related Patterns": "This pattern _complements_ Minimal Information Asymmetry(Minimal-Information-Asymmetry). Like this pattern, it allows a user to see what personal data is acquired by the controller. It provides a better understanding of what data is processed and the policies surrounding that processing, including potential risks. Together these patterns show a clearer representation for the user to consider.\n\nThis pattern may be _used by_ Privacy Mirrors(Privacy-Mirrors). It keeps track of what is known, and allows for various configurations within this. It also stems from a multidisciplinary context. As such there exists a an extension of functionality in this. However, as the described problems are different, there is not an _extends_ relationship.\n\n_Patterns that also show personal data within a user application are the Personal Data Infographic (showing data as infographic, not a table) and Viewable Personal Data Overlay (showing in an overlay which data is viewable by others). Furthermore, the Digital File with Personal Data pattern allows a user to receive the personal data collected for a certain service in a digital file._\n\n\n#",
                "Sources": "J. Siljee, \u201cPrivacy transparency patterns,\u201d in EuroPLoP \u201915, 2015, pp. 1\u201311.\nW. Kraaij, B. Hulsebosch, J. Siljee, M. Kooij, R. Kosman, and J. Janssen, \u201cPrivacy Tansparency,\u201d SWELL, 2014. Online. Available: http://www.swell-project.net/dynamics/modules/SFIL0100/D4.9%20Privacy%20Transparency893d.pdf. Accessed: 10-Oct-2017."
            }
        },
        {
            "filename": "Personal-data-store.html",
            "title": "Personal Data Store",
            "excerpt": "Subjects keep control on their personal data that are stored on a personal device.",
            "sections": {
                "Summary": "Subjects keep control on their personal data that are stored on a\npersonal device.",
                "Context": "The pattern is applicable to any data produced by the data subject (or\noriginally under his control) as opposed to data about him produced by\nthird parties.",
                "Problem": "Data subjects actually lose control over their data when they are\nstored on a server operated by a third party.",
                "Solution": "A solution consists in combining a central server and secure personal\ntokens. Personal tokens, which can take the form of USB keys, embed a\ndatabase system, a local web server and a certificate for their\nauthentication by the central server. Data subjects can decide on the\nstatus of their data and, depending on their level of sensitivity,\nchoose to record them exclusively on their personal token or to have\nthem replicated on the central server. Replication on the central\nserver is useful to enhance sustainability and to allow designated\nthird parties (e.g. health professionals) to get access to the data.\n\n\nEnhance the control of the subjects on their personal data.",
                "Consequences": "Data subjects need to be equipped with a personal data store.",
                "Examples": "Patients want to keep control over their health data but also to grant\nspecific access to some health professionals.\n\n#",
                "Known Uses": "It has even been deployed for certain types of services, in\nparticular, in the health sector."
            }
        },
        {
            "filename": "Platform-for-Privacy-Preferences.html",
            "title": "Platform for Privacy Preferences",
            "excerpt": "Use privacy policies which consist of standardized and extensible vocabulary and data element sets, both of which user agents should be aware of, in order to streamline their review by eliminating redundancies.",
            "sections": {
                "Also Known As": "P3P",
                "Context": "Users are frequently intimidated or discouraged by the size and complexity of legal texts. Privacy policies are an example of such texts, which are in the user's best interest to understand. As these policies are also written for the sake of legal compliance, balancing or reconciling comprehensiveness with comprehensibility is nontrivial. Different users will have varying thresholds to the amount of detail they will readily look through. The controller in this case wants to make their privacy policy more accessible to their users.",
                "Problem": "Users regularly do not read privacy policies, as they are too verbose, complex, and repetitive amongst the sites they visit.\n\n##",
                "Forces and Concerns": "- Users typically do not want to read walls of texts, often needing to be persuaded to inform themselves\n- Controllers want to ensure that users are not surprised and or upset about what is done with their data\n- A number of users want to really understand what risks they are taking regarding their privacy\n- Controllers want to be legally compliant, and minimize the costs involved in catering to data protection",
                "Solution": "Controllers may use the P3P standardization of terms and data elements to construct their privacy policies, allowing users to instead immediately see the policy distinctions which matter before using the service. The policies they share with other controllers the user is subject to will already have been reviewed, or are separated such that minimal time is spent reviewing policy.\n\n##",
                "Rationale": "By removing redundancies, there is far less to read. By standardizing, comprehension is strengthened.\n\n#",
                "Structure": "P3P uses eXtensible Markup Language (XML) to hold a variety of information concerning each web resource listed in a policy reference file. The XML includes the data elements or types collected, its recipients, and explanations of how each set of data is used (purposes and means). It also features important information about the controller and its general policies and practices, such as contact information, a link to the human readable policy, and dispute resolution. It does not contain information about what the controller does not do.\n\n#",
                "Implementation": "The controller must publish the P3P syntax files and policy reference file to their live site. The files may be generated by automated tools. It is encouraged that the policy reference file be published in the well-known location(https://www.w3.org/TR/P3P/#Well_Known_Location), `/w3c/p3p.xml`. A `link` tag or HTTP Headers(https://www.w3.org/TR/P3P/#syntax_ext) may also be used. The policies used may also cover the entire site, or specific areas.\n\nFurther information is available at https://www.w3.org/TR/P3P/",
                "Consequences": "Users will be able to construct preferences for a privacy standard (risk appetite) which they personally can accept. This template will allow them to quickly review the privacy policy of the controller while avoiding repetition, and understanding distinctions. They may additionally choose to have site-specific preferences which point out what is most relevant to them.\n\n#",
                "Constraints": "The human readable privacy policy should be compatible with what can also be expressed using the P3P standardization. While extensions can be made to the specification, there is a limit to this. Careful consideration will need to be used when constructing the policy to ensure full coverage. This may require additional explanation beyond what the P3P specification can provide, which needs to be clearly indicated and explained to users.",
                "Examples": "The following example is taken from the P3P1.0 specification:\n\n_Claudia has decided to check out a store called CatalogExample, located at http://www.catalog.example.com/. Let us assume that CatalogExample has placed P3P policies on all their pages, and that Claudia is using a Web browser with P3P built in._\n\n_Claudia types the address for CatalogExample into her Web browser. Her browser is able to automatically fetch the P3P policy for that page. The policy states that the only data the site collects on its home page is the data found in standard HTTP access logs. Now Claudia's Web browser checks this policy against the preferences Claudia has given it. Is this policy acceptable to her, or should she be notified? Let's assume that Claudia has told her browser that this is acceptable. In this case, the homepage is displayed normally, with no pop-up messages appearing. Perhaps her browser displays a small icon somewhere along the edge of its window to tell her that a privacy policy was given by the site, and that it matched her preferences._\n\n_Next, Claudia clicks on a link to the site's online catalog. The catalog section of the site has some more complex software behind it. This software uses cookies to implement a \"shopping cart\" feature. Since more information is being gathered in this section of the Web site, the Web server provides a separate P3P policy to cover this section of the site. Again, let's assume that this policy matches Claudia's preferences, so she gets no pop-up messages. Claudia continues and selects a few items she wishes to purchase. Then she proceeds to the checkout page._\n\n_The checkout page of CatalogExample requires some additional information: Claudia's name, address, credit card number, and telephone number. Another P3P policy is available that describes the data that is collected here and states that her data will be used only for completing the current transaction, her order._\n\n_Claudia's browser examines this P3P policy. Imagine that Claudia has told her browser that she wants to be warned whenever a site asks for her telephone number. In this case, the browser will pop up a message saying that this Web site is asking for her telephone number, and explaining the contents of the P3P statement. Claudia can then decide if this is acceptable to her. If it is acceptable, she can continue with her order; otherwise she can cancel the transaction._\n\n_Alternatively, Claudia could have told her browser that she wanted to be warned only if a site is asking for her telephone number and was going to give it to third parties and/or use it for uses other than completing the current transaction. In that case, she would have received no prompts from her browser at all, and she could proceed with completing her order._",
                "See Also": "#",
                "Related Patterns": "This pattern _complements_ Dynamic Privacy Policy Display(Dynamic-Privacy-Policy-Display). The solutions are different, but are within the same context. These patterns may work together to show the user the privacy policy and how it compares to the user preferences. Dynamic Privacy Policy Display(Dynamic-Privacy-Policy-Display) _uses_ Privacy Policy Display(Privacy-Policy-Display). This pattern also implicitly _complements_ that pattern.\n\nThis pattern _uses_ Policy Matching Display(Policy-matching-display) and Privacy-Aware Network Client(Privacy-aware-network-client). For both of these, context and problem are overlapping and the latter is a part of the solution's implementation described in the former. Policy Matching Display(Policy-matching-display) in particular adds very useful improvements while including this pattern.\n\n#",
                "Sources": "L. Cranor, M. Langheinrich, M. Marchiori, and J. Reagle, \u201cThe Platform for Privacy Preferences 1.0 (P3P1.0) Specification,\u201d W3C, 2002. Online. Available: https://www.w3.org/TR/P3P/. Accessed: 10-Oct-2017.\n\nO. Drozd, \u201cprivacypatterns.wu.ac.at - Privacy Patterns Catalog,\u201d privacypatterns.wu.ac.at, 2016. Online. Available: http://privacypatterns.wu.ac.at:8080/catalog/. Accessed: 25-Jan-2017."
            }
        },
        {
            "filename": "Policy-matching-display.html",
            "title": "Policy Matching Display",
            "excerpt": "Allow users to specify what privacy preferences they have and non-intrusively bring policy mismatches to their attention.",
            "sections": {
                "Also Known As": "Personalized Policy Matching Display",
                "Context": "Controllers have policies written in a manner appropriate for legal evaluation, as it is the legal compliance which warrants them in the first place. Users tend to not be able to comprehend such language, and do not typically care to spend the time and effort required to parse it. However, much of the content in these policies is consistent throughout the services they use.\n\nUsers value using a service (or product) without having to go through repetitive and verbose policy detail. However, these users must still understand the policies which apply to them in order to not be blindsided. Controllers need to avoid this as keeping users happy is integral to a sustainable business model.",
                "Problem": "Users may get overwhelmed by the complexity of policies impacting privacy when using a service, compromising the validity of their informed consent.\n\n##",
                "Forces and Concerns": "- Users do not want to have to read privacy policies, but do want to know about relevant and important distinctions from their personal preferences\n- Controllers need to have policies which are tailored to legal compliance, but also need users to understand risks and responsibilities\n- Users may not like the default values chosen by controllers for application settings, even if those defaults are privacy friendly\n- Controllers would like users to use a service immediately, with as little in the way and as little potentially discouraging as possible",
                "Solution": "Retrieve user policy preferences and use these to highlight contradictions with the privacy policy. Where possible, configure application settings to the values which best adhere to these preferences.\n\n\n\n\n\n\n\n\n\n#",
                "Implementation": "User policy preferences may be collected and managed by a controller, _exposed by their user agent, or at a well-known URI_. They may be highlighted through an overlay of elements or handled in-line where context plays an important role. In either case these notifications should not encourage users to apply settings which do not match their preferences in order to remove them.\n\nOn the other hand, if the notification is not noticeable, the user may overlook an important policy distinction. Notifications which are persistent or ubiquitous may quickly desensitize users, and should also be used with care.",
                "Consequences": "Allows users to provide a consistent privacy threshold while reducing cognitive workload as they use services.\n\n#",
                "Constraints": "Expressing and comparing the policies requires a consistent machine-readable format. There however numerous approaches to this. The Platform for Privacy Preferences(Platform-for-Privacy-Preferences) pattern addresses this through eXtensible Markup Language.\n\n\n\n\n\n\n#",
                "Known Uses": "- For an academic discussion, see Graf, C., Wolkerstorfer, P., Geven, A., & Tscheligi, M. (2010, November). A pattern collection for privacy enhancing technology. In PATTERNS 2010, The Second International Conferences on Pervasive Patterns and Applications (pp. 72-77).\n- For a discussion of privacy languages see Kumaraguru, P., Cranor, L., Lobo, J., & Calo, S. (2007, July). A survey of privacy policy languages In SOUPS'07: Proceedings of the 3rd Symposium on Usable Privacy and Security. and Becker, M. Y., Malkis, A., & Bussard, L. (2010).\n- A related, classic initiative was W3C's The Platform for Privacy Preferences 1.1 (P3P1.1) Specification, however, the matching was performed at the client's side.\n- A more recent example is available at S4P: A generic language for specifying privacy preferences and policies. Microsoft Research.\n- ... and Sacco, O., & Passant, A. (2011, March). A Privacy Preference Ontology (PPO) for Linked Data. In LDOW.\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _may use_ Privacy Policy Display(Privacy-Policy-Display). While the display aims to show policy information this pattern may highlight privacy preference mismatches therein, providing more valuable information for the user.\n\nIt may also be _used_ by Platform for Privacy Preferences(Platform-for-Privacy-Preferences). It is a fundamental part of the implementation of the latter, which adds useful improvements and overlaps this pattern's context and problem.\n\nThis pattern _complements_ Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides), Dynamic Privacy Policy Display(Dynamic-Privacy-Policy-Display).\n\nBetween this pattern and Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides), both patterns may work together to provide the user with information toward building trust in a controller. This will be based on both preferences matching and means for demonstrating trustworthiness.\n\nWith Dynamic Privacy Policy Display(Dynamic-Privacy-Policy-Display), however, these patterns may provide mismatches within or through the standardization and 'tooltips'.\n\nImplicitly, through Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides), this pattern also complements the visual cue patterns. This includes Icons for Privacy Policies(Icons-for-Privacy-Policies), Appropriate Privacy Icons(Appropriate-Privacy-Icons), and Privacy Color Coding(Privacy-color-coding).\n\n\n#",
                "Sources": "S. Fischer-H\u00fcbner, C. K\u00f6ffel, J.-S. Pettersson, P. Wolkerstorfer, C. Graf, L. E. Holtz, U. K\u00f6nig, H. Hedbom, and B. Kellermann, \u201cHCI Pattern Collection - Version 2,\u201d 2010.\n\nC. Graf, P. Wolkerstorfer, A. Geven, and M. Tscheligi, \u201cA Pattern Collection for Privacy Enhancing Technology,\u201d The Second International Conferences of Pervasive Patterns and Applications (Patterns 2010), vol. 2, no. 1, pp. 72\u201377, 2010."
            }
        },
        {
            "filename": "Preventing-Mistakes-or-Reducing-Their-Impact.html",
            "title": "Preventing mistakes or reducing their impact",
            "excerpt": "Prevent accidental automatic disclosure of personal information.",
            "sections": {
                "Context": "Numerous services (or products) are designed with the purpose of sharing amongst the public or a specific subset of users. In content sharing implementations, it is commonplace to streamline disclosure so that users do not need to publish manually. Content they generate is often automatically shared with the controller, even if not immediately made available to other users or the public. This of course requires the prior consent of users, though it is also possible for users to forget about that consent, or change their mind. If the distinction lies in a simple setting, it may not be apparent to the user that it is still in effect.",
                "Problem": "Immediate and automatic content publication without notification or confirmation of consent leads to unintentional disclosure and may invalidate prior consent.\n\n##",
                "Forces and Concerns": "- Users of the service want to share content with others, but not all of the content they generate is fit for sharing\n- Most users do not want to manually upload content case by case, sometimes long after creation\n- Controllers want to make it easy for users to contribute content\n- Controllers do not want users to disclose content which they regret disclosing and potentially ruins the user's experience",
                "Solution": "Use contextual measures to predict whether content should be processed, re-establishing consent, to prevent accidental disclosure.\n\n\n\n\n\n\n#",
                "Implementation": "_Through the study of patterns in disclosure behavior, systems may be able to helpfully warn users when disclosing following potentially significant change in context, perhaps reducing potential for mistakes. These privacy decisions are often correlated with the context of capture and the content as indicated by the user. It could be feasible to use these patterns for prediction or recommendation of privacy settings. In addition, providing an optional \u201cstaging area\u201d before disclosure actually takes place and an easy way to review recent disclosures may reduce the immediate consequences of quickly regretted or accidental disclosure decisions._",
                "Consequences": "Clearing up mistakenly shared data adds additional overhead, especially if the service does not offer simple modification or removal of information. As sharing more than actually intended may result in potential damage for users, they will benefit from services which reduce these risks.",
                "Examples": "_Through the study of trends in disclosure behavior, systems may be able to helpfully warn users when disclosing following potentially significant change in context, perhaps reducing potential for mistakes. As Ahern et al. found that privacy decisions are often correlated with the context of capture and the content of the photo as indicated by user-specified tags, it could be feasible to use these patterns for prediction or recommendation of privacy settings. In addition, providing an optional \u201cstaging area\u201d before disclosure actually takes place and an easy way to review recent disclosures may reduce the immediate consequences of quickly regretted or accidental disclosure decisions._\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ Impactful Information and Feedback(Impactful-Information-and-Feedback), and [Informed Credential Selection](Informed-Credential-Selection). As such the patterns which refine it do so as well where their context permits. For Impactful Information and Feedback(Impactful-Information-and-Feedback) this is the case. It provides feedback about disclosure under certain privacy settings before it takes place, and can be notified of, and reviewed, before causing an impact. [Informed Credential Selection](Informed-Credential-Selection), however, can only reasonably _complement_ Asynchronous Notice(Asynchronous-notice), as it deals with instant authentication. Modal notification like what this pattern might provide can inform users in a timely manner.\n\nIt is also _refined_ by both Ambient Notice(Ambient-notice) and Asynchronous Notice(Asynchronous-notice). These variants of notice, which are themselves _alternatives_, both provide essentially equal problems for which they give more specific contexts and solutions. The former is unobtrusive and persistently informative, while the latter is unavoidably informative when context demands.\n\n#",
                "Sources": "S. Ahern, D. Eckles, N. Good, S. King, M. Naaman, and R. Nair, \u201cOver-Exposed ? Privacy Patterns and Considerations in Online and Mobile Photo Sharing,\u201d CHI \u201907, pp. 357\u2013366, 2007.\n\nC. Bier and E. Krempel, \u201cCommon Privacy Patterns in Video Surveillance and Smart Energy,\u201d in ICCCT-2012, 2012, pp. 610\u2013615."
            }
        },
        {
            "filename": "Privacy-Aware-Wording.html",
            "title": "Privacy Aware Wording",
            "excerpt": "Ensure that the content of privacy related information provided to the user is worded carefully, maintaining both attention and understanding.",
            "sections": {
                "Context": "Users are exposed to many privacy policies and notifications which seek to inform them of various issues. The controllers who provide these explanations require that users fully understand the circumstances around the use of their data. Specifically, the purposes for which and means by which their personal data is collected or otherwise processed. There is much information however, and so users are likely to overlook important details.",
                "Problem": "Information the controller conveys to the user is frequently overlooked due to length and complexity of both the content and the vocabulary within, which compromises validity of consent.\n\n_Users should clearly understand the content of and terms used within privacy and security software. The terms are usually formulated on an expert-basis and therefore often difficult to understand for the average user._\n\n##",
                "Forces and Concerns": "- Users do not want to read complex and long policies\n- Users still want to understand what risks they might be taking with their data by using the service (or product)\n- Controllers want to ensure that users understand risks\n- Controllers need consent given by users to be informed",
                "Solution": "Construct privacy related information using easily parsed and low difficultly vocabulary, with short concise sentences and enough flow to persuade the user to process it.\n\n\n\n\n\n\n#",
                "Implementation": "Users should not need to be familiar with the subject matter. They should also not be given unnecessary detail at the highest level of abstraction. Consider combining techniques from other patterns such as Layered Policy Design(Layered-policy-design).\n\n_Before using the terms one should be sure that they are clear and understandable for the target-users. Therefore it is recommended to either refer to standardized terms or to conduct user tests on the understandability of utilized terms and phrases. These tests do not have to be extensive. Asking only few representative users from the target-group about their understanding of the terms should suffice._",
                "Examples": "Referring to the user as the data subject or otherwise introducing terms to the user may reduce reading comprehension. Instead of focusing on legally accurate terms, the information should make sense to the user. It should not be provide a false interpretation, however. The PrimeLife example features a mock corporation which summarises information according to 'what', 'how', and 'who'.\n\n!Privacy Aware Wording Example(/media/images/privacy-aware-wording.jpg)\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ Awareness Feed(Awareness-Feed), Appropriate Privacy Icons(Appropriate-Privacy-Icons), Icons for Privacy Policies(Icons-for-Privacy-Policies), Privacy Labels(Privacy-Labels), Privacy Color Coding(Privacy-color-coding), Abridged Terms and Conditions(Abridged-Terms-and-Conditions), Privacy Policy Display(Privacy-Policy-Display), Layered Policy Design(Layered-policy-design), and Privacy-Aware Network Client(Privacy-aware-network-client).\n\nLike many patterns which inform users, elements of Awareness Feed(Awareness-Feed) (like Impactful Information and Feedback(Impactful-Information-and-Feedback)) and its methods for establishing awareness go well with accessible policy aspects like this pattern.\n\nInterpretations of privacy policies and their expression in easily understood summaries could be improved with Appropriate Privacy Icons(Appropriate-Privacy-Icons), Icons for Privacy Policies(Icons-for-Privacy-Policies) and Privacy Color Coding(Privacy-color-coding). This makes for a more accessible solution with visual cues.\n\nAccessible policies like these go well with Abridged Terms and Conditions(Abridged-Terms-and-Conditions), as they _complement_ its need for policy summarization.\n\nPrivacy Aware Wording can be used alongside Privacy Policy Display(Privacy-Policy-Display) and Layered Policy Design(Layered-policy-design) to provide more accessible wording in the resulting layered privacy policy or display. Similarly, Privacy-Aware Network Client(Privacy-aware-network-client) benefits from such attention to accessibility in its easily readable format.\n\nImplicit complementary relationships to this pattern include Dynamic Privacy Policy Display(Dynamic-Privacy-Policy-Display) and Policy Matching Display(Policy-matching-display). Both of these exist through their use of Privacy Policy Display(Privacy-Policy-Display).\n\n#",
                "Sources": "S. Fischer-H\u00fcbner, C. K\u00f6ffel, J.-S. Pettersson, P. Wolkerstorfer, C. Graf, L. E. Holtz, U. K\u00f6nig, H. Hedbom, and B. Kellermann, \u201cHCI Pattern Collection - Version 2,\u201d 2010.\n\nC. Graf, P. Wolkerstorfer, A. Geven, and M. Tscheligi, \u201cA Pattern Collection for Privacy Enhancing Technology,\u201d The Second International Conferences of Pervasive Patterns and Applications, vol. 2, no. 1, pp. 72\u201377, 2010."
            }
        },
        {
            "filename": "Privacy-Awareness-Panel.html",
            "title": "Privacy Awareness Panel",
            "excerpt": "Establish user awareness of the risks inherent in the disclosure of their data, whether to the controller themselves or to other users.",
            "sections": {
                "Also Known As": "Privacy Awareness Panel in Collaborative Workspace",
                "Context": "Numerous services (and products) make an impact on user privacy in ways which are not immediately apparent to the user. Unaware and thus uninformed users are likely to make regrettable decisions in the services they use. Certain kinds of information, especially when combined or viewed over time by others, can reveal details about the user they did not intend. The consent for these disclosures cannot be valid if they do not understand the risks inherent in doing so. Controllers of such personal data therefore seek to minimize these risks.",
                "Problem": "Users do not anticipate the pitfalls of disclosure. They may be under the false impression that their activities are inherently anonymous.\n\nThis can manifest in the use of online services where a user shares information with an unknown audience using a pseudonym. Entities within can potentially discover detail the user does not intend, especially if the user loses track of who knows or has access to what. Providing publication history, or reusing aliases in various services, for example can have unintended consequences.\n\nFurthermore, the controller themselves typically has more capability for identifying the user. If users do not know any better, they might behave or contribute in a manner which assumes they cannot be identified.\n\n##",
                "Forces and Concerns": "- Users sometimes want to use services without being identified, but do not know how to maintain their pseudonymity\n- Users want to understand what using a service might reveal about them to various parties\n- Controllers want to protect users from unknowingly making disclosures which are invasive\n- Controllers do not want to process any personal data without informed consent",
                "Solution": "Provide the user with reminders on who can see the content they have or will disclose, what is done with it, why, and how it might become identifying.\n\n#",
                "Structure": "_First, it should be made clear to users which persons will be able to access their contributions. Second, users should know that controllers get additional information about them for instance their IP addresses, browser versions, location information etc. and thus that they are not completely anonymous within the service._\n\n#",
                "Implementation": "The potential consequences of content disclosure may depend on the service in question, and should be investigated in a general sense.\n\nThe user does not need to be shown every potential consequence, but rather must be aware of the need to consider their submission before disclosure. This may require access to an illustrative example to assist in conveying the risks in an accessible manner.\n\nPrior to disclosure, controllers should primarily indicate the access capabilities of different types of users and entities. For example, those on a Buddy List(Buddy-List), or unauthenticated users. Entities include themselves, their processors, and any third parties. Wherever this might entail personal data, purposes and means are also required before informed consent to the submission. If the user is already aware of these, reminders need not be as frequent and prominent.",
                "Consequences": "_Improved awareness of users about who exactly will be and has been able to see the content they disclose will hopefully make them consider disclosure more carefully_.",
                "Examples": "In a forum setting, a Privacy Awareness Panel may include login and account information, any personalizations, as well as information relating to their browser, session, IP, or other metadata which can uniquely identify them to a degree. It could also show post and user interaction history, and what, if any, of this information is more widely available or public. The panel should be easily located and known about by users, for instance introduced on first use of the forum. Unauthenticated users should also have access to this panel, though there would be less information on these users.\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern is a component of the compound pattern, Awareness Feed(Awareness-Feed). As such, this pattern _may be used_ by it.\n\nThis pattern _complements_ Who's Listening(Whos-Listening), Impactful Information and Feedback(Impactful-Information-and-Feedback), and Appropriate Privacy Feedback(Appropriate-Privacy-Feedback).\n\nWho's Listening(Whos-Listening), like this pattern, tries to show who can see disclosed information. It specifically allows for monitoring who accesses the same content as the user. Comparatively, this pattern allows monitoring what access is occurring and how it might become identifying. These could work together to have a more complete solution which covers released and accessed content monitoring.\n\nPrivacy Awareness Panel may additionally take analytical provisions from Impactful Information and Feedback(Impactful-Information-and-Feedback) to supply information on potentially sensitive activity. Appropriate Privacy Feedback(Appropriate-Privacy-Feedback) provides essentially equivalent information to this pattern, together covering more contexts. However, these are also _similar_ patterns.\n\nThis pattern is additionally _refined by_ Increasing Awareness of Information Aggregation(Increasing-Awareness-of-Information-Aggregation). While the problem this pattern aims to solve is overlapped by Increasing Awareness of Information Aggregation(Increasing-Awareness-of-Information-Aggregation), this pattern considers past disclosure decisions which mirrors knowledge of more specific aggregation risks in general.\n\nThis pattern also _complements_ Privacy Options in Social Networks, Selective Access Control in Forum Software, and Privacy Enhanced Group Scheduling.\n\n#",
                "Sources": "S. Fischer-H\u00fcbner, C. K\u00f6ffel, J.-S. Pettersson, P. Wolkerstorfer, C. Graf, L. E. Holtz, U. K\u00f6nig, H. Hedbom, and B. Kellermann, \u201cHCI Pattern Collection - Version 2,\u201d 2010.\n\nS. P\u00f6tzsch, P. Wolkerstorfer, and C. Graf, \u201cPrivacy-awareness information for web forums,\u201d Proceedings of the 6th Nordic Conference on Human-Computer Interaction Extending Boundaries - NordiCHI \u201910, no. June, pp. 363\u2013372, 2010.\n\nC. Graf, P. Wolkerstorfer, A. Geven, and M. Tscheligi, \u201cA Pattern Collection for Privacy Enhancing Technology,\u201d The Second International Conferences of Pervasive Patterns and Applications (Patterns 2010), vol. 2, no. 1, pp. 72\u201377, 2010.\n\nG. Aggarwal and E. Bursztein, \u201cAn Analysis of Private Browsing Modes in Modern Browsers.,\u201d USENIX Security \u2026, pp. 1\u20138, 2010."
            }
        },
        {
            "filename": "Privacy-Labels.html",
            "title": "Privacy Labels",
            "excerpt": "Standardize warning labels similar to nutrition information to quickly inform users about privacy policies and preferences.",
            "sections": {
                "Also Known As": "Privacy Nutrition Labels",
                "Context": "Users use a variety of services (or products) for which there are different effects on their privacy. The providers of these services have varying policies around that usage, and thus affect privacy differently. Typically the differences appear in a privacy policy document, or set of documents. Services encourage users to read this information, which can be quite extensive and involved. Users do not typically have the time or patience to investigate this information on their own.",
                "Problem": "Due to the effort required, users often do not investigate the various privacy policies of the services they use, leaving them uninformed about the potential consequences of their consent and choices. Services tend to have overly complex policies, and present them inconsistently, which agitates this issue.\n\n##",
                "Forces and Concerns": "- Users want to know how much personal data they must share to use a service, without unnecessary or disproportionate effort\n- Users want to quickly determine which services provide the functionality they seek with the privacy tradeoffs they can best accept\n- Controllers want users to realize what data they use, and how they use it, so that they do not process it without informed consent\n- Controllers also want users to understand the options they have in privacy preferences, and the advantages of opting into further sharing",
                "Solution": "Present the user with an standardized privacy 'nutritional' label to quickly summarize policy information.\n\n#",
                "Structure": "_Putting a box around the label identifies the boundaries of the information, and, importantly, defines the areas that are \u201cregulated\u201d or should be trusted. This is a common issue when the label is placed in close proximity to other information, but may not be as significant an issue online._\n\n_Using bold rules to separate sets of information gives the reader an easy roadmap through the label and clearly designates sections that can be grouped by similarity_\n\n_Providing a clear and boldfaced title, e.g., Privacy Facts, communicates the content and purpose of the label specifically and assists in recognition._\n\n_Finally, we have defined a maximum width of 760px for this label and all following designs in this paper. One important consideration was that the privacy label design be printable to a single page and viewable in the standard width of today\u2019s internet browsers._\n\n#",
                "Implementation": "_The tabular format can be filled in automatically if a site uses [Platform  for  Privacy  Preferences(Platform-for-Privacy-Preferences)]_.\n\n![Privacy Label Example(/media/images/Privacy-Label.png)](https://cups.cs.cmu.edu/privacylabel-05-2009/current/1.php)\n\nPrivacy Labels use four colored squares to help convey information quickly:\n\n- Dark Red Square: _we *will* collect and use your information in this way_\n- 'opt out' Red Square: _by default, we *will* collect and use your information in this way unless you tell us not to by opting out_\n- Light Blue Square: _we *will not* collect and use your information in this way_\n- 'opt in' Blue Square: _by default, we *will not* collect and use your information in this way unless you allow us to by opting in_\n\nIn the short table variation(https://cups.cs.cmu.edu/privacylabel-05-2009/current/2.php), the label omits any rows (information types) which are entirely light blue (no collection or use). Instead this information gets summarized in text below the label using short natural-language format. _Similar rows are merged into combined statements for brevity._",
                "Consequences": "The Privacy Label authors conducted a study(https://www.cylab.cmu.edu/_files/pdfs/tech_reports/CMUCyLab09014.pdf) where they assessed respondents' (n=764) attention to presented policies. They were able to determine how long respondents looked at each policy and where that affected their opt-out and further investigation decisions in the study. These were randomly divided between Privacy Labels (n=188), short table version (n=167), short text version (n=169), the full original policy document (n=162), and Layered Policy Design(Layered-policy-design) (n=78). Privacy Labels tested best among the respondents, followed by short table and text variations.  Layered Policy Design(Layered-policy-design) was not found to perform any better than the full text when not additionally rephrasing policies.",
                "Examples": "#",
                "Known Uses": "Privacy Labels are currently implemented using Privacy Bird and Privacy Finder(http://www.privacyfinder.org) Their source code(http://www.privacyfinder.org/dist/privacybird-source.tar.gz) is also available.\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ Impactful Information and Feedback(Impactful-Information-and-Feedback), Layered Policy Design(Layered-policy-design), Privacy Aware Wording(Privacy-Aware-Wording), Privacy-Aware Network Client(Privacy-aware-network-client), Awareness Feed(Awareness-Feed), and Privacy Color Coding(Privacy-Color-Coding). It also implicitly _complements_ Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides) through Awareness Feed(Awareness-Feed), and P3P(Platform-for-Privacy-Preferences) through Privacy-Aware Network Client(Privacy-aware-network-client).\n\nAs a visual cue, this pattern aids in providing Impactful Information and Feedback(Impactful-Information-and-Feedback) by augmenting it with quickly interpreted information. Unlike other visual cues, this pattern does not relate to Informed Secure Passwords(Informed-Secure-Passwords).\n\nVisual cues like this pattern also aid in providing accessible policies, and thus _complement_ Layered Policy Design(Layered-policy-design), Privacy Aware Wording(Privacy-Aware-Wording), and Privacy-Aware Network Client(Privacy-aware-network-client). This pattern in particular implicitly _complements_ P3P(Platform-for-Privacy-Preferences) through Privacy-Aware Network Client(Privacy-aware-network-client).\n\nLike many patterns which inform users, elements of Awareness Feed(Awareness-Feed) and its methods for establishing awareness also go well with visual cues like this pattern. It also implicitly aids Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides), which provides visual representation to highlight trust levels to the user.\n\n##",
                "Pre-patterns": "- _uses_ Financial Privacy Notice\n- _refines_ P3P Expandable Grid, which sought to _refine_ P3P(Platform-for-Privacy-Preferences)\n- _refines_ Simplified Privacy Grid\n- _refines_ Simplified Privacy Label\n\n#",
                "Sources": "P.G. Kelley, L.J. Cesca, J. Bresee, and L.F. Cranor. Standardizing Privacy Notices: An Online Study of the Nutrition Label Approach. CHI 2010.\n\nP. Kelley, J. Bresee, L. Cranor, and R. Reeder. A \"Nutrition Label\" for Privacy. SOUPS 2009\n\nKleimann Communication Group, Inc. Evolution of a Prototype Financial Privacy Notice. February 2006. Available: http://www.ftc.gov/privacy/privacyinitiatives/ftcfinalreport060228.pdf\n\nReeder, R.W. Expandable Grids: A user interface visualization technique and a policy semantics to support fast, accurate security and privacy policy authoring. PhD thesis, Carnegie Mellon. 2008. http://www.robreeder.com/pubs/ReederThesis.pdf"
            }
        },
        {
            "filename": "Privacy-Mirrors.html",
            "title": "Privacy Mirrors",
            "excerpt": "Disclosure awareness is needed to adequately manage digital identity. Provide the user of a system with a high level reflection on what personal data the system knows about, what access is given to others, and what kind of personal data can be deduced.",
            "sections": {
                "Context": "Controllers process a lot of personal data within the services (or products) which users use. These users should however be made to understand the risks involved in all the processing. Typically users need to be encouraged to review what data a service uses, and whether they consent to this. When provided with lock icons for certificates, or privacy coordination through color, users often still overlook warnings. Users want information to be streamlined, quick, and easy to digest in order to benefit from a service without delay.\n\nThis pattern is focused on the socio-technical domain, as opposed to purely technical, and as such considers a number of factors that do not play into a developer's perspective.",
                "Problem": "Users are frequently unaware of the personal data which a system processes and may use to draw conclusions from. Due to this, they either accept their data's undefined usage, or limit their disclosure, potentially more than needed, which could result in an poorer user experience.\n\n##",
                "Forces/Concerns": "- Controllers want users to take note of important notifications, particularly if it prevents users from over or under sharing\n- Many users are complacent with not knowing about what a service does with their data, maintaining a disinterest in details\n- Users may experience notification fatigue, if they are frequently provided with warnings and access notifications\n- Users perceive information and notification appropriateness differently, depending on various contexts\n\nAn approach to this transparency which is both noticeable and yet unobtrusive is needed. One which is passively assertive. A purely technical solution is not appropriate, it must also consider physical and social contexts.\n\nThis is because personal information has varying levels of sensitivity to users depending upon these contexts (for e.g. a closed room, or a close friend, are contexts in which some personal information may be considered less vulnerable).",
                "Solution": "Provide a framework for socio-technical systems which allow users to consider their privacy in context, and make decisions to cater for their personal needs.\n\nThis pattern encourages methods, mechanisms, and interfaces which reflect the history, flow, state, and nature of processed personal data which may otherwise have been hidden.\n\n#",
                "Structure": "Privacy Mirrors focus on 5 characteristics:\n\n- history, of data flows;\n- feedback, regarding the state of their physical, social, and technical environment;\n- awareness, enabled by the feedback;\n- accountability, from these; and\n- change, enacted by the users.\n\n##",
                "History": "Logging is possible in technical systems from as little to as much granularity as desired. Whatever is kept needs to have been done so bearing in mind the social implications, i.e. the contexts, which may be important to a user's privacy. Who was involved in the processing, where was it processed, when, how, why, etc. are relevant.\n\n  The past must be summarized in a way which is easy to understand, but still detailed enough to identify less obvious risks. What information is relevant to different users as opposed to that which is seen as unnecessary noise? What isn't socially acceptable to record? How long must this be kept, should it deteriorate or simply vanish?\n\n##",
                "Feedback": "Logging is of little (or detrimental) use if not transparent and appropriately accessible. There needs to be a way to disseminate this history, state, and flow information to the users without inducing notification fatigue and without exposing information which is not contextually acceptable. Visual cues may be less distracting than the use of other senses, and capable of conveying much more information. However, some contexts may call for more distracting notification. A user should be able to choose whether, how much, and by what means they are notified - as some people have higher tolerances, or different tolerances, for distraction than others.\n\nA distinction is suggested between notifications which require 'glancing', 'looking', or 'interacting'. Examples of these in an Android system are toast notifications (ambient display), heads up notifications (in the status bar), and pop up notifications, respectively. Ideally, each level will be available to cater to a user's personal preference. Information about a certain context should by default be found in the location where users would naturally look for it.\n\nIn feedback, how should different senses be addressed, to what level, where should it be shown, for how long, etc. These are aspects which should ideally be user configurable, with reasonable defaults. This should cater to what each user determines is important.\n\n##",
                "Awareness": "This concept includes the user's knowledge about how they feature in the system, how others feature with regards to the user's personal data, as well as what capabilities and constraints entities are given. The level of information and notification to convey depends on the user, as some will want more detail than others - meeting this balance will make the user more comfortable with their involvement.\n\nThis awareness can be divided amongst the three domains:\n\n- Social: Notable usage patterns on access, being able to correlate this with others and encourage better decisions.\n- Technical: Understanding the limitations of the system, and the capabilities if used correctly, to use the system more effectively. Users should understand the flow, state, and history of their personal data in the system.\n- Physical: Having regard for the repercussions of their physical state, including location, being perceivable by the system.\n\nIn maintaining awareness, one difficulty is in adequately informing users of the flows, history, and states of more complex systems. Meeting the balance between overwhelming users and underwhelming them can be difficult.\n\n##",
                "Accountability": "In a ubiquitous system, interpersonal information is something which should ideally be traceable to show who can access, and has accessed, what. In order for social governance to take place, people should be held accountable for what they do. When personal data is accessed, it should be clear who did so, and when - to both the person concerned and the one doing the accessing. Other matters such as how it was accessed, where from, or why, are also subject to the social norms and contexts placed on these aspects by those concerned. This 'you-know-that-I-know-that-you-know' effect controls the (mis)use of shared personal information.\n\nAnother balance to make is how much accountability is necessary. Too much exposure of usage may create tension, while too little may do the same. Being able to reliably link usage to an individual is also a matter to consider.\n\n##",
                "Change": "The social norms brought into the foreground, or created through the previous steps will bring about changes in usage. Being able to anticipate repercussions for actions, will cause users to think more carefully about what they reveal and what they access, as well as how (often), when, why, etc. If a user can determine that certain changes to information flow will be overall beneficial, the user may decide to act on those changes. This applies to both the user's needs, and that of the those around them.\n\nUnderstanding the resulting effect of sharing or controlling information will help users find a level which suits them. Although some may retreat in-wards upon realizing the consequences of over-sharing, or over-share when the consequences of doing so are not immediately apparent. This is why meeting the balance is important. There is also the matter of outliers, where some users will not be as comfortable or as uncomfortable as the majority. Therefore, having the means to share less or more than others is important.\n\n#",
                "Implementation": "Implementing this pattern is a matter of providing logging, reporting, and other informational access and notifications on user-selected/filtered, appropriately defaulted, relevant usage data. The data provided to the notified users should not intrude on other users' sensitive information, apart from the activities which involve the notified users.\n\nThe right balance needs to be met, both in the selected defaults and in the minimum and maximum levels available to the users in settings. The settings should be found easily, as should additional information. Balanced defaults can be determined from identified norms among users, while minimums should cater to the least interested and maximums to those most interested in their data's usage.\n\nUsers should ideally be able to choose the medium for the notifications, and for information retrieval, which best suits them. Candidates include email, push notifications on mobile devices, or simply from the same interface as the rest of the system.\n\nAn effort can be made to slowly introduce users to this system. For example, starting out more privately and then gradually revealing future information so that users have time to adjust their usage. This way users are less likely to portray an undesirable usage pattern.\n\nThese correlations may also be stored in a secure way, so that they cannot be viewed arbitrarily by backend users. If users are given assurances about what information can be seen by who, including backend users, they will be more willing to make use of the information and notification system.",
                "Consequences": "Advantages:\n\n- Users are less likely to portray a negative usage pattern if they are aware of the correlation of their actions to it. This results in a more positive user experience once adjustments have been made. In some cases, this can increase productivity, and or efficiency in using the system.\n\nDisadvantages:\n\n- Initial discovery of the way they appear from the outside may lead users to retreat into themselves and disclose little to no information, cease using the system, and or call for their usage to be erased. This can be mitigated by slowly introducing users to the system without immediately providing intricate usage history.\n- Even if introduced slowly, users may be dissatisfied with their usage pattern as it appears to the system (and any authorised backend users). These correlations should ideally be difficult (or impossible) to retrieve if not by the user in question.",
                "Examples:": "A Groupware Calendar System (GCS), 'Augur', Tullio, J., Goeckes, J., Mynatt, E.D, and Nguyen, D.H. Augmenting Shared Personal Calendars. Submitted to UIST'02 Paris, France.\n\nHistory: This example logs all access to the shared calendars by the group members, and if the calendar is public, especially the users which are not expected to do so. The sharing of these calendars produces social norm information, that is, social trends from how members use the information, spread it, or dismiss it. This includes the usual when/how/what/etc. information around access. As the members are presented this analysis, they are given the ability to react to it, and adjust the sharing or details within their calendars to their privacy needs.\n\nFeedback: Augur informs users who accessed the calendar, when, where, and what in particular was seen. This is especially useful for shared calendars since the feedback mechanism allows users of the calendar to adjust what they add to it, or who is permitted access the information.\n\nWhile a GCS notification, or information display could reside anywhere, the 'native habitat' for calendar related information is in the calendar application, a mail application, or if the user chooses and if necessary, the area where time sensitive notifications usually appear.\n\nAwareness: Users are given information at the chosen detail and notification levels in order to feel comfortable with the system. Since monitoring can negatively impact the users, the level of this is also configurable.\n\nAccountability: Social norms around mutual understanding of what will/has been accessed in this example will affect calendar viewing and sharing. Prying into other's affairs without reasonable explanation could have social (or other) consequences. This includes a distinction between occasional viewing and constant checks. This may result in less information being shared, different access control settings, or an inquiry into the usage, which may address underlying issues.\n\nChange: Being able to see cause and effect around different personal data sharing, hiding, or specific information flows, will likely bring about changes in how users use the shared calendar system. Important information may be shared while leaving less important details out, increasing efficiency.\n\n#",
                "Known Uses:": "WebAware provided a view of page accesses, this was extended to a Web Server Log Mirror (WSLM). This was initially shown at http://www.smartmoney.com/marketmap/, but is no longer available.",
                "See Also:": "#",
                "Related Patterns:": "This pattern _complements_ Minimal Information Asymmetry(Minimal-Information-Asymmetry) and Impactful Information and Feedback(Impactful-Information-and-Feedback).\n\nThis pattern provides a general solution for managing identify through informing and controlling sharing decisions. This is compatible with the solution suggested in Minimal Information Asymmetry(Minimal-Information-Asymmetry), as it supports informed user agency through explanations of policy and potential risks. Together they could compose a better identity management solution for the user.\n\nImpactful Information and Feedback(Impactful-Information-and-Feedback) supplies insights on potentially sensitive activity. These warnings allow for protection from the controller and reflection on sharing decisions in this pattern. This makes the patterns almost _similar_, and just short of a refinement towards more specific contexts. The problems these patterns address are however quite distinct.\n\nThis patter is _similar to_ Privacy Dashboard(Privacy-dashboard). They have overlapping contexts, describe overlapping problems, and have solutions which have similar elements within them.\n\nThis pattern uses Personal Data Table(Personal-Data-Table) and Appropriate Privacy Feedback(Appropriate-Privacy-Feedback). Personal Data Table(Personal-Data-Table) is focused in tracking stored personal data, which this pattern applies as part of its solution. This pattern may also _use_ Appropriate Privacy Feedback(Appropriate-Privacy-Feedback) as a means to provide feedback on personal data usage.\n\n#",
                "Sources:": "D. H. Nguyen and E. D. Mynatt, 'Privacy Mirrors : Understanding and Shaping Socio-technical Ubiquitous Computing Systems', pp. 1--18, 2002.\n\n\n\nE. S. Chung et al., 'Development and Evaluation of Emerging Design Patterns for Ubiquitous Computing', DIS '04 Proceedings of the 5th conference on Designing interactive systems: processes, practices, methods, and techniques, pp. 233--242, 2004.\n\n\n\nH. Baraki et al., Towards Interdisciplinary Design Patterns for Ubiquitous Computing Applications. Kassel, Germany, 2014.\n\n\n\nG. Iachello and J. Hong, 'End-User Privacy in Human-Computer Interaction', Foundations and Trends in Human-Computer Interaction, vol. 1, no. 1, pp. 1--137, 2007.",
                "General Comments:": "",
                "Categories:": "",
                "Tags:": ""
            }
        },
        {
            "filename": "Privacy-Policy-Display.html",
            "title": "Privacy Policy Display",
            "excerpt": "The goal of this display is to provide the user information about why what information by whom is requested. It should be used whenever personal data is required from the user.",
            "sections": {
                "Context": "Privacy policies are an important element in the processing activities of a controller. They not only relay to data subjects, the users, crucial aspects about the processing in question, but also adhere to the laws which mandate those policies. Balancing the accessibility of these policies however with the legal comprehensiveness needed is nontrivial. As such users do not naturally familiarize themselves with privacy policies as they need to be verbose, and often complex, to comply with the law. It is therefore necessary that controllers ensure that users are indeed informed before soliciting their consent.",
                "Problem": "Whenever the user's information is requested, it must be clear to them exactly what information is needed, who requests it, and what will be done with it.\n\n##",
                "Forces and Concerns": "- Users do not want to read extensive policies, but they do want to understand any relevant risks\n- Controllers need users to understand specific policy elements in order to legally process their data\n- Users would rather be provided with relevant and ideally concise information than all of it at once\n- Controllers want users to trust that they are not trying to hide the risks of using the system",
                "Solution": "As requests for personal data are made, state clearly what information is needed by whom, for which purposes, and by what means, prior to soliciting consent.\n\n\n\n\n\n\n#",
                "Implementation": "The Article 29 Working Party of the Data Protection Directive of the European Union have set out recommendations regarding the distribution of policy into a layered format. They suggest three tiers, each providing additional detail. Users should have clearly visible access to successive detail upon the controller's request of the related personal data.\n\nThe first tier, 'short notice', shall offer core information necessary for users to understand the purposes and means of processing. It should provide a clear mechanism to obtain further detail. This tier is aimed towards maximum user understanding.\n\nThe second tier, 'condensed notice', includes a summary of pertinent information as required by Article 13 of the General Data Protection Regulation (GDPR), the successor to the Directive. This non-exhaustively includes additional information regarding contact details of applicable entities, legal basis or obligation, legitimate interests, recipients, retention, data subject rights, and whether automated decision making is in use.\n\nThe third tier, 'full notice', presents all remaining information required by the GDPR in addition to the previous information. This is the variation which expresses the full detail of the policy which best holds up the legislative requirements.",
                "Consequences": "By constantly reminding users what it really means to share their information, they will better contemplate the personal data they choose to provide. However, users may also become fatigued or otherwise desensitized by frequent reminders and begin to overlook privacy policies. As such it is important to balance the levels of visibility and implicit severities of the information conveyed.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _may be used_ by Dynamic Privacy Policy Display(Dynamic-Privacy-Policy-Display) and Policy Matching Display(Policy-matching-display). The first of these uses it to add standardization and 'tooltip' functionality, while the second adds preference and policy mismatches.\n\nThis pattern _complements_ Privacy Aware Wording(Privacy-Aware-Wording), Layered Policy Design(Layered-policy-design), Platform for Privacy Preferences(Platform-for-Privacy-Preferences).\n\nThe complementary relationship with Platform for Privacy Preferences(Platform-for-Privacy-Preferences) however, is implicit. It is made so by the _use_ of this pattern by Dynamic Privacy Policy Display(Dynamic-Privacy-Policy-Display), which has a _complements_ relationship with Platform for Privacy Preferences(Platform-for-Privacy-Preferences).\n\nThe complementary relationship between Privacy Aware Wording(Privacy-Aware-Wording) and Layered Policy Design(Layered-policy-design) stems from their use as accessible policies. As they seek to make privacy policies more easily interpreted by users, it is a natural aid to the display of information requests and explanations within this pattern.\n\n\n#",
                "Sources": "S. Fischer-H\u00fcbner, C. K\u00f6ffel, J.-S. Pettersson, P. Wolkerstorfer, C. Graf, L. E. Holtz, U. K\u00f6nig, H. Hedbom, and B. Kellermann, \u201cHCI Pattern Collection - Version 2,\u201d 2010.\n\nC. Graf, P. Wolkerstorfer, A. Geven, and M. Tscheligi, \u201cA Pattern Collection for Privacy Enhancing Technology,\u201d The Second International Conferences of Pervasive Patterns and Applications (Patterns 2010), vol. 2, no. 1, pp. 72\u201377, 2010."
            }
        },
        {
            "filename": "Privacy-aware-network-client.html",
            "title": "Privacy-Aware Network Client",
            "excerpt": "Enhance user awareness of privacy policies by automatically converting it into a standardized and easily readable format over a secure channel.",
            "sections": {
                "Also Known As": "Privacy Policy Proxy",
                "Context": "Users frequent various domains across the Internet for a number of reasons, each controller having their own set of policies to which users are held. The need for users to understand these policies is shared by most controllers, as catering to an international audience enhances the legislative impact. One such impact is the need for informed consent. Not understanding the purposes and means for personal data processing invalidates consent, which makes that processing unlawful. There are however numerous other requirements for these controllers, which tend to make their policies verbose and complex.",
                "Problem": "Privacy policies are typically written to satisfy legal requirements ahead of conveying concise and easily understandable information to users. This makes users less informed overall.\n\n##",
                "Forces and Concerns": "- Users do not want to read through long policy documents on each site they visit while browsing the Internet\n- Users want to understand any notable risks or tradeoffs of using a site, preferably before being subject to them\n- Controllers want to adhere to the many requirements of law, in a manner that is balanced and best reduces risks for them\n- Controllers also want users to have a pleasant user experience without enduring shocking revelations or underhanded agendas",
                "Solution": "Provide a privacy preserving proxy which securely parses and interprets the privacy policies of controllers, supplying users with standardized and easily understood summaries of those policies.\n\n#",
                "Structure": "_Figure 1 of the paper shows a class diagram for the relationships between the user, the server, and the proxy. Each server can publish many policies and each user can be made aware of many policies at a time through the proxy._\n\n_In Figure 2 of the paper, a user wishes to access some information or interact with files on the server, which publishes its privacy Policy. The access occurs in the following sequence:_\n\n- _The User interacts with the Server through a network Client._\n- _The Client consults the Proxy for privacy policies._\n- _The Proxy discovers the correct Policy (or Policies) made available by the Server, for the information or files in question._\n- _The Proxy displays a user-friendly screen to the User requesting approval of the Policy, prior to allowing access to the information or permitting the interaction._\n- _The User makes a decision after reviewing the Policy._\n\n#",
                "Implementation": "_Design and implement a proxy able to parse and interpret privacy policies written in some standard language. This proxy could be built as a specialized version of the Proxy pattern by the Gang of Four. The proxy could be able to interpret several privacy languages or just one of them. Successful use of the pattern requires that the proxy can understand the server\u2019s privacy language._\n\n_Design and implement a secure communication channel between network clients and their proxies. This is necessary to avoid interception of the user choices by malicious actors._",
                "Consequences": "_The user's awareness of the privacy policy rises so that more informed decisions can be made. The proxy is able to automatically detect changes of the privacy policy. A separate secure connection is needed for the proxy for every access to an area which is secured by a privacy policy. Policy constraints need to allocate local storage in the client. An attack on this could lead the user to decisions which they would otherwise not do. If there are any breaches of privacy it can be blamed on the client if they did use a privacy-aware client for a particular access._",
                "Examples": "_Alice uses several web-based services but is not aware of the their privacy policies. Even when she reads the policies, she is still not aware of the actual implications of the legal description. In the absence of other solutions, she does not read the policies and does not understand the ramifications._\n\n#",
                "Known Uses": "_JRC P3P Proxy Version 2.0 is a P3P user agent acting like an intermediary. Depending on the specified privacy preferences of a user, it controls the access to web servers. Another known P3P user agent is AT&T Privacy Bird. Privacy Bird is a tool warning users if privacy policies of visited websites are not matching with their individual privacy preferences._\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ Awareness Feed(Awareness-Feed), Appropriate Privacy Icons(Appropriate-Privacy-Icons), Icons for Privacy Policies(Icons-for-Privacy-Policies), Privacy Labels(Privacy-Labels), Privacy Color Coding(Privacy-color-coding), Abridged Terms and Conditions(Abridged-Terms-and-Conditions), and Privacy Aware Wording(Privacy-Aware-Wording).\n\nLike many patterns which inform users, elements of Awareness Feed(Awareness-Feed) (like Impactful Information and Feedback(Impactful-Information-and-Feedback)) and its methods for establishing awareness go well with accessible policy aspects like this pattern.\n\nInterpretations of privacy policies and their expression in easily understood summaries could be improved with Appropriate Privacy Icons(Appropriate-Privacy-Icons), Icons for Privacy Policies(Icons-for-Privacy-Policies), and Privacy Color Coding(Privacy-color-coding). This makes for a more accessible solution with visual cues.\n\nAccessible policies like these go well with Abridged Terms and Conditions(Abridged-Terms-and-Conditions), as they _complement_ its need for policy summarization.\n\nAdditionally, where this pattern securely standardizes privacy policies into an accessible format, this format is complemented by Privacy Aware Wording(Privacy-Aware-Wording).\n\nThis pattern may also be _used_ by the Platform for Privacy Preferences(Platform-for-Privacy-Preferences) pattern. The context and problem overlap that of this pattern, its solution's implementation describes elements which already exist in Privacy-Aware Network Client(Privacy-aware-network-client).\n\n_The Privacy-Aware Network Client(Privacy-aware-network-client) _refines_ the Proxy pattern_, while the Web Shopping Process pattern _is one of the patterns most likely to _complement_ this pattern_. This pattern also _complements_ Adaptive Web Applications, _patterns for web applications that change their behavior according to the current user. They would display more or less complete privacy disclosures depending on the type of user._\n\n#",
                "Sources": "M. Sadicoff, M. M. Larrondo-Petrie, and E. B. Fernandez, \u201cPrivacy-aware network client pattern,\u201d in Proceedings of the Pattern Languages of Programs Conference, 2005.\n\n\u201cprivacypatterns.eu - collecting patterns for better privacy,\u201d privacypatterns.eu, 2017. Online. Available: https://privacypatterns.eu/. Accessed: 20-Oct-2015."
            }
        },
        {
            "filename": "Privacy-color-coding.html",
            "title": "Privacy Color Coding",
            "excerpt": "Provide visual cues in standardized colors about privacy policies and preferences to help convey information to users more quickly.",
            "sections": {
                "Context": "The numerous policies and settings around privacy for each service (or product) used by a user would be quite complex and time consuming if such a user endeavored to investigate them. Policies are written for legal compliance and settings are often configured for best experience rather than privacy. Even in the instances where privacy friendly defaults are used, they may cripple the usability of the system, or otherwise disable desirable features. Some settings can also be difficult to consider due to overly brief and vague descriptions.",
                "Problem": "Users do not investigate policies and preferences due to the effort required, and cannot inherently comprehend the consequences of settings otherwise. The poor understanding of these can lead to undesirable disclosures.\n\n##",
                "Forces and Concerns": "- Users want to be able to quickly investigate how much or little information they can comfortably provide while still enjoying the service\n- Users want to be guided as to what preferences achieve better privacy\n- Controllers want users to configure preferences in ways they actually intend, therefore not processing data without informed consent\n- Controllers also want users to understand the limits of the settings through understanding the policies",
                "Solution": "Present the user with standardized color visual cues to help guide them in selecting privacy friendly settings, and in understanding the policies around those settings.\n\n\n\n\n\n\n#",
                "Implementation": "_The results of privacy settings such as visibility are divided into different levels. A distinct color is assigned to each of these levels. Every time the user is performing an action where privacy settings come into play, the color is used as an indication of the privacy settings currently in effect. The choice of colors should take into account prevalent color meanings, like usage of the color red for warning situations. If privacy settings cannot be grouped into distinct levels, a gradient between different colors could also be used._\n\nThe same treatment may be applied to policies, or explanations of settings. User rights and affordances may be presented differently from what the controller may do with their data. Aspects which could be perceived to have the greatest impact on privacy should stand out most. Explanations of who has responsibility or accountability, contact details, etc. can also be given a distinct color. Finally purposes and means for processing should be clearly visible.",
                "Consequences": "_Users receive direct visual cues on the consequences of their privacy settings currently in effect. In order to be more clear about their privacy settings._\n\n_The danger of unwanted actions is decreased, as users will regularly perceive visual cues. On the other hand a reduction of complex settings to a few colors may lead to an oversimplification which would render the whole pattern useless. Visual cues must be integrated into the service design but must still be placed prominently enough to be noticeable. Cultural aspects for the different meanings of colors should be taken into account. The same color may not be recognized as a warning label in different cultures._",
                "Examples": "_Alice uses a social network and shares personal stories only with her friends while she shares mundane content publicly. Hence she always has to change the privacy settings of her posts in order to adjust the visibility of the posts. One day she forgets to change the setting and does not realize that she actually shared a precarious story with her boss._\n\n#",
                "Known Uses": "_A color coding similar to traffic lights is implemented in many modern web browsers for HTTPS connections. A green background indicates a valid certificate while a red background and a warning label shows that there are problems when validating a certificate. Facebook Privacy Watcher(http://www.daniel-puscher.de/fpw/) enhances the Facebook website by color-coding shared content and indicating its visibility. Posts with green background are public, yellow indicates visibility for friends only and red content is only visible to the user. Blue background is used for custom audiences such as groups._\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ Impactful Information and Feedback(Impactful-Information-and-Feedback), Informed Secure Passwords(Informed-Secure-Passwords), Layered Policy Design(Layered-policy-design), Privacy Aware Wording(Privacy-Aware-Wording), Privacy-Aware Network Client(Privacy-aware-network-client), Awareness Feed(Awareness-Feed), and Icons for Privacy Policies(Icons-for-Privacy-Policies). It also implicitly _complements_ Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides) through Awareness Feed(Awareness-Feed).\n\nAs a visual cue, this pattern aids in providing Impactful Information and Feedback(Impactful-Information-and-Feedback) by augmenting it with quickly interpreted information. These visual cues additionally help towards Informed Secure Passwords(Informed-Secure-Passwords), as they may indicate password strength and policy.\n\nVisual cues like this pattern also aid in providing accessible policies, and thus _complement_ Layered Policy Design(Layered-policy-design), Privacy Aware Wording(Privacy-Aware-Wording), and Privacy-Aware Network Client(Privacy-aware-network-client).\n\nLike many patterns which inform users, elements of Awareness Feed(Awareness-Feed) and its methods for establishing awareness also go well with visual cues like this pattern. It also implicitly aids Trust Evaluation of Services Sides(Trust-Evaluation-of-Services-Sides), which provides visual representation to highlight trust levels to the user.\n\nLike this pattern, Icons for Privacy Policies(Icons-for-Privacy-Policies) provides its own way to tackle an overlapping and quite similar problem. This features the understanding of the privacy policy in both cases, as well as privacy settings in this pattern. These patterns may work together to integrate a solution illustrating with both color and imagery.\n\n#",
                "Sources": "Christoph Boesch, Frank Kargl, Henning Kopp, and Patrick Mosby, \u201cprivacypatterns.eu - collecting patterns for better privacy,\u201d 2017. Online. Available: https://privacypatterns.eu/. Accessed: 18-Jul-2017."
            }
        },
        {
            "filename": "Privacy-dashboard.html",
            "title": "Privacy dashboard",
            "excerpt": "An informational privacy dashboard can provide collected summaries of the collected or processed personal data for a particular user.",
            "sections": {
                "Context": "A service (or product) which processes personal data of users may make that data accessible to them. This is often the case whether conforming to laws about self-determination and notice, or merely wanting to provide an additional privacy consideration for the sake of users. The controller concerned wants to open up about the data they have processed, and to improve the ease of use for configuring privacy settings.",
                "Problem": "A system should succinctly and effectively communicate the kind and extent of potentially disparate data that has been processed.\n\n_Users may not remember or realize what data a particular service or company has collected, and thus can't be confident that a service isn't collecting too much data. Users who aren't regularly and consistently made aware of what data a service has collected may be surprised or upset when they hear about the service's data collection practices in some other context. Without visibility into the actual data collected, users may not fully understand the abstract description of what types of data are collected; simultaneously, users may easily be overwhelmed by access to raw data without a good understanding of what that data means._\n\n##",
                "Forces and Concerns": "- Controllers want to provide users with sufficient information to determine how it is used, and to prevent regrettable sharing decisions\n- Controllers want to prevent both over and under-sharing, so as to provide users with the best experience possible\n- Users often do not realize the privacy risks in providing their personal data\n- Users do not want to be subjected to too many or overly detailed notifications, as they will quickly make a habit of overlooking them",
                "Solution": "Provide successive summaries of collected or otherwise processed personal data for a particular user, representing this data in a meaningful way. This can be through demonstrative examples, predictive models, visualizations, or statistics.\n\n_Where users have choices for deletion or correction of stored data, a dashboard view of collected data is an appropriate place for these controls (which users may be inspired to use on realizing the extent of their collected data)._\n\n\n\n\n#",
                "Structure": "A variation of the privacy dashboard, Privacy Mirrors, focuses on history, feedback, awareness, accountability, and change.\n\n#",
                "Implementation": "_Implementing this pattern is a matter of providing logging, reporting, and other informational access and notifications on user-selected/filtered, appropriately defaulted, relevant usage data._\n\nAspects which the controller wishes to inform their users about may include the collection and aggregation of their data, particularly personal data which:\n\n- _changes over time_,\n- _is processed in ways that might be unexpected_,\n- is _invisible or easily forgotten_, or\n- is subject to _correction and deletion_ by users.",
                "Consequences": "#",
                "Constraints": "_As in other access mechanisms, showing a user's data back to them can create new privacy problems. Implementers should be careful not to provide access to sensitive data on the dashboard to people other than the user. For example, showing the search history associated with a particular cookie to any user browsing with that cookie can reveal the browsing history of one family member to another that uses the same computer._\n\n_Also, associating all usage information with a particular account or identity (in order to show a complete dashboard) may encourage designers to associate data that would otherwise not be attached to the user account at all. Designers should balance the access value against the potential considerations within Deidentification(Deidentification)._",
                "Examples": "##",
                "Google Privacy Dashboard": "!Google Dashboard Latitude(/media/images/Google_Dashboard_Latitude.png)\n\n_The Google Dashboard(https://google.com/dashboard) shows a summary of the content stored and/or shared by many (but not all) of Google's services (Latitude, Google's location sharing service, is shown above). For each service, a summary (with counts) of each type of data is listed, and in some cases an example of the most recent such item is described. An icon signifies which pieces of data are public. Links are also provided in two categories: to actions that can be taken to change or delete data, and to privacy policy / help pages._\n\n_Google Accounts: About the Dashboard(http://www.google.com/support/accounts/bin/answer.py?answer#162744)_",
                "See Also": "_Dashboards are a widely-used pattern in other data-intensive activities for providing a summary of key or actionable metrics._\n\n#",
                "Related Patterns": "This pattern _complements_ Awareness Feed(Awareness-Feed). As this pattern provides collective summaries of processed data, and Awareness Feed(Awareness-Feed) keeps users informed of such data, as well as what can be derived, they can work together. In doing so, users are better equipped to take actions which are in line with their personal privacy preferences.\n\nThis patter is _similar to_ Privacy Mirrors(Privacy-Mirrors). They have overlapping contexts, describe overlapping problems, and have solutions which have similar elements within them.\n\nThis pattern _uses_ Appropriate Privacy Feedback(Appropriate-Privacy-Feedback), as it empowers users to act on detail they have been drawn attention to.\n\n#",
                "Sources": "N. Doty & M. Gupta, (2003). \u201cPrivacy Design Patterns and Anti-Patterns Patterns Misapplied and Unintended Consequences,\u201d 1--5.\n\nD. H. Nguyen and E. D. Mynatt, (2002). \u201cPrivacy Mirrors : Understanding and Shaping Socio-technical Ubiquitous Computing Systems', pp. 1--18.\n\nS. Romanosky, A. Acquisti, J. Hong, L. F. Cranor, and B. Friedman, (2006). \u201cPrivacy patterns for online interactions,\u201d Proceedings of the 2006 conference on Pattern languages of programs - PLoP \u201906, p. 1.\n\nC. Bier & E. Krempel, (2012). \u201cCommon Privacy Patterns in Video Surveillance and Smart Energy,\u201d In ICCCT-2012 (pp. 610--615). Karlsruhe, Germany: IEEE.\n\nE. S. Chung et al., (2004). \u201cDevelopment and Evaluation of Emerging Design Patterns for Ubiquitous Computing,\u201d DIS '04 Proceedings of the 5th conference on Designing interactive systems: processes, practices, methods, and techniques, pp. 233--242.\n\n\n\nH. Baraki et al., (2014). \u201cTowards Interdisciplinary Design Patterns for Ubiquitous Computing Applications,\u201d Kassel, Germany.\n\n\n\nG. Iachello and J. Hong, (2007). \u201cEnd-User Privacy in Human-Computer Interaction,\u201d Foundations and Trends in Human-Computer Interaction, vol. 1, no. 1, pp. 1--137."
            }
        },
        {
            "filename": "Privacy-icons.html",
            "title": "Privacy icons",
            "excerpt": "A privacy policy which is hard to understand by general audience is summarized and translated into commonly agreed visual icons. A privacy icon is worth a thousand-word policy.",
            "sections": {
                "Summary": "A privacy policy which is hard to understand by general audience is summarized and translated into commonly agreed visual icons. A privacy icon is worth a thousand-word policy.",
                "Context": "This pattern can be applied to any system which collects end user data. It can be presented in an interactive web page but also as part of a physical product which can collect data (e.g. fitness tracker)",
                "Problem": "Many organizations provide privacy policies which are too lengthy and hard to understand by the general audience. These policies are oriented as legal disclaimers for legal issues, rather than to inform end users so they can consent to the organization practices after being clearly informed of the collected data, its purpose, and the processing and potential sharing with third parties.",
                "Solution": "Include within the service/device a very accessible and visual explanation of the privacy policy. Icons are a great complement to written text, as they may convey much information at a glance through a different modality (images). Standardized icon sets may thus be added to the privacy policy.\n\n\nTruly inform customers of the privacy policy of a system/organization",
                "Consequences": "Users may understand, at first glance, what are the potential risks of consenting of a privacy policy. In order to be useful, the icons must be well known and understood by the majority of the potential users before being used. A common meaning of the icon needs to be shared by the community. Educational material can be built upon the implications of each of these icons.",
                "Examples": "Alice buys a fitness tracker and she is aware that the device collects her location, and sends it to a central web service in order to provide her with her fitness statistics (her fitness routes, the time spent...). The device provider aggregates this data and provides a business analytics service to third parties.\n\nAlice is totally unaware of this secondary use of her data and may not agree to it. But accessing this policy involves accessing a website and going through a lengthy and legally oriented document.\n\n#",
                "Known Uses": "- The current version of the forthcoming EU Data Protection Regulation includes a set of privacy icons that should be used within European services and organizations\n- https://disconnect.me/icons\n- https://wiki.mozilla.org/Privacy_Icons\n- http://yale.edu/self/psindex.html\n- http://www.privacybird.org/\n- https://netzpolitik.org/2007/iconset-fuer-datenschutzerklaerungen/\n- http://knowprivacy.org/policies_methodology.html\n- http://www.privicons.org/\n- The EU-funded PrimeLife project also proposed a set of privacy icons: Holtz, L. E., Zwingelberg, H., & Hansen, M. (2011). Privacy policy icons (http://link.springer.com/chapter/10.1007%2F978-3-642-20317-6_15) In Privacy and Identity Management for Life (pp. 279-285). Springer Berlin Heidelberg and Holtz, L. E., Nocun, K., & Hansen, M. (2011). Towards displaying privacy information with icons. In Privacy and Identity Management for Life (pp. 338-348). Springer Berlin Heidelberg.\n- The Use of Privacy Icons and Standard Contract Terms for Generating Consumer Trust and Confidence in Digital Services CREATe Working Paper 2014/15 (October 2014)\n\nCurrently, most of these are only applied by client-side solutions.\n\nSee also the Privacy Icons entry at Ideas for a Better Internet (kind of a pattern repository by the Berkman Center for Internet and Society in Harvard)."
            }
        },
        {
            "filename": "Private-link.html",
            "title": "Private link",
            "excerpt": "Enable sharing and re-sharing without wide public visibility or cumbersome authenticated access control.",
            "sections": {
                "Context": "The controller provides a service which hosts resources, potentially constituting personal data. When users want to share (and enable re-sharing of) these resources, they may wish to do so privately using existing communication mechanisms. This is particularly relevant when users are sharing with contacts who would rather not, or cannot, simply authenticate.",
                "Problem": "Users want to share a private resource with unauthenticated users in a way that respects the sensitivity of that resource.\nThe solution must not allow users to access resources that weren't intended to be shared, nor publicize the location of the intended resource to unintended recipients.\n\n##",
                "Forces/Concerns": "- The controller should keep the links confidential in order to honor the user's privacy expectations.\n- The link should not be guessable (e.g. by convention or brute force) to prevent unintended recipients from accessing unlisted links.\n- The user should be able to limit the access to a resource by version or time restriction.\n- The recipient should be able to forward the link to another trusted recipient, so long as the link is valid.\n- The recipient should be able to access the link again at a later date, unless the resource is version or time restricted.\n\nNote that the URL will be retained in recipients' browser history and could easily be inadvertently shared with others. Services should help users understand these limitations.",
                "Solution": "Provide the user a _private link_ or _unguessable URL_ for a particular resource, such as a set of their personal information (e.g. their current location, an album of photos). Anyone who has the link may access the information, but the link is not posted publicly or guessable by an unintended recipient. The user can share the private link with friends, family or other trusted contacts who can in turn forward the link to others who will be able to access it, without any account authentication or access control lists.\n\nServices may allow users to revoke existing private links or change the URL to effectively re-set who can access the resource. Additionally, users may set a time-limit for the resource's validity, or have it invalidated upon modification.\n\n\n\n\n\n\n#",
                "Implementation": "The controller allows their users' online resources to be shared by publishing an unlisted URL with a complex, long, and randomly generated string. This can be part of a query string as opposed to an on disk location. In this case, the preprocessor intercepts the query and redirects the user to the correct resource. This may be an actual file on disk (probably not served by direct link), generated on the fly, or extracted from a database or compressed file. The preprocessor can verify validity dynamically before serving the resource.\n\nThe situation in which the user has a direct link to the resource location is not ideal, however, as it will need to change in the event of a time or version restriction since access to the file is not controlled by the preprocessor.",
                "Examples": "1. Flickr \"Guest Pass\"\n2. Google \"anyone with the link\" sharing\n3. Tripit \"Get a link\"\n4. Dropbox \"Share Link\"\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "Private link(Private-link) may be complemented by Active broadcast of presence(Active-broadcast-of-presence), which deals with sharing with all people, while this pattern considers specific audience. They could together broadcast a more public kind of link. Private link(Private-link) may also be used by Support Selective Disclosure(Support-Selective-Disclosure) as a means to provide anonymous access in a resource sharing context.\n\nThis pattern _complements_ a number of patterns, namely Masquerade(Masquerade), Decoupling content and location information visibility(Decoupling-content-and-location-information-visibility), Selective Access Control(Selective Access Control), and Reasonable Level of Control(Reasonable-Level-of-Control).\n\nPrivate link(Private-link) could facilitate both Masquerade(Masquerade)'s selective identifiability and the provision of decoupled location information to specific individuals, after the fact, and while being open to modification. This private sharing with anonymous users may be achieved along with Selective Access Control(Selective Access Control)'s definition of audience for a contribution.Reasonable Level of Control(Reasonable-Level-of-Control) aims to define the granularity while sharing content and the specific audience. These can work together for similar reasons, as Private link(Private-link) again is able to facilitate.  In each case it could provide a more complete sharing (or withholding) solution.\n\nFinally, Private link](Private-link) _must use_ Lawful Consent(Lawful-Consent), as the generation of even unpublished links constitutes processing.\n\n#",
                "Sources": "Based on:\n\nDoty, N., Gupta, M., & Zych, J. (n.d.). PrivacyPatterns.org. Retrieved February 26, 2015, from http://privacypatterns.org/"
            }
        },
        {
            "filename": "Protection-against-tracking.html",
            "title": "Protection against Tracking",
            "excerpt": "This pattern avoids the tracking of visitors of websites via cookies. It does this by deleting them at regular intervals or by disabling cookies completely.",
            "sections": {
                "Summary": "This pattern avoids the tracking of visitors of websites via cookies.\nIt does this by deleting them at regular intervals or by disabling\ncookies completely.",
                "Context": "This pattern is applicable when personal identifiable information is\ntracked through software tools, protocols or mechanisms such as\ncookies and the like.",
                "Problem": "With every single interaction in the web you leave footmarks and clues\nabout yourself. Cookies for example enable webservers to gather\ninformation about web users which therefore affects their privacy and\nanonymity. Web service providers trace user behavior, which can lead\nto user profiling. Also providers can sell the gathered data about\nusers visiting their pages to other companies.",
                "Solution": "Restricting usage of cookies on the client side by deleting cookies on\na regular basis e.g. at every start-up of the operating system or\nenabling them case-by-case by deciding if the visited website is\ntrustworthy or not and by accepting a cookie only for the current\nsession. At the highest level of privacy protection cookies are\ndisabled, but as a consequence web services are restricted. Another\nsolution could be that cookies are exchanged between clients, so that\nsophisticated user profiles emerge.\n\n\nRestricting a website to not be able to track any of the user's\npersonal identifiable informations.",
                "Consequences": "With cookies disabled there is no access to sites that require enabled\ncookies for logging in. Other tracking mechanisms for user\nfingerprinting may still work even when cookies are disabled.",
                "Examples": "Alice wants to buy shoes and she wants to shop online. She heads to an\nonline shop and searches for shoes but can\u2019t decide which ones she\nwants, so she buys neither of them. The next day she finds a couple of\nemails in her inbox, giving her suggestions for other shoes and\nalerting her that the viewed shoes are now on sale.\n\n#",
                "Known Uses": "Junkbuster is an old proxy filtering between web server and browser to\nblock ads and cookies, but it is no longer maintained. A program named\nCookieCooker (http://www.cookiecooker.de/) provides protection for\nmonitored user behaviour and interests by exchanging cookies with\nother users or using a random selection of identities. Unfortunately\nthis project also seems to be not maintained anymore. There is also\nthe Firefox Add-on Self-Destructing Cookies which deletes cookies of\ntabs as soon as they are closed."
            }
        },
        {
            "filename": "Pseudonymous-identity.html",
            "title": "Psuedonymous Identity",
            "excerpt": "Hide the identity by using a pseudonym and ensure a pseudonymous identity that can not be linked with a real identity during online interactions.",
            "sections": {
                "Summary": "Hide the identity by using a pseudonym and ensure a pseudonymous\nidentity that can not be linked with a real identity during online\ninteractions.",
                "Context": "This pattern can be used for systems in which users are identified by\npublic identities.",
                "Problem": "Many kinds of sensitive informations are released through web\ninteractions, email, data sharing or location-based systems, which can\ncontain the name of a user or header information in packets. Another\nproblem could be to interact anonymously in a forum. However too much\ninteraction in a forum with an anonymous identity can be dangerous in\nthe sense that the relation between original identity and a\npseudonymous identity can be exposed.",
                "Solution": "Initiate a random pseudonym, that can not be related to the original,\nso that the identity is hidden. Furthermore a pseudonym depends on\nconcealment, so the pseudonym allocation needs protection.\n\n\nHide the identity of the participants.",
                "Consequences": "The real identity of a user is hidden. In certain scenarios there is a\nneed for additional space to store the pseudonym-identity mapping.\nExtensive Usage of the same pseudonym can weaken it.",
                "Examples": "Assuming some students are writing an exam and they have to fill out a\nform about their identity, where there is an optional field for a\nchosen pseudonym. This way the result can be released under the chosen\npseudonyms and the identity of each student is hidden. But by being\nobservant, some students might be able to figure out which identity\nbelongs to which pseudonym and so the confidentiality of the identity\nis compromised.\n\n#",
                "Known Uses": "Anonymizer are well-known tools for anonymous web interactions. They\nwork for example by using a proxy between a request sender and a\nrecipient to strip header information like HTTP_USER_AGENT in packet\nheaders because they contain metadata about packet senders. The\nMixmaster is an anonymous remailer that hides the sender and recipient\nidentity by stripping its name and assigning a pseudonym. Some data\nsharing systems with a privacy-preserving focus make use of pseudonyms\nso that identifying information such as names and social security\nnumbers are hidden. For example various electronic healthcare systems\nare using pseudonyms for the storage of e-health records."
            }
        },
        {
            "filename": "Pseudonymous-messaging.html",
            "title": "Pseudonymous Messaging",
            "excerpt": "A messaging service is enhanced by using a trusted third party to exchange the identifiers of the communication partners by pseudonyms.",
            "sections": {
                "Summary": "A messaging service is enhanced by using a trusted third party to\nexchange the identifiers of the communication partners by pseudonyms.",
                "Context": "This pattern can be used for online communications by email, through\nmessage boards, and newsgroups.",
                "Problem": "Messaging includes all forms of communication through emails,\narticles, message boards, newsgroups etc. This information could be\nstored and used to build sophisticated user profiles. Sometimes it can\nalso be used to prosecute people.",
                "Solution": "A message is send by a user to the server, which exchanges the\nsender's address with a pseudonym. Replied messages are sent back to\nthe pseudonymous address, which will then be swapped back to the\noriginal.\n\n\nThe goal of this pattern is to prevent unforeseen ramifications of the\nuse of online messaging services.",
                "Consequences": "Users can communicate more freely. Pseudonym servers can be misused to\nsend offensive messages, for spam mails or by criminals for illegal\nactivities. Under those circumstances it could be necessary to revoke\nthe pseudonymity of the corresponding parties.",
                "Examples": "Alice is a political activist and tries to organize a political\ndemonstration. Since her government does not like free speech, her\ncommunication channels are intensely monitored and one day, she simply\ndisappears into a labor camp and is never seen again.\n\n#",
                "Known Uses": "nym.alias.net a pseudonymous email system with the goal to provide\nsecure concealment of the user's identity. A Type I Anonymous Remailer\nforwards emails by modifying the message header and removing\nsender-related information."
            }
        },
        {
            "filename": "Reasonable-Level-of-Control.html",
            "title": "Reasonable Level of Control",
            "excerpt": "Let users share selectively (push) and make available (pull) specific information to predefined groups or individuals.",
            "sections": {
                "Context": "Users have certain expectations about what level of privacy they can expect in certain contexts. In general, they are given the means to provide themselves with as much or little shielding from intrusions as they need. This expectation carries over to usage of services (or products) offered by a Controller. Users expect that they can have an impact on what about them is known to a service, or others that use the service.",
                "Problem": "Users expect to be afforded sufficient self-determination over what information about them is collected or otherwise processed. The level of information and control desired, however, varies from person to person, as does the negative response when expectations are not met.\n\n##",
                "Forces/Concerns": "- Users want to share and be shared with, but have varying limits on what they feel comfortable sharing.\n- They have their own conceptions on what is worth withholding, and different regards for information sensitivities.\n- Not all users trust a service to handle their information with the same care they feel is due.\n- Many users want others to be able to know certain things about them on request, sometimes even in real-time.",
                "Solution": "Allow users to selectively and granularly provide information to a service, or its users, and have select information available to user-defined or predetermined groups.\n\n#",
                "Structure": "Users should be able to push their chosen information to (or have it pulled by) those they grant access. Using push mechanisms, users will have the greatest level of control due to the fact that they can decide the privacy level of their data case by case.\n\nPull mechanisms are less granular, as granting access to a group or individual continues until that access is denied. Within this time frame, the sensitivity of the data may fluctuate. However, the user should have the ability to retract access at will, and thus, can manage their own identified risks.\n\nUsers should also be made aware of the potential risks of over-sharing and increased sensitivity of data over time. This creates a complementing relationship between many Inform patterns, including Ambient(Ambient-Notice)/Asynchronous Notice(Asynchronous-Notice), Preventing mistakes or reducing their impact(Preventing-mistakes-or-reducing-their impact), as well as Awareness Feed(Awareness-Feed), Privacy Dashboard(Privacy-Dashboard) and their compounded patterns.\n\nAdditionally, Blur Personal Data(Blur-Personal-Data) and Partial Identification(Partial-Identification) patterns could be used inside the implementation.\n\n#",
                "Implementation": "When users are pushing their information to a service, design the user interface such that where appropriate, controls define the access, granularity, completeness, accuracy, etc. of the information being shared.\n\nElsewhere, ensure that any required fields are truly required, and that the completeness needed for those fields be indicated. When there are automatic suggestions, let users redefine or remove the information before it is collected by the service. These automatic suggestions should also not take place without consent.\n\nWhere information is provided on a continual basis to those granted access, provide the user with the necessary tools. They should be able to indicate who falls within a group, and what exactly that group can access, for how long, at what granularity, how far back they can look, and so forth.",
                "Examples": "- Google Maps (simple implementation)\n- Facebook (simple implementation)\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern is _refined_ by Selective Access Control(Selective-Access-Control) for socially oriented services, Negotiation of Privacy Policy(Negotiation-of-Privacy-Policy), and by Decoupling [content and location information visibility](Decoupling-content-and-location-information-visibility). The Negotiation of Privacy Policy(Negotiation-of-Privacy-Policy) pattern talks about methods which allow users to share their information (selectively and granularly) while this pattern provides these kinds of features at the beginning of the service's use. Decoupling [content and location information visibility](Decoupling-content-and-location-information-visibility) provides a means of control for attaching location to content. It is compliant with this pattern's solution in a more specific scenario.\n\nAs with most patterns in privacy, data protection, or self-determination, Reasonable Level of Control(Reasonable-Level-of-Control) _must use_ use Lawful Consent(Lawful-Consent). It also _may use_ Masquerade(Masquerade), which allows the user to set their identifiability.  This pattern may include that functionality inside its own solution.\n\nReasonable Level of Control(Reasonable-Level-of-Control) may be used by Support Selective Disclosure(Support-Selective-Disclosure) as one of the compound pattern's constituent patterns. It is also complemented by Discouraging blanket strategies(Discouraging-blanket-strategies), Private link(Private-link), and Active broadcast of presence(Active-broadcast-of-presence).\n\nThe first pattern in these complementary relationships defines methods which allow users to share their information (selectively and granularly). These methods could be complemented where considering a range of options as in this pattern. The second, Private link(Private-link), focuses on private sharing with anonymous users, while Reasonable Level of Control(Reasonable-Level-of-Control) focuses on granularity. They can work together to cover all possible audiences. The third complementary pattern, Active broadcast of presence(Active-broadcast-of-presence), aims to define the audience for posts through rules, through which it could complement this pattern considering its relationship to Selective Access Control(Selective-Access-Control) as a generalization.\n\nDue to the strong importance of notified and informed users in this pattern, the following patterns also complement this pattern:\n\n- Ambient(Ambient-Notice)/Asynchronous Notice(Asynchronous-Notice),\n- Preventing mistakes or reducing their impact(Preventing-mistakes-or-reducing-their impact),\n- Awareness Feed(Awareness-Feed) (and components), and\n- Privacy Dashboard(Privacy-Dashboard) (and components).\n\nAs per original source, this pattern should ideally use the following:\n\n- _Reasonable level of control should use APPROPRIATE PRIVACY FEEDBACK(Appropriate-Privacy-Feedback) (C5) to give users a greater understanding of what data is being collected about them._\n- _Systems should also have LIMITED DATA RETENTION(Time-limited-personal-data-keeping) (C12), so that personal information is stored only for long as it is needed. Limited retention is also one of the FAIR INFORMATION PRACTICES(Fair-Information-Practices) (C1)._\n- _Lastly, control is only useful if there is a PRIVACY-SENSITIVE ARCHITECTURE(Privacy-Sensitive-Architectures) (C6) backing it up, ensuring that users really do have control and that eavesdroppers are shut out._\n\n\n#",
                "Sources": "Based on:\n\n- E. S. Chung, J. I. Hong, J. Lin, M. K. Prabaker, J. a. Landay, and A. L. Liu, \u201cDevelopment and Evaluation of Emerging Design Patterns for Ubiquitous Computing,\u201d DIS \u201904 Proceedings of the 5th conference on Designing interactive systems: processes, practices, methods, and techniques, pp. 233\u2013242, 2004.\n    - The full catalog of the patterns by Chung et al. is in https://www.cs.cmu.edu/~jasonh/projects/ubicomp-design-patterns/ubicomp_patterns.pdf\n- S. Romanosky, A. Acquisti, J. Hong, L. F. Cranor, and B. Friedman, \u201cPrivacy patterns for online interactions,\u201d Proceedings of the 2006 conference on Pattern languages of programs - PLoP \u201906, p. 1, 2006.\n- H. Baraki et al., Towards Interdisciplinary Design Patterns for Ubiquitous Computing Applications. Kassel, Germany, 2014.\n- G. Iachello and J. Hong, \u201cEnd-User Privacy in Human-Computer Interaction,\u201d Foundations and Trends in Human-Computer Interaction, vol. 1, no. 1, pp. 1\u2013137, 2007."
            }
        },
        {
            "filename": "Reciprocity.html",
            "title": "Reciprocity",
            "excerpt": "Let users benefit according to the contributions they make.",
            "sections": {
                "Also Known As": "Fair distribution of efforts / Win-win situation",
                "Context": "In services where users may either socially or collaboratively contribute, participation may be a foundation for the service's business model. In these situations the quality and frequency of content affects the success of the service, and thus users have a large impact on its survival. Whether any single user contributes, or not, plays a role in profitability, which puts the controller in a position to encourage or enforce equal participation. Users may respond to such ideas negatively, however, especially if they do not see potential gains worthy of their effort and personal risks to privacy.",
                "Problem": "Equal participation does not always result in equal rewards. In some cases, participants do not need to contribute at all to benefit from the content generated by the group. Any who feel slighted are then likely to contribute less, eventually jeopardizing results for the group.\n\n##",
                "Forces/Concerns": "- Users may feel uncomfortable due to unfairly spread workload, and it could generate problems with the overall tasks' fulfillment. Some might decide to leave the group altogether.\n- Inequality may additionally generate a tense work or social environment.\n- Controllers want group dynamics to work so that content generation continues.",
                "Solution": "Limit the benefits gained from the group effort to the amount of effort contributed. All contribution should be afforded proportionate gains.\n\n\n#",
                "Structure": "_Ensure that all group members' activities result in an improved group result that is beneficial for all group members again. Prohibit people to benefit from group results if they are not willing to help the group in return._\n\n#",
                "Implementation": "Prior to completing designs on functionality, determine the benefits as opposed to efforts or costs on all possible user activities. Weigh these, with input from any necessary stakeholders. Any feature which does not affect more than one user does not need to be assessed.\n\nFor user groups that are able to affect one another within a feature or functionality, consider them each a case for a collaboration mode. If a user within this group performs an activity, they are expected to reciprocate on any benefits (or gain from costs). This is in proportion to the weighted effort of the feature determined earlier.\n\nThe way in which users reciprocate is up to specific implementation. It may include required effort (satisfied by certain activities) before their activity's resulting benefit is realized. Alternatively it may prevent additional beneficial activities until they contribute. It may also make their discrepancy public, allowing the users to determine tolerable thresholds. In all these cases it is useful to keep track of each user's ratio within each collaboration mode they feature.\n\nIt is important that any use of user data is done so under the explicit and properly obtained permissions required. Deriving value from participation rewards users for providing personal information, and thus they must be informed about how their data may be used.",
                "Consequences": "##",
                "Benefits": "- _Finding the inequalities in the design phase involving all stakeholders can reduce the objections for participating to the system since the benefit is made explicit to the end-user._\n- Using this pattern minimizes reasons for groupware applications failure.\n\n##",
                "Liabilities": "- _The pattern is only needed in situations, where the critical mass of participation can only be reached with most users participating. If the community is very large (e.g. a news group), it can succeed with a small number of active participants and a larger number of inactive participants (free riders, lurkers)._\n- Consent given by users needs to be freely-given, which is a requirement easily overlooked as controllers are tempted to coerce participation. As with sunk cost, emotional investment can pressure users into choices they do not truly consent to. Therefore, Lawful Consent(Lawful-Consent) should be used in this pattern.",
                "Examples": "- Reddit\n    - Gold: those who never 'gild' are set apart from those that do, as this fact is made clear within a profile.\n    - Upvotes: while individual votes are not publicized, the votes received as part of contributing are.\n- Facebook Friends; LinkedIn Contacts; etc.: these relationships are one-to-one, to have a contact is to be a contact.\n- TUKAN;\n- Buddy Lists in Instant Messaging systems;\n- Bulletin Board Systems\n\n#",
                "Known Uses": "_TUKAN: The collaborative programming environment TUKAN introduced the concept of modes of collaboration (MoC) to ensure reciprocity. A MoC is a lightweight mode, which defines possible collaborative activities. It combines a specific level of privacy (cf. Masquerade(Masquerade)) with the right of receiving information about other users. It thus provides a set of predefined Attention Screen(Attention-Screen)s. This combination ensures that a user can only utilize information from other users at a privacy level on which he is also willing to reveal personal information._\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern may be used by Incentivized Participation(Incentivized-Participation). It is complemented by Pay Back(Pay-Back), which compensates without a focus on equal work for equal gain. It is also led to by Masquerade(Masquerade). The application of Masquerade(Masquerade) allows users to potentially misuse a system, or benefit from it without contributing. This pattern addresses that issue.\n\nReciprocity(Reciprocity) may also complement Buddy List(Buddy-List), as often these lists are reciprocal. It _must use_ Lawful Consent(Lawful-Consent), however, as motivating users to provide personal information should be done only along with informed, explicit, and freely-given (uncoerced) consent.\n\nAs per Sch\u00fcmmer (2004), it is also complemented by the following patterns which are invasive by design, but introduce useful notions:\n\n- Show the Expert (dark pattern), showing contributions prominently;\n- Who\u2019s Listening (dark pattern), feedback by subscribers.\n\n#",
                "Sources": "Based on:\n\nT. Sch\u00fcmmer, \u201cThe Public Privacy \u2013 Patterns for Filtering Personal Information in Collaborative Systems,\u201d in Proceedings of CHI workshop on Human-Computer-Human-Interaction Patterns, 2004."
            }
        },
        {
            "filename": "Selective-Access-Control.html",
            "title": "Selective access control",
            "excerpt": "Allow users to specify who may access the content they generate, both during and after submission.",
            "sections": {
                "Also Known As": "Selective Access Control in Forum Software;\nPrivacy Options in Social Networks",
                "Context": "Users enjoy social reaction when posting content in socially oriented services on the Internet. Though sometimes the reactions are not as ideal. Some content is inappropriate for some audiences, and some users would rather keep some content mostly private. While users are capable of sharing content privately, perhaps through Private Link(Private-link), they may wish to have better control over whom they share with in their service of choice. The controller providing this service may too want its users to share more specifically.",
                "Problem": "Users want to control the visibility of the content being shared, because it may not currently be appropriate for all users.\n\n##",
                "Forces/Concerns": "- Users aim to share content aimed at different kinds of users because they have varying social proximities (friends, family, colleagues, etc.).\n- Users want to share content to certain other users based on the content\u2019s nature for that user specifically.\n- Users could have trouble over-sharing, dealing with content aimed at the wrong audience, or under-share as a precaution.",
                "Solution": "_Provide users with the option to define the audience of their contributions by specifying the access rules to their content._\n\n\n\n\n\n#",
                "Implementation": "Implement visual controls to help users to define access control rules when they create or modify content.\n\nThese rules could be defined based on users, groups of users, or based on context-aiding attributes like age or location. For groups, it should be possible to directly define who may view the post being published (e.g. a post with personal data aimed only at a group of close friends). Contextually, it may be possible to define an attribute constraint based on whom in general the post is intended for (e.g. a post aimed at people in a specific town or region).",
                "Consequences": "##",
                "Benefits": "- Users have the possibility to control access as they want in every submission. It allows configuration based on kinds of users or the content's context.\n\n##",
                "Liability": "- Users could find granular configurations time consuming or tedious, so a default configuration for new submissions would be helpful.",
                "Examples": "- Facebook\n- Youtube\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "Selective Access Control(Selective-Access-Control)\n is complemented by Private link(Private-link), which focuses on private sharing with anonymous users while this pattern defines the audience for a contribution. It is a part of the Support Selective Disclosure(Support-Selective-Disclosure) compound pattern, and thus may be used by it.\n\nThis pattern _refines_ Reasonable Level of Control(Reasonable-Level-of-Control) in a socially oriented service context. It _complements_ both Discouraging Blanket Strategies(Discouraging-blanket-strategies) (more flexible privacy setting management) and Decoupling [content and location information visibility](Decoupling-content-and-location-information-visibility) (selectively providing location access).\n\nDespite focusing on the choices within access control, decisions which users make should still be informed, and explicit, with the consent involved uncoerced. Therefore, this pattern also _must use_ Lawful Consent(Lawful-Consent).\n\n#",
                "Sources": "Based on:\n\nDrozd, O. (n.d.). Privacy Patterns Catalog. Retrieved January 25, 2017, from http://privacypatterns.wu.ac.at:8080/catalog/\n\nFischer-H\u00fcbner, S., K\u00f6ffel, C., Pettersson, J.-S., Wolkerstorfer, P., Graf, C., Holtz, L. E., \u2026 Kellermann, B. (2010). HCI Pattern Collection \u2013 Version 2."
            }
        },
        {
            "filename": "Sign-an-Agreement-to-Solve-Lack-of-Trust-on-the-Use-of-Private-Data-Context.html",
            "title": "Sign an Agreement to Solve Lack of Trust on the Use of Private Data Context",
            "excerpt": "Services of a controller may require users to sign contracts that stipulate their obligations and processing purposes for which users must consent to use the service. This ensures that users can trust the controller as it is bound to the contract it signs.",
            "sections": {
                "Also Known As": "Suggested: Contractual Consent",
                "Context": "Users do not inherently trust controllers who provide services (or products), as they do not have assurances as to what the controller's or their processor's true intentions are. Controllers and processors typically aim to make profit, but this might be at the expense of users if those users do not consider their privacy needs. The controller might have reasonable defaults or levels of control(Reasonable-Level-of-Control), but users also need to feel reassured that their choices are being honored. This is especially true of what they do or do not provide Lawful Consent(Lawful-Consent) for.",
                "Problem": "The controller does not necessarily have the trust of its users, and needs this trust for its services to process their data.\n\n##",
                "Forces/Concerns": "- The controller wishes to provide services to the user, but needs their trust and consent to do so.\n- Processors want to manipulate data without having to worry about whether the data contains consented information or not.\n- Users want to use services, but not at the risk of their own personal privacy requirements being undermined.\n- Users want to know what they can safely provide to the controller and what information might be revealed about them if they use the service.\n- Users need to feel that the controller will honor any decision taken about their personal data.",
                "Solution": "The service should provide the user with a contractual agreement (featuring privacy policy) which binds the controller to their word, provided that the user consents to the processing of data needed for specific purposes. The agreement should also bind any representative of the controller. It should be straightforward and clear enough for the user to comprehend.\n\n\n\n\n\n\n#",
                "Implementation": "The service should feature a mechanism (e.g. landing page or unavoidable introduction) prior to collection, which stipulates the need for user consent. There should be a reasonable effort to prevent users from bypassing this mechanism.\n\nThe specific purposes for which their data will be processed should be made clear. The service should, at the same time, outline the contractual obligations it will be held against should the user consent. The user should be able to seek further detail about these obligations without first needing to consent.\n\nIf users decide to consent, they can make this clear by interacting with a mechanism (e.g. button) which clearly represents their agreement to the contract.\n\nA further implementation could additionally allow the user access to a subset of the service which does not require any data, in order to help justify their consent. This would also alleviate the user's potential apprehension about the time taken to review and inform themselves about their decision.",
                "Consequences": "##",
                "Benefits": "The controller, any of their representatives, and their users are tied to the terms of the contract and the legal implications it holds. Any disputes will involve both contract law and privacy law.\n\n##",
                "Liabilities": "Users may be discouraged to use a service if they are made aware of the risks to their privacy, or introduced to the ways in which their data can be used to reveal information.\n\nThey may also be tempted to consent without reading about the contract or how their data may be used. Therefore it is useful to not force an immediate decision, as this can invalidate the consent as not freely given or uninformed.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "Sign an Agreement to Solve Lack of Trust on the Use of Private Data Context(Sign-an-Agreement-to-Solve-Lack-of-Trust-on-the-Use-of-Private-Data-Context) is one of the components of the compound pattern, Lawful Consent(Lawful-Consent). As such, they share a _may use_ relationship.\n\nThis pattern is _similar to_ Obtaining Explicit Consent(Obtaining-Explicit-Consent). It aims to get the user's trust, while the second pattern focuses on collecting consent in a manner which cannot be second-guessed. Although they may seem to be complementary at first, the solutions are actually quite similar. Each pattern points out advantages for the user or the controller from their own perspective.\n\n#",
                "Sources": "Based on:\n\nAsnar, Y., Bryl, V., Bonato, R., Campagna, L., Donnan, D., Khoury, P. El, Giorgini, P., Holtmanns, S., Martinez-Juste, M., Massacci, F., Porekar, J., Riccucci, C., Saidane, A., Seguran, M., Thomas, R., & Yautsiukhin, A. (2007). Initial Set of Security and Privacy Patterns at Organizational Level, (December 2006). Retrieved from http://www.serenity-forum.org/IMG/pdf/A1.D3.1_patterns_at_organizational_level_v1.3_final.pdf"
            }
        },
        {
            "filename": "Single-Point-of-Contact.html",
            "title": "Single Point of Contact",
            "excerpt": "The Single Point of Contact is a security authority who protects the privacy and security of sensitive data stored online by validating the authority of requests and ensuring secure communication channels.",
            "sections": {
                "Also Known As": "Personal Agent",
                "Context": "Many controllers make use of a storage platform (i.e. 'cloud' facilities), such as e-Health services that keep their sensitive patient data in a distributed online storage. The sensitivity of this information raises concern and garners a need for special care. The storage medium in this case rules out typical security approaches.",
                "Problem": "Effective distributed storage services require specialized privacy management. The deficiencies of traditional means may be expressed through the following:\n\n- traditional security mechanisms are platform dependent;\n- typically they are difficult to federate or distribute;\n- compliance with protocol can be cumbersome; and\n- as such they are often inflexible.\n\n##",
                "Forces/Concerns": "- Controllers wish to protect the sensitive or otherwise personal data they are charged with\n- They want to acquire genuine Lawful Consent(Lawful-Consent) in a streamlined fashion\n- They need this process to be facilitated, supervised, and provably sound",
                "Solution": "Single Point of Contact\u00a0adopts a claim-based approach for both authentication and authorization similar to a super-peer design, also acting as a (Resource) Security Token Service, an Identity and Attribute Provider, and a Relying Party. It features a tried and proven\u00a0expressive e-consent\u00a0language, and can communicate with other SPoCs in a Circle of Trust\n\n##",
                "Rationale": "Overcoming the inflexibility of traditional security mechanisms is partly solved by claim-based identity, which _provides a platform-independent way of presenting identity information_.\n\n#",
                "Structure": "_A SPoC is essentially a security authority, which protects patients' privacy in e-Health applications by providing a claim-based authentication and authorisation functionality  (Baier et al. 2010), and facilitating secure communication between an e-Health service and its clients._\n\nSPoC shares characteristics with a Central Medical Registry (CMReg), which performs authentication and manages identifying access to anonymised medical documents in a central repository. SPoC additionally facilitates secure e-Health service development and integration. It is able to share Electronic Health Records (EHRs) through a peer-to-peer network as an overarching, claim-based, super-peer-like representative of the e-Health community. Multiple SPoCs may also communicate, constituting a Circle of Trust.\n\nSee Fan et al. (2012) Figure 1 for a visual depiction.\n\nThe SPoC features a *Domain Ontology* for providing vocabulary towards claims and policies, a *Policy Engine* for consent syntax using natural language and pseudonym storage, and an *Interface Service*. The interfaces provided include Authentication, Authorisation, and Pseudonym Resolution.\n\n#",
                "Implementation": "A SPoC is able to issue security tokens as a Security Token Service (STS), authenticate local domain users as an Identity Provider, certify attributes as an Attribute Provider, and accept external claims as a Relying Party. When in a Circle of Trust, the SPoC can also translate the claims of other SPoCs as a Resource STS.\n\nSPoCs' implementation of e-consent features the following levels, based on Coiera et al. (2004):\n\n- general consent with or without specific exclusions;\n- general denial with or without specific consents;\n- service authorisation;\n- service subscription; and\n- investigation.\n\nAs with Pruski's (2010) e-CRL, SPoCs' e-consent also considers _specific grantees, operations, purposes and period of validity_.\n\nFor more information see Fan et al. (2012).",
                "Consequences": "The SPoC ensures that the privacy of sensitive medical data is protected, and that it is distributed securely and only to the people who are allowed to access the data. However, it requires a reliable credential-based authentication system to be able to validate requests.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _must use_ Lawful Consent(Lawful-Consent), as it features an expressive e-consent language which aims to provide sufficient means to acquire permission for processing that is valid.\n\n#",
                "Sources": "- Fan, L., Buchanan, W. J., Lo, O., Thuemmler, C., Lawson, A., Uthmani, O., Ekonomou, E., & Khedim, A. S. (2012). SPoC: Protecting Patient Privacy for e-Health Services in the Cloud. Retrieved from http://researchrepository.napier.ac.uk/4992/\n    - D. Baier, V. Bertocci, K. Brown, E. Pace, and M. Woloski, A Guide to Claims-based Identity and Access Control, Patterns & Practices. ISBN: 9780735640597, Microsoft Corp., Jan. 2010.\n    - E. Coiera and R. Clarke, \u201ce-Consent: the Design and Implementation of Consumer Consent Mechanism in an Electronic Environment,\u201d JAMIA, vol. 11, no. 2, pp. 129\u2013140, 2004.\n    - C. Pruski, \u201ce-CRL: A Rule-Based Language for Expressing Patient Electronic Consent,\u201d in Proc. of eTELEMED. IEEE, 2010, pp. 141\u2013146.\n\n- C. Bier and E. Krempel, \u201cCommon Privacy Patterns in Video Surveillance and Smart Energy,\u201d in ICCCT-2012, 2012, pp. 610\u2013615."
            }
        },
        {
            "filename": "Sticky-policy.html",
            "title": "Sticky Policies",
            "excerpt": "Machine-readable policies are sticked to data to define allowed usage and obligations as it travels across multiple parties, enabling users to improve control over their personal information.",
            "sections": {
                "Summary": "Machine-readable policies are sticked to data to define allowed usage\nand obligations as it travels across multiple parties, enabling users\nto improve control over their personal information.",
                "Context": "Multiple parties are aware of and act according to a certain policy\nwhen privacy-sensitive data is passed along the multiple successive\nparties storing, processing and sharing that data.",
                "Problem": "Data may be accessed or handled by multiple parties that share data\nwith an organisation in ways that may not be approved by the data\nsubject.",
                "Solution": "Service providers use an obligation management system. Obligation\nmanagement handles information lifecycle management based on\nindividual preferences and organisational policies. The obligation\nmanagement system manipulates data over time, ensuring data\nminimization, deletion and notifications to data subjects.\n\n\nThe goal of the pattern is to enable users to allow users to control\naccess to their personal information.",
                "Consequences": "Bene\ufb01ts: Policies can be propagated throughout the cloud to trusted\norganisations, strong enforcement of the policies, traceability.\nLiabilities: Scalability: policies increase size of data. Practicality\nmay not be compatible with existing systems. It may be difficult to\nupdate the policy after sharing of the data and existence of multiple\ncopies of data. It requires ensuring data is handled according to\npolicy e.g. using auditing.",
                "Examples": "When data is shared by an organisation they can use privacy preserving\npolicy to enforce respecting user privacy by third party organisations\nthat use, process and store such data. For example, a hospital may\nshare data with third party organisations requiring adhering to\nspecific privacy policies associated with the data.\n\n#",
                "Known Uses": "Examples of policy specification languages include EPAL, OASIS XACML\nand W3C P3P. Tracing of services can use Identi\ufb01er-Based Encryption\nand trusted technologies. An alternative approach using Merkle hash\ntree has been proposed by P\u00f6hls (2008). A Platform for Enterprise\nPrivacy Practices (E-P3P) (2003) distinguishes the enterprise-specific\ndeployment policy from the privacy policy and facilitates the\nprivacy-enabled management and exchange of customer data. References:\nPearson, S., Sander, T. and Sharma, R., Privacy Management for Global\nOrganisations, Data Privacy Management and Autonomous Spontaneous\nSecurity, LNCS 5939, Springer, pp. 9-17., 2009 Ph\u00f6ls, H.G., Veri\ufb01able\nand Revocable Expression of Consent to Processing of Aggregated\nPersonal Data. ICICS, pp.279-293, 2008 Karjoth, G., Schunter, M., &\nWaidner, M., Platform for enterprise privacy practices:\nPrivacy-enabled management of customer data. In Privacy Enhancing\nTechnologies, pp. 69-84, Springer Berlin Heidelberg, 2003"
            }
        },
        {
            "filename": "Strip-invisible-metadata.html",
            "title": "Strip Invisible Metadata",
            "excerpt": "Strip potentially sensitive metadata that isn't directly visible to the end user.",
            "sections": {
                "Summary": "Strip potentially sensitive metadata that isn't directly visible to the end user.",
                "Context": "When a service requires a user to import data from external sources (eg.\npictures, tweets, documents) different types of metadata may be \ntransmitted. Users may not be aware of the metadata as it can be\nautomatically generated or not directly visible. Services might be\ninadvertently responsible for exposing private metadata, or going\nagainst users' expectations.",
                "Problem": "Users are not always fully aware of the various kinds of metadata\nattached to files and web resources they share with online services.\nMuch of this data is automatically generated, or not directly visible to\nusers during their interactions. This can create situations where, even\nthough users share information explicitly with services, they may be\nsurprised to find this data being revealed. In certain cases where the\ndata is legally protected, the service could be held responsible for any\nleakage of sensitive information. \n\nHow should services that need users to share data and upload files\ntreat additional metadata attached with files? In case of uploading\ndocuments and images, which parts of the metadata can be treated as\nexplicitly shared information.",
                "Solution": "Stripping all metadata that is not directly visible during upload time,\nor during the use of the service can help protect services from\nleaks and liabilities. Even in cases where the information is not\nlegally protected, the service can protect themselves from surprising\ntheir users and thus alienating them. \n\nAdditionally when users share data with services, they can be presented\nwith a preview of the data obtained by the service, including any\nmetadata ``[Preview Shared Data]``. This allows users to be more aware\nof information that they are sharing with the services, and in many\ncases with other entities on the Internet.\n\nTo summarize: user metadata that can not be made visible to users\nclearly should be stripped to avoid overstepping the users' expectations.",
                "Examples": "1. Uploading images to twitter.com\n\n   Twitter.com removes EXIF data from images uploaded to their image\n   sharing service. Previously there have been many breaches of personal\n   location by using EXIF data shared by image sharing services. \n\n2. Hiding EXIF data on Flickr.com\n\n   In certain cases services might build features based on\n   metadata, or the metadata sharing could be an important part of the\n   community of users. Flickr.com allows users to hide their EXIF data from\n   public display, and also provides an interface for users to easily see\n   whether they are sharing location as part of uploading their images. \n\n   _TODO: add screenshots_"
            }
        },
        {
            "filename": "Support-Selective-Disclosure.html",
            "title": "[Support] Selective Disclosure",
            "excerpt": "Many services (or products) require the collection of a fixed, often large, amount of personal data before users can use them. Many users, instead, want to freely choose what information they share. This pattern recommends that services Support Selective Disclosure, tailoring functionality to work with the level of data the user feels comfortable sharing.",
            "sections": {
                "Summary": "Many services (or products) require the collection of a fixed, often large, amount of personal data before users can use them. Many users, instead, want to freely choose what information they share. This pattern recommends that services Support Selective Disclosure, tailoring functionality to work with the level of data the user feels comfortable sharing.",
                "Context": "Controllers aim to design services to be both maintainable and extensible, though as a result blanket strategies are used to simplify designs. Users are individuals and do not always respond the same way to different approaches. Restricting user choice on processing displeases users, and bundling purposes for that processing conflicts with international law. Users want a service which works without the data they do not want to provide, even so far as effectively anonymous usage.",
                "Problem": "Controllers typically want to collect data by default, and tend to limit the diversity of their services, and the choices they provide, to encourage that. This goes against the best interests of the users, who have varying data collection tolerances.\n\nThe underlying issues are discussed in more detail below.\n\n##",
                "An All or Nothing Mindset": "Controllers are tempted to see consent as all-encompassing, see held personal data as data available for use, and the lack of that data as a barrier to service. This mindset reduces adoption of the offering and may introduce a lack of trust.\n\n##",
                "The Temptation to Share by Default": "User information is frequently acquired before users are given the opportunity to decide whether to share. An example of this is in cookie policies, where the whole site is loaded before the user is shown the policy. From this loading, metadata is often generated even if the user chooses to leave the site.\n\nThis problem is also present when users register for or acquire a service, as unnecessary information is often requested as part of the process.  In the case of account registration users are often provided with inappropriate default settings. They are typically sent additional offers by default as well. The negative implications of these defaults are also not necessarily reversible, as the Internet is notorious for its inability to forget.\n\n##",
                "Data Gluttony": "Services tend to collect a surplus of information, especially in contexts where monitoring is integral to the system, such as in productivity tracking. This unnecessary level of detail results in negative experience factors for the tracked individuals (for e.g. increased levels of anxiety) which in a work environment may affect their actual productiveness.\n\n##",
                "Forces/Concerns": "- Controllers want their system to be applicable to as many potential users as possible, but do not want this to heavily inflate costs or jeopardise profits\n- Users want to be able to use a system anonymously, or with as little leakage of their personal information as needed to perform functionality\n- Controllers do not want users to be capable of malicious activity without consequence\n- Many controllers want to benefit from the data they collect from their users, but do not want to violate their users' trust by using their information excessively or otherwise inappropriately",
                "Solution": "Determine what information is integral to the functioning of the system. If functionality may be sustained with less, it should be an option for the user, even if doing so comes with reduced usability. Additionally, provide anonymous functionality only where it cannot jeopardise the service. Lower levels of anonymity may be provided in relation to various capabilities for abuse.\n\n##",
                "Rationale": "The key to a successful solution is meeting the correct balance between how little the system can work with and what is feasible in performance. This will affect the applicability of the system; a system which optionally functions with less will attract far more users. This increases the popularity of the system and therefore offsets a certain amount of additional implementation costs.\n\n\n\n\n\n\n#",
                "Implementation": "##",
                "Anonymous Usage": "At one extent it may be possible to benefit from the system anonymously, though whether this is feasible will depend on the level of abuse anonymous usage might attract. Alternatively, this can be approached from the perspective of revocable privacy. That is, tentative or eroding anonymity. If this would result in an unsustainable business model, however, a re-balance of usability may be sufficient.\n\nIt is important to note that while anonymous usage might not translate into direct profit, additional contributors and positive public perception may increase overall user activity. Furthermore, there are payment methods which support some level of anonymity if necessary.\n\n##",
                "Assumption of Modesty": "Where users choose to register, it should not be assumed that they wish to use all of the system's services. Short of explicitly opting for 'best experience settings' (with sufficient explanation; not the default option), user preferences should default to the most privacy-friendly configuration.\n\nThere exist numerous strategies for streamlining the preference-tailoring process, including gradual elevation as they begin to use services (see Awareness Feed(Awareness-Feed) and Lawful Consent(Lawful-Consent)).\n\n##",
                "The Right to Reconsider": "User decisions should be amendable. For example, an agreement to share activity with another user may not carry over to all future usage. A user may decide to share something once in a while, or share regularly, but not always. The system should be able to account for this behaviour if it aims to prevent mistaken actions.\n\n##",
                "Look Before You Leap": "In situations where there are requirements for personal data, particularly when strict, users should be aware of this prior to their consent. These services should also not be coupled with other services holding lower requirements unless it would be infeasible not to. Where users are required to use the system, no unnecessary information should be used. In a productivity tracking example, this may mean that users are only identified when their productivity falls, or perhaps if they opt to receive credit for their work.",
                "Consequences": "##",
                "Benefits": "Due to increased control over their data, users may be able to share pieces of information which they otherwise wouldn't due to it otherwise being coupled with what they perceive to be more sensitive.\n\nUsers will be less likely to mistakenly release personal information to the public, since they would perhaps be able to set their own defaults, or by default stay private. To a further extent, users may be capable of participating or benefiting from a system anonymously. Where this is the case, the activity levels of the system will benefit, and users who stayed anonymous due to mixed feelings about the system may decide to register and authenticate later, once trust has been built.\n\n##",
                "Liabilities": "The system's complexity will increase by a certain degree, as not only will each user need to have their preferences set, stored, and adhered to, but also services will need to account for variable inputs. As such, flaws in the system will be felt with greater effect.\n\nProviding anonymity for some contexts may result in increased undesired behaviour, depending on the level of anonymity provided. Anonymising a service often requires additional processing power, especially in the case of revocable privacy.\n\n#",
                "Constraints": "By separating functionality according to purpose and personal data needed, as well as providing variations where feasible, the system will be more complex. Services will need to be designed while taking into consideration the potential for limited access to data.\n\nImprovements to results may therefore be limited as well. However, the controller may be able to gauge adoption in data-rich services while they are investing in them. The same holds for determining how valuable non-invasive alternatives are, as users will express their intolerance for invasiveness through their actions.",
                "Examples": "* TUKAN; a collaborative software development environment which introduces Modes of Collaboration: lightweight contexts which filter collaboration possibilities according to user privacy preferences.\n * Anonymous access; to a degree, there exist many examples of websites which allow access to content without a need to identify users. Especially in cases where usage analytics are kept to a minimum, or tracking is disabled completely, users may use a service without a need to be monitored.\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern may be complemented by Masquerade(Masquerade), as together they may focus on audience and identifiability when determining disclosure choices.\n\nSupport Selective Disclosure(Support-Selective-Disclosure) is a compound pattern. It contains and therefore _may use_ a variety of patterns geared towards granular and contextual privacy preferences and choices regarding the provision of data. These include:\n\n- Negotiation of Privacy Policy(Negotiation-of-Privacy-Policy);\n- Buddy List(Buddy-List);\n- Discouraging blanket strategies(Discouraging-blanket-strategies);\n- Decoupling [content and location information visibility](Decoupling-content-and-location-information-visibility);\n- Reasonable Level of Control(Reasonable-Level-of-Control);\n- Selective Access Control(Selective-Access-Control); and\n- Enable/Disable Functions(Enable-Disable-Functions).\n\nIt also _may use_ Private link(Private-link) as a means to provide anonymous functionality in a resource sharing context.\n\nSupport Selective Disclosure(Support-Selective-Disclosure) may be aimed towards providing users with choice, but it must still do so conscientiously. It _must use_ Lawful Consent(Lawful-Consent) in order to ensure that consent for each choice is informed, explicit, and freely-given.\n\n#",
                "Sources": "S. Ahern, D. Eckles, N. Good, S. King, M. Naaman, and R. Nair, \u201cOver-Exposed ? Privacy Patterns and Considerations in Online and Mobile Photo Sharing,\u201d CHI \u201907, pp. 357\u2013366, 2007.\n\nH. Baraki et al., Towards Interdisciplinary Design Patterns for Ubiquitous Computing Applications. Kassel, Germany, 2014.\n\nE. S. Chung, J. I. Hong, J. Lin, M. K. Prabaker, J. a. Landay, and A. L. Liu, \u201cDevelopment and Evaluation of Emerging Design Patterns for Ubiquitous Computing,\u201d DIS \u201904 Proceedings of the 5th conference on Designing interactive systems: processes, practices, methods, and techniques, pp. 233\u2013242, 2004.\n\nG. Iachello and J. Hong, \u201cEnd-User Privacy in Human-Computer Interaction,\u201d Foundations and Trends in Human-Computer Interaction, vol. 1, no. 1, pp. 1\u2013137, 2007.\n\nJ. Porekar, A. Jerman-Bla\u017ei\u010d, and T. Klobu\u010dar, \u201cTowards organizational privacy patterns,\u201d Proceedings - The 2nd International Conference on the Digital Society, ICDS 2008, 2008.\n\nS. Romanosky, A. Acquisti, J. Hong, L. F. Cranor, and B. Friedman, \u201cPrivacy patterns for online interactions,\u201d Proceedings of the 2006 conference on Pattern languages of programs - PLoP \u201906, p. 1, 2006.\n\nT. Sch\u00fcmmer, and J. M. Haake (2001). \u201cSupporting distributed software development by modes of collaboration,\u201d in Proceedings of ECSCW 2001, Bonn.\n\nT. Sh\u00fcmmer, \u201cThe Public Privacy \u2013 Patterns for Filtering Personal Information in Collaborative Systems,\u201d in Proceedings of CHI workshop on Human-Computer-Human-Interaction Patterns, 2004."
            }
        },
        {
            "filename": "Trust-Evaluation-of-Services-Sides.html",
            "title": "Trust Evaluation of Services Sides",
            "excerpt": "A visual highlight provided by an authority which signals the extent to which given privacy criteria are fulfilled. It should be clearly placed and easily found, with links to additional information.",
            "sections": {
                "Also Known As": "Privacy Transparency Label",
                "Context": "When using a service (or product) offered by a controller, the level of trust held by users is crucial. Without sufficient trust, the users would seek alternatives or generate bad publicity. They will use a system more cautiously, regardless of whether it is necessary. In many systems this lessens the quality of service offered, not only to the user in question, but holistically.",
                "Problem": "Users want to have reason to trust that a service does not undermine their personal privacy requirements. They do not want to have to take controllers, and third parties, at their word alone.\n\n##",
                "Forces and Concerns": "- Controllers, as well as third parties, want to show that they are provably trustworthy and reliable\n- Less confident entities will not make this effort alone\n- Users want to verify claims which controllers and third parties make without having to do so themselves\n- Users benefit from a standardised way of indicating trust, as it is easier and quicker to look into if done consistently and often",
                "Solution": "Supply a function which informs users of the trustworthiness and reliability of services, and that of the third parties connected to those services. These qualities may be determined, and assured, through independent evaluation of given criteria.\n\n#",
                "Structure": "Information regarding a service's trustworthiness and reliability needs to be clearly indicated to the user prior to or during collection. It may therefore be brought up along with obtaining informed consent. This ensures that the user does not make misinformed or uninformed decisions, especially as this can seriously jeopardise trust.\n\nA visual highlight which succinctly asserts this quality may also be displayed in persistent manner, or where otherwise contextually relevant.\n\n#",
                "Implementation": "_A trust evaluation function should be based on suitable parameters for measuring the trustworthiness of communication partners and for establishing reliable trust._\n\n_Trust in a service provider can be established by monitoring and enforcing institutions, such as data protection commissioners, consumer organisations and certification bodies. Privacy seals certified by data protection commissioners or independent certifiers (e.g., the EuroPrise seal, the TRUSTe seal or the ULD G\u00fctesiegel) therefore provide especially suitable information for establishing user trust. Such static seals can be complemented by dynamic seals conveying assurance information about the current security state of the system and its implemented privacy and security (PrimeLife) functions. Further information sources by independent trustworthy monitoring organisations that can measure the trustworthiness of services sides can be blacklists maintained by consumer organisations or privacy alert lists provided by data protection commissioners._\n\n_Also, reputation metrics based on other users' ratings can influence user trust. Reputation systems, for instance in eBay, can however often be manipulated by reputation forging or poisoning. Besides, the calculated reputation values are often based on subjective ratings by non-experts, through which privacy-friendliness may be difficult to judge._\n\n_A trust evaluation function should in particular follow the following design principles:_\n\n- _Use a multi-layered structure for displaying evaluation results._\n- _Make clear who is evaluated_\n- _Inform the user without unnecessary warnings._\n- _Use a selection of meaningful overall evaluation results.",
                "Consequences": "Users will be able to better justify the trust they place in controllers who measure high levels of trustworthiness and reliability, and will know of greater risks in lower trust. A familiarity with the approach will also cause a healthy skepticism of controllers who do not participate, or have low confidence evaluations.",
                "Examples": "Determine an appropriate metric for evaluating trustworthiness of partners of the service who will receive personal data as third parties. This can be simple, such as meeting expectations, failing them, or exceeding them. PrimeLife suggests 'poor', 'fair', and 'good', with fair evaluations having neither negative nor positive influences. Blacklists or alert lists make for a poor evaluation regardless of positive aspects.\n\nThese evaluations are shown to users prior to their related parties having consent for access. The notification is not shown too frequently, as extensive warnings may be misleading to users. While they should be aware of neutral or unevaluated parties, it may not be desired to worry them without cause. There should also be just enough information to raise awareness, allowing the user to investigate further if desired. A notification for a fair evaluation may be 'we have not found any issues with this partner' for example, with a neutral colour which matches the rest of the interface. Poor evaluations could be yellow or red (alarming colours), with good evaluations green or blue (positive colours).\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ Policy Matching Display(Policy-matching-display) and Awareness Feed(Awareness-Feed). It also implicitly _complements_ Icons for Privacy Policies(Icons-for-Privacy-Policies), Privacy Color Coding(Privacy-color-coding), and Appropriate Privacy Icons(Appropriate-Privacy-Icons).\n\nWith Policy Matching Display(Policy-matching-display), these patterns may work together towards providing the user with information which builds trust. This will be based on both preferences matching and means for demonstrating trustworthiness. With Awareness Feed(Awareness-Feed), this pattern keeps users informed about what risks their disclosures might face, providing feedback which can relate to and further explain met criteria.\n\nAs visual cues, Appropriate Privacy Icons(Appropriate-Privacy-Icons), Icons for Privacy Policies(Icons-for-Privacy-Policies), and Privacy Color Coding(Privacy-color-coding) aid this pattern implicitly through Awareness Feed(Awareness-Feed) by augmenting this pattern with quickly interpreted, visual information. This is useful for highlighting trust levels to the user.\n\n#",
                "Sources": "Additional information can be found in the original version of the pattern:\nS. Fischer-H\u00fcbner, C. K\u00f6ffel, J.-S. Pettersson, P. Wolkerstorfer, C. Graf, L. E. Holtz, U. K\u00f6nig, H. Hedbom, and B. Kellermann, \u201cHCI Pattern Collection - Version 2,\u201d 2010.\n\nThis pattern is also highlighted in other works:\nJ. Siljee, \u201cPrivacy transparency patterns,\u201d in EuroPLoP \u201915, 2015, pp. 1\u201311.\n\nO. Drozd, \u201cprivacypatterns.wu.ac.at - Privacy Patterns Catalog,\u201d privacypatterns.wu.ac.at, 2016. Online. Available: http://privacypatterns.wu.ac.at:8080/catalog/. Accessed: 25-Jan-2017.\n\nC. Andersson, J. Camenisch, S. Crane, S. Fischer-H\u00fcbner, R. Leenes, S. Pearson, J. S. Pettersson and D. Sommer. \u201cTrust in PRIME\u201d. Proceedings of the 5th IEEE Int. Symposium on Signal Processing and IT, pages 18-21, 2005."
            }
        },
        {
            "filename": "Trustworthy-privacy-plugin.html",
            "title": "Trustworthy Privacy Plug-in",
            "excerpt": "Aggregate usage records at the user side in a trustworthy manner.",
            "sections": {
                "Summary": "Aggregate usage records at the user side in a trustworthy manner.",
                "Context": "A service provider gets continuous measurements of a service attribute linked to a service individual. Applicable service tariffs may vary over time.",
                "Problem": "The provision of a service may require repeated, detailed measurements of a service attribute linked to a data subject to e.g. properly bill them for the service usage. However, these measurements may reveal further information (e.g. personal habits, etc.) when repeated over time.",
                "Solution": "Host a Privacy Plugin at a consumer-trusted device, in between the metering and the billing systems. and the service provider in charge of billing for the service usage. This privacy plugin, under the consumer\u2019s control, computes the aggregated invoice and sends it to the service provider (or to its billing subsystem), which does not need any fine-grained consumption records anymore. Cryptographic techniques (homomorphic commitments, zero-knowledge proofs of knowledge, digital signatures) are used to ensure trustworthiness of the generated invoices without requiring tamper-proof hardware.\n\n\nA service provider can get a trustworthy measurement of service usage along a period to issue a bill for the service usage; however, the detailed consumption for finer intervals cannot be obtained.",
                "Consequences": "The service provider does not need anymore to access detailed consumption data in order to issue reliable bills.",
                "Examples": "An electric utility operates a smart grid network with smart meters that provide measurements of the instantaneous power consumption of each user. Depending on the power demand, dynamic tariffs are applied. The utility employs that information to bill each client periodically, according to his aggregated consumption over the billing period and the respective tariffs at each moment. However, this information can also be exploited to infer sensitive user information (e.g. at what time he or she leaves and comes back to home, etc.)\n\n#",
                "Known Uses": "- Alfredo Rial and George Danezis. 2011. Privacy-preserving smart metering. In Proceedings of the 10th annual ACM workshop on Privacy in the electronic society (WPES '11). ACM, New York, NY, USA, 49-60.\n- Rial, A., & Danezis, G. (2011, October). Privacy-preserving smart metering. In Proceedings of the 10th annual ACM workshop on Privacy in the electronic society (pp. 49-60). ACM."
            }
        },
        {
            "filename": "Unusual-activities.html",
            "title": "Unusual Activities",
            "excerpt": "Prevent suspicious access to user data through alerts and authenticate through multiple factors upon potential compromise of an account.",
            "sections": {
                "Also Known As": "Handling unusual account activities with multiple factors",
                "Context": "Services (or products), particularly over the Internet, tend to use username and password based authentication. This security mechanism proves most convenient for users, as it is commonplace and simple compared to the more secure alternatives. It is also subject to common shortcomings, however. Passwords become less secure the longer they remain unchanged, are often vulnerable to brute force, snooping, and phishing attacks, and cannot be proven to be held solely by the user.\n\nThis complicates the certainty of the authentication, and thereby the authenticity of any decision made by the user, including consent. Controllers may also derive additional factors, however, such as device or access specific information. If location is provided, for example, it may hint at unlikely account activity.",
                "Problem": "Username and password authentication alone has varying reliability for proving decisions taken by a user, especially when concerning more sensitive actions. Controllers need to enhance their certainty that any consent provided is legitimate.\n\n##",
                "Forces and Concerns": "- Users want to be able to authenticate easily and quickly, but also do not want controllers to accept decisions made by intruders\n- Users want to know that their password is compromised, so that they can change it, especially if they use derivatives elsewhere\n- Controllers want to protect user accounts from unauthorized access\n- Controllers do not want to allow actions which the user did not truly consent to\n\n\nA balance should be made between the insecurity of username and password authentication and the inconvenience of multi-factor authentication. If measures affect usability or privacy too greatly, users will stop using the system. While the rate of false positives must not be too high, they are far preferable to undetected intrusions.\n\n- _In the provided example, Facebook makes use of its resource of friendship and photos. Their decision is based on the assumption that it is very unlikely for a hacker to recognize the friends. Actually the assumption may not hold true in some scenarios, because many of the photos are public and can be viewed under another account, or can be identified with the help from a large-scale tagged photo collection and machine learning._\n- _Persuading the user into carrying a hardware token everywhere only for occasional multi-factor authentication may be difficult, but it might worth the effort for financial services._",
                "Solution": "Analyze the available information for which there is consent to establish an access norm. Test this against future access to identify unusual activities. When this occurs, alert the user and use multi-factor authentication while re-establishing certainty. The authenticated user should be able to review and take further action.\n\n\n\n\n\n\n#",
                "Implementation": "_Typically, a sign-in to a website is in the form of an HTTP request, which contains many customized settings of the browser, including the type of the browser and operating system as well as the architecture (`User-Agent` header), the Cookie (`Cookie` header), language preferences (`Accept-Languages` header). Apart from these, the website can get the IP address of the user, which may be mapped to a certain country/area through GeoIP. These can be used to tell if a browser is 'new' to the website. The website can have its rules to determine if an access is 'suspicious', for example, an access from a new country / browser / operating system is considered suspicious._\n\n_By running native code, the application can consensually collect some device identifiers, including the operating system environment settings (e.g. the list of running processes), the hardware parameters (such as the ID of the CPU), and device UUIDs (provided by mobile operating systems like iOS). By completing a network request, the service also retrieves the IP address of the device. These can be used to tell if a device is 'new' to the service. The service can have its rules to determine if a sign-in is 'suspicious', for example, an access from a new country / device / operating system is considered suspicious._\n\n* _Require Multi-factor Authentication_\n\n_In case of a suspicious activity, multi-factor authentication may be a way to let the legitimate user in. The service can request further authentication, such as:_\n\n- _A software token_\n    - _Examples include Google Authenticator which runs on mobile phones and implements RFC6238 TOTP security tokens._\n- _A hardware token (disconnected)_\n    - _Examples include a token issued by a bank which displays digits, which is similar to a software token._\n- _A hardware token (connected)_\n    - _The token may exchange a longer secondary password than the previous one, which means it's safer._\n- _Personal data like date of birth, or civil identification._\n    - _Obviously not a good choice here because it cannot be changed._\n- _An one-time password (OTP) sent to the registered E-mail address / mobile phone_\n    - _Depending on the type of the service, the user may use the same password for the E-mail address, or may lose their mobile phone._\n\n_Using multi-factor authentication only in case of suspicious activity is more convenient than using it all the time, but is less secure._\n\n* _Notify Account Holders of Unusual Activities_\n\n_When a suspicious sign-in is detected, it may be a sign that the password has already been leaked. Depending on the type of the service, it can notify the user about the suspicious sign-in through E-mail, telephone, or other means._\n\n_Here the immediate notification can also be used in the multi-factor authentication._\n\n_For services that can be logged on from multiple devices at the same time, the user should be able to check the existence of other sessions, and review recent activity._",
                "Consequences": "Users will be able to use an easier, more familiar method of authentication in most scenarios, only having to resort to multi-factor authentication when there is potential cause for concern.\n\n#",
                "Constraints": "_This pattern has some limitations. For example, it relies on accurate identification of suspicious activity based on meta information, where the meta information including the IP address can be spoofed by an experienced attacker._\n\n_If the fallback multi-factor authentication only happens occasionally to the legitimate account owner, they may be unprepared to handle such authentication, leading to decreased usability._",
                "Examples": "1. _Gmail_\n    - _Gmail displays information about other sessions (if any) in the footer, linking to a page named \"Activity on this account\" which lists other sessions and recent activities to the Gmail account. The user has the option to sign out other sessions._\n    - _In case of annoying false positives, the user may choose to disable the alert for unusual activity. The disable takes about a week, \"to make sure the bad guys aren't the ones who turned off your alerts.\"_\n2. _Facebook_\n    - _When Facebook detects an unusual sign-in, it shows 'social authentication' that displays a few pictures of the user's friends and asks the user to name the person in those photos._\n3. _Dropbox_\n    - _The 'Security' tab of the 'Settings' of the Dropbox website displays all web browser sessions logged in to the account, and enables the user to log out one or more of them. The name of the browser, operating system, and the IP address and corresponding country are displayed to help the user make a choice._\n    - _It also displays all devices that are linked to the account, and allows the user to unlink one or more of them._\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern _complements_ the Data Breach Notification(Data-breach-notification-pattern) pattern. These patterns work in an overlapping context. While this pattern  focuses on detecting and dealing with unauthorized access, Data Breach Notification(Data-breach-notification-pattern) focuses on informing and reacting when a data breach has occurred. The patterns can work together to handle unauthorized access to personal data.\n\nThis pattern also _complements_ Informed Secure Passwords(Informed-Secure-Passwords). While this pattern establishes access norms for authentication, the latter focuses on encouraging better use of password-based authentication. The patterns may work together to aid in detection and response to compromised access, and in users learning from these instances.\n\nFinally this pattern _complements_ Impactful Information and Feedback(Impactful-Information-and-Feedback). Unusual Activities provides important information which can be used with Impactful Information and Feedback(Impactful-Information-and-Feedback) to better inform the user, and allow the user to better protect their personal data.\n\n#",
                "Sources": "N. Doty, M. Gupta, and J. Zych, \u201cprivacypatterns.org - Privacy Patterns,\u201d privacypatterns.org, 2017. Online. Available: http://privacypatterns.org/. Accessed: 26-Feb-2015.\n\nJ. Polakis, M. Lancini, G. Kontaxis, F. Maggi, S. Ioannidis, A. Keromytis, and S. Zanero, \u201cAll Your Face Are Belong to Us: Breaking Facebook\u2019s Social Authentication,\u201d Proceedings of the Annual Computer Security Applications Conference (ACSAC), no. i, pp. 399\u2013408, 2012.",
                "General Comments": "* _Determining the Scope_\n\n_Gmail displays unusual activities regarding an account, which involves identifying unusual activities where the password entered is correct. For some other services, correct passwords can be rejected from a new device / location._\n\n_So, the scope of this pattern is to handle unusual activities (including sign-ins)._\n\n* _Relevant Information_\n\n_This pattern includes multi-factor authentication and two-step authentication, which are well studied. But the general topic about informing the user of unusual activities seems to be lacking in literature._"
            }
        },
        {
            "filename": "Use-of-dummies.html",
            "title": "Use of dummies",
            "excerpt": "This pattern hides the actions taken by a user by adding fake actions that are indistinguishable from real.",
            "sections": {
                "Summary": "This pattern hides the actions taken by a user by adding fake actions\nthat are indistinguishable from real.",
                "Context": "This pattern is applicable when it is not possible to avoid executing,\ndelaying or obfuscating the content of an action.",
                "Problem": "When users interact with ICT systems their actions reveal a lot of\ninformation about themselves. An option would be for users to not\nperform such actions to protect their privacy. However, this is not\npossible since users cannot completely avoid executing these actions\nbecause they need to perform them to achieve a goal (e.g., search for\na word on the Internet, send an email, search for a location).",
                "Solution": "Since the action must be accurately performed, an option to provide\nprivacy is to simultaneously perform other actions in such a way that\nthe adversary cannot distinguish real and fake (often called dummy)\nactions.\n\n\nTo hinder the adversary\u2019s ability to infer the user behavior, as well\nas her preferences.",
                "Consequences": "This pattern entails the need for extra resources to perform the dummy\nactions, both at the side of the user that must repeat the action, and\nat the server side that must process several actions. Sometimes it may\ndegrade the quality of service since the service provider cannot\npersonalize services. It has been demonstrated that generating dummies\nthat are perfectly indistinguishable from real actions (in terms of\ncontent, timing, size, etc...) is very difficult.",
                "Examples": "Alice wants to search for an abortion clinic on Google, but she does\nnot want to reveal her intentions of abort to an adversary that may be\neavesdropping this search (e.g., ISP provider, system administrator of\nher workplace, etc).\n\n#",
                "Known Uses": "The use of this pattern has been proposed to protect privacy in\nlocation based services (the user reveals several locations to the\nservice provider so that her real location is hidden), anonymous\ncommunications (the user sends fake messages to fake recipients to\nhide her profile), web searches (the user searches for fake terms to\nhide her real preferences)."
            }
        },
        {
            "filename": "User-data-confinement-pattern.html",
            "title": "User data confinement pattern",
            "excerpt": "Avoid the central collection of personal data by shifting some amount of the processing of personal data to the user-trusted environments (e.g. their own devices). Allow users to control the exact data that shares with service providers",
            "sections": {
                "Summary": "Avoid the central collection of personal data by shifting some amount\nof the processing of personal data to the user-trusted environments\n(e.g. their own devices). Allow users to control the exact data that\nshares with service providers",
                "Context": "This pattern may be used whenever the collection of personal data with\none specific and legitimate purpose still pose a relevant level of\nthreat to the users' privacy",
                "Problem": "The engineering process is biased to develop system-centric\narchitectures where the data is collected and processed in single\ncentral entities, forcing users to trust them and share potentially\nsensible personal data",
                "Solution": "The solution is to shift the trust relationship, meaning that instead\nof having the customer trust the service provide to protect its\npersonal data, the service provider now haves to trust the customers'\nprocessing.\n\nIn the smart meter example, the smart meter would receive the monthly\ntariff and calculate the customer's bill which will be then sent to\nthe energy provider where it will be processed. The main benefit is\nthat at no moment the personal data has left the users trusted\nenvironment.\n\n\nAvoid the need for trust in service providers and the collection of\npersonal data",
                "Consequences": "Depending on the type of processing (e.g calculate the bill for the\nmonthly energy consumption or the age from the birth date) the service\nprovider will require some guarantees from the processor (the end\nuser). This may involve the usage of Trusted Platform Modules or\ncryptographic algorithms (e.g. ABC4Trust)",
                "Examples": "The smart grid is a domain with a clear example: having smart meters\ndelivering hourly customers' energy consumption to the energy provider\nposes a serious threat to the customers' privacy. If the only purpose\nof collecting these data is to bill the customer, why cannot this\ncalculation be done by the customer based on pre-established tariffs?\n\nSimilar examples in other domains are \"pay as your drive\" insurance\npolicies where the insurance price is calculated based on the drivers\nbehaviour or electronic toll pricing\n\n#",
                "Known Uses": "Smart meter, Privacy-enhanced attribute based credentials, pay as your\ndrive insurances, electronic toll pricing"
            }
        },
        {
            "filename": "Whos-Listening.html",
            "title": "Who\u2019s Listening",
            "excerpt": "Inform users of content where other users or unauthenticated persons having accessed the same content are listed, and may access any further disclosures.",
            "sections": {
                "Also Known As": "User List",
                "Context": "Users of a service regularly share its usage with other users. Sometimes these are users they know personally, and sometimes these are anonymous, unauthenticated persons. This occurs particularly in shared or collaborative environments where content is generated. Knowledge of the contributions of other users contributes to additional or refined content in general. Controllers facilitating this interaction therefore encourage the users to form groups or allow public access. Though when the amount of disclosure is high it is difficult to keep track of attribution and modification.",
                "Problem": "Users do not know if the content they are accessing or have disclosed has been accessed or modified by others, nor if it is someone they know.\n\n##",
                "Forces and Concerns": "- Users want to know who can access their disclosures and those of others\n- Users want to know that specific other users have accessed or modified content\n- Controllers do not want users to be unaware of who can see their disclosures\n- Controllers want to log access to prevent abuse",
                "Solution": "Provided that users know their access is not private, inform them of other users, even unauthenticated, which are also accessing the content in question.\n\n\n\n\n\n\n#",
                "Implementation": "Ensure that it is made clear to the user that the content they are about to view is accessed in a shared and public manner. Their access will be visible to others, and may be recorded by the system (if applicable) for historic views, or for preventing abuse.\n\nThe implementation of the system prior to this will likely only require the addition of UI elements to indicate the access state as the system already perceives it. Each user may be shown using some identifier easily recognizable by other users, such as a randomly selected avatar (e.g. Gravitar), initial(s), username, or profile picture. The same may identify unauthenticated users as 'anonymous'.\n\nWhere historic views are provided, the same consistent identifier can be shown next to differential changes along with timestamps. The ability to edit, remove, or anonymize a contribution may also be available if desired. Details of these extra features, or justification for the lack of user ability to perform these actions, should be provided prior to usage.",
                "Consequences": "_This pattern will only work, if the users trust the system that provides the information and log in personally. In web based systems that don\u2019t require personal login, it is not possible to reliably detect, who is visiting the site (even cookies and browser fingerprints do not necessarily reveal information about the users\u2019 identities). This is problematic for attribution, but it ensures that the users can control their privacy._",
                "Examples": "_The MIME protocol provides an option so that receivers of the message are asked to confirm the message. It is defined in RFC 8098 (Hansen & Melnikov 2017)_\n\n_The BSCWshared workspace system (Bentley, Horstmann, and Trevor 1997) logs accesses to the shared content. The event log can be queried by users and for each document stored in the shared workspace, the users can define notification patterns. By these means, it is possible for an author of a document to find out who read the document (and when)._\n\nVarious collaborative environments, like Google's Docs, or chat rooms, instant messaging, and other immediate content sharing mediums frequently provide lists of currently online users. These can also indicate a number of anonymous users who have not authenticated, but have reduced privileges.\n\n\n\n\n\n\n\n\n\n\n\n#",
                "Related Patterns": "This pattern is a component of the compound pattern, Awareness Feed(Awareness-Feed). As such, this pattern _may be used_ by it.\n\nThis pattern _complements_ Privacy Awareness Panel(Privacy-Awareness-Panel), Appropriate Privacy Feedback(Appropriate-Privacy-Feedback), Buddy List(Buddy-List), and Reciprocity(Reciprocity).\n\nPrivacy Awareness Panel(Privacy-Awareness-Panel), like this pattern, shows disclosed information access. It specifically allows monitoring what access is occurring and how it might become identifying. Comparatively, this pattern allows for monitoring who accesses the same content as the user. These could work together to have a more complete solution which covers released and accessed content monitoring. Appropriate Privacy Feedback(Appropriate-Privacy-Feedback) is another pattern which tries to show who can see disclosed content. It however adds the possibility of knowing how the data might be used, providing useful feedback to the user. These patterns may work together in a similar fashion.\n\nIt also _may use_ Sch\u00fcmmer's Activity Counter for anonymous information aggregation which does not reveal receiver identify. The same holds for Elephant\u2019s Brain, which can log information of user activity. It also _refines_ the Magic Document pattern (Volter 2003), which to a lessor extent ensures that collaborative users are aware of accessed information.\n\n#",
                "Sources": "T. Sch\u00fcmmer, \u201cThe Public Privacy - Patterns for Filtering Personal Information in Collaborative Systems,\u201d in Proceedings of CHI workshop on Human-Computer-Human-Interaction Patterns, 2004.\n\nT. Hansen & A. Melnikov, \u201cMessage Disposition Notification,\u201d IETF. STD 85. RFC 8098. Retrieved November 2017.\n\nR. Bentley, T. Horstmann, and J. Trevor, \u201cThe world wide web as enabling technology for cscw: The case of bscw,\u201d 1997."
            }
        }
    ]
}